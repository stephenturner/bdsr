[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Biological Data Science with R",
    "section": "",
    "text": "Preface\nThis book was written as a companion to a series of courses introducing the essentials of biological data science with R. While this book was written with the accompanying live instruction in mind, this book can be used as a self-contained self study guide for quickly learning the essentials need to get started with R. The BDSR book and accompanying course introduces methods, tools, and software for reproducibly managing, manipulating, analyzing, and visualizing large-scale biological data using the R statistical computing environment. This book also covers essential statistical analysis, and advanced topics including survival analysis, predictive modeling, forecasting, and text mining.\nThis is not a “Tool X” or “Software Y” book. I want you to take away from this book and accompanying course the ability to use an extremely powerful scientific computing environment (R) to do many of the things that you’ll do across study designs and disciplines – managing, manipulating, visualizing, and analyzing large, sometimes high-dimensional data. Regardless of your specific discipline you’ll need the same computational know-how and data literacy to do the same kinds of basic tasks in each. This book might show you how to use specific tools here and there (e.g., DESeq2 for RNA-seq analysis (Love, Huber, and Anders 2014), ggtree for drawing phylogenetic trees (Yu et al. 2017), etc.), but these are not important – you probably won’t be using the same specific software or methods 10 years from now, but you’ll still use the same underlying data and computational foundation. That is the point of this series – to arm you with a basic foundation, and more importantly, to enable you to figure out how to use this tool or that tool on your own, when you need to.\nThis is not a statistics book. There is a short lesson on essential statistics using R in Chapter 8 but this short chapter offers neither a comprehensive background on underlying theory nor in-depth coverage of implementation strategies using R. Some general knowledge of statistics and study design is helpful, but isn’t required for going through this book or taking the accompanying course.\nThere are no prerequisites to this book or the accompanying course. However, each chapter involves lots of hands-on practice coding, and you’ll need to download and install required softwar and download required data. See the setup instructions in Appendix A.\n\n\nAcknowledgements\nThis book is partially adapted from material we developed for the University of Virginia BIMS8382 graduate course . The material for this course was adapted from and/or inspired by Jenny Bryan’s STAT545 course at UBC (Bryan 2019), Software Carpentry (Wilson 2014) and Data Carpentry (Teal et al. 2015) courses, David Robinson’s Variance Explained blog (Robinson 2015), the ggtree vignettes (Yu 2022) Tidy Text Mining with R (Silge and Robinson 2017), and likely many others.\n\n\n\n\nBryan, Jennifer. 2019. “STAT 545: Data Wrangling, Exploration, and Analysis with r.” https://stat545.com/.\n\n\nLove, Michael I., Wolfgang Huber, and Simon Anders. 2014. “Moderated Estimation of Fold Change and Dispersion for RNA-seq Data with DESeq2.” Genome Biology 15 (12): 1–21.\n\n\nRobinson, David. 2015. “Variance Explained.” http://varianceexplained.org/.\n\n\nSilge, Julia, and David Robinson. 2017. Text Mining with R: A Tidy Approach. 1st edition. Beijing ; Boston: O’Reilly Media.\n\n\nTeal, Tracy K., Karen A. Cranston, Hilmar Lapp, Ethan White, Greg Wilson, Karthik Ram, and Aleksandra Pawlik. 2015. “Data Carpentry: Workshops to Increase Data Literacy for Researchers.”\n\n\nWilson, Greg. 2014. “Software Carpentry: Lessons Learned.” F1000Research 3.\n\n\nYu, Guangchuang. 2022. “Ggtree: An r Package for Visualization of Tree and Annotation Data.” http://bioconductor.org/packages/ggtree/.\n\n\nYu, Guangchuang, David K. Smith, Huachen Zhu, Yi Guan, and Tommy Tsan-Yuk Lam. 2017. “Ggtree: An R Package for Visualization and Annotation of Phylogenetic Trees with Their Covariates and Other Associated Data.” Methods in Ecology and Evolution 8 (1): 28–36."
  },
  {
    "objectID": "basics.html#rstudio",
    "href": "basics.html#rstudio",
    "title": "1  Basics",
    "section": "1.1 RStudio",
    "text": "1.1 RStudio\nLet’s start by learning about RStudio. R is the underlying statistical computing environment. RStudio is a graphical integrated development environment (IDE) that makes using R much easier.\n\nOptions: First, let’s change a few options. We’ll only have to do this once. Under Tools… Global Options…:\n\nUnder General: Uncheck “Restore most recently opened project at startup”\nUnder General: Uncheck “Restore .RData into workspace at startup”\nUnder General: Set “Save workspace to .RData on exit:” to Never.\nUnder General: Set “Save workspace to .RData on exit:” to Never.\nUnder R Markdown: Uncheck “Show output inline for all R Markdown documents”\n\nProjects: first, start a new project in a new folder somewhere easy to remember. When we start reading in data it’ll be important that the code and the data are in the same place. Creating a project creates an Rproj file that opens R running in that folder. This way, when you want to read in dataset whatever.txt, you just tell it the filename rather than a full path. This is critical for reproducibility, and we’ll talk about that more later.\nCode that you type into the console is code that R executes. From here forward we will use the editor window to write a script that we can save to a file and run it again whenever we want to. We usually give it a .R extension, but it’s just a plain text file. If you want to send commands from your editor to the console, use CMD+Enter (Ctrl+Enter on Windows).\nAnything after a # sign is a comment. Use them liberally to comment your code."
  },
  {
    "objectID": "basics.html#basic-operations",
    "href": "basics.html#basic-operations",
    "title": "1  Basics",
    "section": "1.2 Basic operations",
    "text": "1.2 Basic operations\nR can be used as a glorified calculator. Try typing this in directly into the console. Make sure you’re typing into into the editor, not the console, and save your script. Use the run button, or press CMD+Enter (Ctrl+Enter on Windows).\n\n2+2\n\n[1] 4\n\n5*4\n\n[1] 20\n\n2^3\n\n[1] 8\n\n\nR Knows order of operations and scientific notation.\n\n2+3*4/(5+3)*15/2^2+3*4^2\n\n[1] 55.6\n\n5e4\n\n[1] 50000\n\n\nHowever, to do useful and interesting things, we need to assign values to objects. To create objects, we need to give it a name followed by the assignment operator &lt;- and the value we want to give it:\n\nweight_kg &lt;- 55\n\n&lt;- is the assignment operator. Assigns values on the right to objects on the left, it is like an arrow that points from the value to the object. Mostly similar to = but not always. Learn to use &lt;- as it is good programming practice. Using = in place of &lt;- can lead to issues down the line. The keyboard shortcut for inserting the &lt;- operator is Alt-dash.\nObjects can be given any name such as x, current_temperature, or subject_id. You want your object names to be explicit and not too long. They cannot start with a number (2x is not valid but x2 is). R is case sensitive (e.g., weight_kg is different from Weight_kg). There are some names that cannot be used because they represent the names of fundamental functions in R (e.g., if, else, for, see here for a complete list). In general, even if it’s allowed, it’s best to not use other function names, which we’ll get into shortly (e.g., c, T, mean, data, df, weights). In doubt check the help to see if the name is already in use. It’s also best to avoid dots (.) within a variable name as in my.dataset. It is also recommended to use nouns for variable names, and verbs for function names.\nWhen assigning a value to an object, R does not print anything. You can force to print the value by typing the name:\n\nweight_kg\n\n[1] 55\n\n\nNow that R has weight_kg in memory, we can do arithmetic with it. For instance, we may want to convert this weight in pounds (weight in pounds is 2.2 times the weight in kg).\n\n2.2 * weight_kg\n\n[1] 121\n\n\nWe can also change a variable’s value by assigning it a new one:\n\nweight_kg &lt;- 57.5\n2.2 * weight_kg\n\n[1] 127\n\n\nThis means that assigning a value to one variable does not change the values of other variables. For example, let’s store the animal’s weight in pounds in a variable.\n\nweight_lb &lt;- 2.2 * weight_kg\n\nand then change weight_kg to 100.\n\nweight_kg &lt;- 100\n\nWhat do you think is the current content of the object weight_lb? 126.5 or 220?\nYou can see what objects (variables) are stored by viewing the Environment tab in Rstudio. You can also use the ls() function. You can remove objects (variables) with the rm() function. You can do this one at a time or remove several objects at once. You can also use the little broom button in your environment pane to remove everything from your environment.\n\nls()\nrm(weight_lb, weight_kg)\nls()\nweight_lb # oops! you should get an error because weight_lb no longer exists!\n\n\n\n\n\n\n\nExercise 1\n\n\n\nWhat are the values after each statement in the following?\n\nmass &lt;- 50              # mass?\nage  &lt;- 30              # age?\nmass &lt;- mass * 2        # mass?\nage  &lt;- age - 10        # age?\nmass_index &lt;- mass/age  # massIndex?"
  },
  {
    "objectID": "basics.html#functions",
    "href": "basics.html#functions",
    "title": "1  Basics",
    "section": "1.3 Functions",
    "text": "1.3 Functions\nR has built-in functions.\n\n# Notice that this is a comment.\n# Anything behind a # is \"commented out\" and is not run.\nsqrt(144)\n\n[1] 12\n\nlog(1000)\n\n[1] 6.91\n\n\nGet help by typing a question mark in front of the function’s name, or help(functionname):\n\nhelp(log)\n?log\n\nNote syntax highlighting when typing this into the editor. Also note how we pass arguments to functions. The base= part inside the parentheses is called an argument, and most functions use arguments. Arguments modify the behavior of the function. Functions some input (e.g., some data, an object) and other options to change what the function will return, or how to treat the data provided. Finally, see how you can next one function inside of another (here taking the square root of the log-base-10 of 1000).\n\nlog(1000)\n\n[1] 6.91\n\nlog(1000, base=10)\n\n[1] 3\n\nlog(1000, 10)\n\n[1] 3\n\nsqrt(log(1000, base=10))\n\n[1] 1.73\n\n\n\n\n\n\n\n\nExercise 2\n\n\n\nSee ?abs and calculate the square root of the log-base-10 of the absolute value of -4*(2550-50). Answer should be 2."
  },
  {
    "objectID": "basics.html#tibbles-data-frames",
    "href": "basics.html#tibbles-data-frames",
    "title": "1  Basics",
    "section": "1.4 Tibbles (data frames)",
    "text": "1.4 Tibbles (data frames)\nThere are lots of different basic data structures in R. If you take any kind of longer introduction to R you’ll probably learn about arrays, lists, matrices, etc. We are going to skip straight to the data structure you’ll probably use most – the tibble (also known as the data frame). We use tibbles to store heterogeneous tabular data in R: tabular, meaning that individuals or observations are typically represented in rows, while variables or features are represented as columns; heterogeneous, meaning that columns/features/variables can be different classes (on variable, e.g. age, can be numeric, while another, e.g., cause of death, can be text).\nWe’ll learn more about tibbles in Chapter 2."
  },
  {
    "objectID": "tibbles.html#our-data",
    "href": "tibbles.html#our-data",
    "title": "2  Tibbles",
    "section": "2.1 Our data",
    "text": "2.1 Our data\n\nThe data we’re going to look at is cleaned up version of a gene expression dataset from Brauer et al. Coordination of Growth Rate, Cell Cycle, Stress Response, and Metabolic Activity in Yeast (2008) Mol Biol Cell 19:352-367. This data is from a gene expression microarray, and in this paper the authors are examining the relationship between growth rate and gene expression in yeast cultures limited by one of six different nutrients (glucose, leucine, ammonium, sulfate, phosphate, uracil). If you give yeast a rich media loaded with nutrients except restrict the supply of a single nutrient, you can control the growth rate to any rate you choose. By starving yeast of specific nutrients you can find genes that:\n\nRaise or lower their expression in response to growth rate. Growth-rate dependent expression patterns can tell us a lot about cell cycle control, and how the cell responds to stress. The authors found that expression of &gt;25% of all yeast genes is linearly correlated with growth rate, independent of the limiting nutrient. They also found that the subset of negatively growth-correlated genes is enriched for peroxisomal functions, and positively correlated genes mainly encode ribosomal functions.\nRespond differently when different nutrients are being limited. If you see particular genes that respond very differently when a nutrient is sharply restricted, these genes might be involved in the transport or metabolism of that specific nutrient.\n\nYou can download the cleaned up version of the data here. The file is called brauer2007_tidy.csv. Later on we’ll actually start with the original raw data (minimally processed) and manipulate it so that we can make it more amenable for analysis."
  },
  {
    "objectID": "tibbles.html#reading-in-data",
    "href": "tibbles.html#reading-in-data",
    "title": "2  Tibbles",
    "section": "2.2 Reading in data",
    "text": "2.2 Reading in data\n\n2.2.1 dplyr and readr\nThere are some built-in functions for reading in data in text files. These functions are read-dot-something – for example, read.csv() reads in comma-delimited text data; read.delim() reads in tab-delimited text, etc. We’re going to read in data a little bit differently here using the readr package. When you load the readr package, you’ll have access to very similar looking functions, named read-underscore-something – e.g., read_csv(). You have to have the readr package installed to access these functions. Compared to the base functions, they’re much faster, they’re good at guessing the types of data in the columns, they don’t do some of the other silly things that the base functions do. We’re going to use another package later on called dplyr, and if you have the dplyr package loaded as well, and you read in the data with readr, the data will display nicely.\nFirst let’s load those packages.\n\nlibrary(readr)\nlibrary(dplyr)\n\nIf you see a warning that looks like this: Error in library(packageName) : there is no package called 'packageName', then you don’t have the package installed correctly. See the setup chapter (Appendix A).\n\n\n2.2.2 read_csv()\nNow, let’s actually load the data. You can get help for the import function with ?read_csv. When we load data we assign it to a variable just like any other, and we can choose a name for that data. Since we’re going to be referring to this data a lot, let’s give it a short easy name to type. I’m going to call it ydat. Once we’ve loaded it we can type the name of the object itself (ydat) to see it printed to the screen.\n\nydat &lt;- read_csv(file=\"data/brauer2007_tidy.csv\")\nydat\n\n# A tibble: 198,430 × 7\n   symbol systematic_name nutrient  rate expression bp                     mf   \n   &lt;chr&gt;  &lt;chr&gt;           &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;                  &lt;chr&gt;\n 1 SFB2   YNL049C         Glucose   0.05      -0.24 ER to Golgi transport  mole…\n 2 &lt;NA&gt;   YNL095C         Glucose   0.05       0.28 biological process un… mole…\n 3 QRI7   YDL104C         Glucose   0.05      -0.02 proteolysis and pepti… meta…\n 4 CFT2   YLR115W         Glucose   0.05      -0.33 mRNA polyadenylylatio… RNA …\n 5 SSO2   YMR183C         Glucose   0.05       0.05 vesicle fusion*        t-SN…\n 6 PSP2   YML017W         Glucose   0.05      -0.69 biological process un… mole…\n 7 RIB2   YOL066C         Glucose   0.05      -0.55 riboflavin biosynthes… pseu…\n 8 VMA13  YPR036W         Glucose   0.05      -0.75 vacuolar acidification hydr…\n 9 EDC3   YEL015W         Glucose   0.05      -0.24 deadenylylation-indep… mole…\n10 VPS5   YOR069W         Glucose   0.05      -0.16 protein retention in … prot…\n# ℹ 198,420 more rows\n\n\nTake a look at that output. The nice thing about loading dplyr and reading in data with readr is that data frames are displayed in a much more friendly way. This dataset has nearly 200,000 rows and 7 columns. When you import data this way and try to display the object in the console, instead of trying to display all 200,000 rows, you’ll only see about 10 by default. Also, if you have so many columns that the data would wrap off the edge of your screen, those columns will not be displayed, but you’ll see at the bottom of the output which, if any, columns were hidden from view. If you want to see the whole dataset, there are two ways to do this. First, you can click on the name of the data.frame in the Environment panel in RStudio. Or you could use the View() function (with a capital V).\n\nView(ydat)"
  },
  {
    "objectID": "tibbles.html#inspecting-data.frame-objects",
    "href": "tibbles.html#inspecting-data.frame-objects",
    "title": "2  Tibbles",
    "section": "2.3 Inspecting data.frame objects",
    "text": "2.3 Inspecting data.frame objects\n\n2.3.1 Built-in functions\nThere are several built-in functions that are useful for working with data frames.\n\nContent:\n\nhead(): shows the first few rows\ntail(): shows the last few rows\n\nSize:\n\ndim(): returns a 2-element vector with the number of rows in the first element, and the number of columns as the second element (the dimensions of the object)\nnrow(): returns the number of rows\nncol(): returns the number of columns\n\nSummary:\n\ncolnames() (or just names()): returns the column names\nstr(): structure of the object and information about the class, length and content of each column\nsummary(): works differently depending on what kind of object you pass to it. Passing a data frame to the summary() function prints out useful summary statistics about numeric column (min, max, median, mean, etc.)\n\n\n\nhead(ydat)\n\n# A tibble: 6 × 7\n  symbol systematic_name nutrient  rate expression bp                      mf   \n  &lt;chr&gt;  &lt;chr&gt;           &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;                   &lt;chr&gt;\n1 SFB2   YNL049C         Glucose   0.05      -0.24 ER to Golgi transport   mole…\n2 &lt;NA&gt;   YNL095C         Glucose   0.05       0.28 biological process unk… mole…\n3 QRI7   YDL104C         Glucose   0.05      -0.02 proteolysis and peptid… meta…\n4 CFT2   YLR115W         Glucose   0.05      -0.33 mRNA polyadenylylation* RNA …\n5 SSO2   YMR183C         Glucose   0.05       0.05 vesicle fusion*         t-SN…\n6 PSP2   YML017W         Glucose   0.05      -0.69 biological process unk… mole…\n\ntail(ydat)\n\n# A tibble: 6 × 7\n  symbol systematic_name nutrient  rate expression bp                      mf   \n  &lt;chr&gt;  &lt;chr&gt;           &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;                   &lt;chr&gt;\n1 DOA1   YKL213C         Uracil     0.3       0.14 ubiquitin-dependent pr… mole…\n2 KRE1   YNL322C         Uracil     0.3       0.28 cell wall organization… stru…\n3 MTL1   YGR023W         Uracil     0.3       0.27 cell wall organization… mole…\n4 KRE9   YJL174W         Uracil     0.3       0.43 cell wall organization… mole…\n5 UTH1   YKR042W         Uracil     0.3       0.19 mitochondrion organiza… mole…\n6 &lt;NA&gt;   YOL111C         Uracil     0.3       0.04 biological process unk… mole…\n\ndim(ydat)\n\n[1] 198430      7\n\nnames(ydat)\n\n[1] \"symbol\"          \"systematic_name\" \"nutrient\"        \"rate\"           \n[5] \"expression\"      \"bp\"              \"mf\"             \n\nstr(ydat)\n\nspc_tbl_ [198,430 × 7] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ symbol         : chr [1:198430] \"SFB2\" NA \"QRI7\" \"CFT2\" ...\n $ systematic_name: chr [1:198430] \"YNL049C\" \"YNL095C\" \"YDL104C\" \"YLR115W\" ...\n $ nutrient       : chr [1:198430] \"Glucose\" \"Glucose\" \"Glucose\" \"Glucose\" ...\n $ rate           : num [1:198430] 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 ...\n $ expression     : num [1:198430] -0.24 0.28 -0.02 -0.33 0.05 -0.69 -0.55 -0.75 -0.24 -0.16 ...\n $ bp             : chr [1:198430] \"ER to Golgi transport\" \"biological process unknown\" \"proteolysis and peptidolysis\" \"mRNA polyadenylylation*\" ...\n $ mf             : chr [1:198430] \"molecular function unknown\" \"molecular function unknown\" \"metalloendopeptidase activity\" \"RNA binding\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   symbol = col_character(),\n  ..   systematic_name = col_character(),\n  ..   nutrient = col_character(),\n  ..   rate = col_double(),\n  ..   expression = col_double(),\n  ..   bp = col_character(),\n  ..   mf = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\nsummary(ydat)\n\n    symbol          systematic_name      nutrient              rate      \n Length:198430      Length:198430      Length:198430      Min.   :0.050  \n Class :character   Class :character   Class :character   1st Qu.:0.100  \n Mode  :character   Mode  :character   Mode  :character   Median :0.200  \n                                                          Mean   :0.175  \n                                                          3rd Qu.:0.250  \n                                                          Max.   :0.300  \n   expression         bp                 mf           \n Min.   :-6.50   Length:198430      Length:198430     \n 1st Qu.:-0.29   Class :character   Class :character  \n Median : 0.00   Mode  :character   Mode  :character  \n Mean   : 0.00                                        \n 3rd Qu.: 0.29                                        \n Max.   : 6.64                                        \n\n\n\n\n2.3.2 Other packages\nThe glimpse() function is available once you load the dplyr library, and it’s like str() but its display is a little bit better.\n\nglimpse(ydat)\n\nRows: 198,430\nColumns: 7\n$ symbol          &lt;chr&gt; \"SFB2\", NA, \"QRI7\", \"CFT2\", \"SSO2\", \"PSP2\", \"RIB2\", \"V…\n$ systematic_name &lt;chr&gt; \"YNL049C\", \"YNL095C\", \"YDL104C\", \"YLR115W\", \"YMR183C\",…\n$ nutrient        &lt;chr&gt; \"Glucose\", \"Glucose\", \"Glucose\", \"Glucose\", \"Glucose\",…\n$ rate            &lt;dbl&gt; 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, …\n$ expression      &lt;dbl&gt; -0.24, 0.28, -0.02, -0.33, 0.05, -0.69, -0.55, -0.75, …\n$ bp              &lt;chr&gt; \"ER to Golgi transport\", \"biological process unknown\",…\n$ mf              &lt;chr&gt; \"molecular function unknown\", \"molecular function unkn…\n\n\nThe skimr package has a nice function, skim, that provides summary statistics the user can skim quickly to understand your data. You can install it with install.packages(\"skimr\") if you don’t have it already.\n\nlibrary(skimr)\nskim(ydat)\n\n\nData summary\n\n\nName\nydat\n\n\nNumber of rows\n198430\n\n\nNumber of columns\n7\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n5\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nsymbol\n47250\n0.76\n2\n9\n0\n4210\n0\n\n\nsystematic_name\n0\n1.00\n5\n9\n0\n5536\n0\n\n\nnutrient\n0\n1.00\n6\n9\n0\n6\n0\n\n\nbp\n7663\n0.96\n7\n82\n0\n880\n0\n\n\nmf\n7663\n0.96\n11\n125\n0\n1085\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nrate\n0\n1\n0.18\n0.09\n0.05\n0.10\n0.2\n0.25\n0.30\n▇▅▅▅▅\n\n\nexpression\n0\n1\n0.00\n0.67\n-6.50\n-0.29\n0.0\n0.29\n6.64\n▁▁▇▁▁"
  },
  {
    "objectID": "tibbles.html#accessing-variables-subsetting-data-frames",
    "href": "tibbles.html#accessing-variables-subsetting-data-frames",
    "title": "2  Tibbles",
    "section": "2.4 Accessing variables & subsetting data frames",
    "text": "2.4 Accessing variables & subsetting data frames\nWe can access individual variables within a data frame using the $ operator, e.g., mydataframe$specificVariable. Let’s print out all the gene names in the data. Then let’s calculate the average expression across all conditions, all genes (using the built-in mean() function).\n\n# display all gene symbols\nydat$symbol\n\n  [1] \"SFB2\"     NA         \"QRI7\"     \"CFT2\"     \"SSO2\"     \"PSP2\"    \n  [7] \"RIB2\"     \"VMA13\"    \"EDC3\"     \"VPS5\"     NA         \"AMN1\"    \n [13] \"SCW11\"    \"DSE2\"     \"COX15\"    \"SPE1\"     \"MTF1\"     \"KSS1\"    \n [19] NA         NA         \"YAP7\"     NA         \"YVC1\"     \"CDC40\"   \n [25] NA         \"RMD1\"     \"PCL6\"     \"AI4\"      \"GGC1\"     \"SUL1\"    \n [31] \"RAD57\"    NA         \"PER1\"     \"YHC3\"     \"SGE1\"     \"HNM1\"    \n [37] \"SWI1\"     \"NAM8\"     NA         \"BGL2\"     \"ACT1\"     NA        \n [43] \"SFL1\"     \"OYE3\"     \"MMP1\"     \"MHT1\"     \"SUL2\"     \"IPP1\"    \n [49] \"CWP1\"     \"SNF11\"    \"PEX25\"    \"ELO1\"     NA         \"CDC13\"   \n [55] \"FKH1\"     \"SWD1\"     NA         \"HOF1\"     \"HOC1\"     \"BNI5\"    \n [61] \"CSN12\"    \"PGS1\"     \"MLP2\"     \"HRP1\"     NA         \"SEC39\"   \n [67] \"ECM31\"    NA         NA         \"ADE4\"     \"ABC1\"     \"DLD2\"    \n [73] \"PHA2\"     NA         \"HAP3\"     \"MRPL23\"   NA         NA        \n [79] \"MRPL16\"   NA         NA         NA         NA         \"AI3\"     \n [85] \"COX1\"     NA         \"VAR1\"     \"COX3\"     \"COX2\"     \"AI5_BETA\"\n [91] \"AI2\"      NA         NA         \"GPI18\"    \"COS9\"     NA        \n [97] NA         \"PRP46\"    \"XDJ1\"     \"SLG1\"     \"MAM3\"     \"AEP1\"    \n[103] \"UGO1\"     NA         \"RSC2\"     \"YAP1801\"  \"ZPR1\"     \"BCD1\"    \n[109] \"UBP10\"    \"SLD3\"     \"RLF2\"     \"LRO1\"     NA         \"ITR2\"    \n[115] \"ABP140\"   \"STT3\"     \"PTC2\"     \"STE20\"    \"HRD3\"     \"CWH43\"   \n[121] \"ASK10\"    \"MPE1\"     \"SWC3\"     \"TSA1\"     \"ADE17\"    \"GFD2\"    \n[127] \"PXR1\"     NA         \"BUD14\"    \"AUS1\"     \"NHX1\"     \"NTE1\"    \n[133] NA         \"KIN3\"     \"BUD4\"     \"SLI15\"    \"PMT4\"     \"AVT5\"    \n[139] \"CHS2\"     \"GPI13\"    \"KAP95\"    \"EFT2\"     \"EFT1\"     \"GAS1\"    \n[145] \"CYK3\"     \"COQ2\"     \"PSD1\"     NA         \"PAC1\"     \"SUR7\"    \n[151] \"RAX1\"     \"DFM1\"     \"RBD2\"     NA         \"YIP4\"     \"SRB2\"    \n[157] \"HOL1\"     \"MEP3\"     NA         \"FEN2\"     NA         \"RFT1\"    \n[163] NA         \"MCK1\"     \"GPI10\"    \"APT1\"     NA         NA        \n[169] \"CPT1\"     \"ERV29\"    \"SFK1\"     NA         \"SEC20\"    \"TIR4\"    \n[175] NA         NA         \"ARC35\"    \"SOL1\"     \"BIO2\"     \"ASC1\"    \n[181] \"RBG1\"     \"PTC4\"     NA         \"OXA1\"     \"SIT4\"     \"PUB1\"    \n[187] \"FPR4\"     \"FUN12\"    \"DPH2\"     \"DPS1\"     \"DLD1\"     \"ASN2\"    \n[193] \"TRM9\"     \"DED81\"    \"SRM1\"     \"SAM50\"    \"POP2\"     \"FAA4\"    \n[199] NA         \"CEM1\"    \n [ reached getOption(\"max.print\") -- omitted 198230 entries ]\n\n#mean expression\nmean(ydat$expression)\n\n[1] 0.00337\n\n\nNow that’s not too interesting. This is the average gene expression across all genes, across all conditions. The data is actually scaled/centered around zero:\n\n\n\n\n\nWe might be interested in the average expression of genes with a particular biological function, and how that changes over different growth rates restricted by particular nutrients. This is the kind of thing we’re going to do in the next section.\n\n\n\n\n\n\nExercise 1\n\n\n\n\nWhat’s the standard deviation expression (hint: get help on the sd function with ?sd).\nWhat’s the range of rate represented in the data? (hint: range())."
  },
  {
    "objectID": "tibbles.html#bonus-preview-to-advanced-manipulation",
    "href": "tibbles.html#bonus-preview-to-advanced-manipulation",
    "title": "2  Tibbles",
    "section": "2.5 BONUS: Preview to advanced manipulation",
    "text": "2.5 BONUS: Preview to advanced manipulation\nWhat if we wanted show the mean expression, standard deviation, and correlation between growth rate and expression, separately for each limiting nutrient, separately for each gene, for all genes involved in the leucine biosynthesis pathway?\n\nydat |&gt; \n  filter(bp==\"leucine biosynthesis\") |&gt; \n  group_by(nutrient, symbol) |&gt; \n  summarize(mean=mean(expression), sd=sd(expression), r=cor(rate, expression))\n\n\n\n\n\n\nnutrient\nsymbol\nmean\nsd\nr\n\n\n\n\nAmmonia\nLEU1\n-0.82\n0.39\n0.66\n\n\nAmmonia\nLEU2\n-0.54\n0.38\n-0.19\n\n\nAmmonia\nLEU4\n-0.37\n0.56\n-0.67\n\n\nAmmonia\nLEU9\n-1.01\n0.64\n0.87\n\n\nGlucose\nLEU1\n-0.55\n0.41\n0.98\n\n\nGlucose\nLEU2\n-0.39\n0.33\n0.90\n\n\nGlucose\nLEU4\n1.09\n1.01\n-0.97\n\n\nGlucose\nLEU9\n-0.17\n0.35\n0.35\n\n\nLeucine\nLEU1\n2.70\n1.08\n-0.95\n\n\nLeucine\nLEU2\n0.28\n1.16\n-0.97\n\n\nLeucine\nLEU4\n0.80\n1.06\n-0.97\n\n\nLeucine\nLEU9\n0.39\n0.18\n-0.77\n\n\nPhosphate\nLEU1\n-0.43\n0.27\n0.95\n\n\nPhosphate\nLEU2\n-0.26\n0.19\n0.70\n\n\nPhosphate\nLEU4\n-0.99\n0.11\n0.24\n\n\nPhosphate\nLEU9\n-1.12\n0.53\n0.90\n\n\nSulfate\nLEU1\n-1.17\n0.34\n0.98\n\n\nSulfate\nLEU2\n-0.96\n0.30\n0.57\n\n\nSulfate\nLEU4\n-0.24\n0.43\n-0.60\n\n\nSulfate\nLEU9\n-1.24\n0.55\n0.99\n\n\nUracil\nLEU1\n-0.74\n0.73\n0.89\n\n\nUracil\nLEU2\n0.18\n0.13\n-0.07\n\n\nUracil\nLEU4\n-0.65\n0.44\n0.77\n\n\nUracil\nLEU9\n-1.02\n0.91\n0.94\n\n\n\n\n\nNeat eh? We’ll learn how to do that in the advanced manipulation with dplyr lesson."
  },
  {
    "objectID": "dplyr.html#review",
    "href": "dplyr.html#review",
    "title": "3  Data Manipulation with dplyr",
    "section": "3.1 Review",
    "text": "3.1 Review\n\n3.1.1 Our data\nWe’re going to use the yeast gene expression dataset described on the data frames lesson in Chapter 2. This is a cleaned up version of a gene expression dataset from Brauer et al. Coordination of Growth Rate, Cell Cycle, Stress Response, and Metabolic Activity in Yeast (2008) Mol Biol Cell 19:352-367. This data is from a gene expression microarray, and in this paper the authors are examining the relationship between growth rate and gene expression in yeast cultures limited by one of six different nutrients (glucose, leucine, ammonium, sulfate, phosphate, uracil). If you give yeast a rich media loaded with nutrients except restrict the supply of a single nutrient, you can control the growth rate to any rate you choose. By starving yeast of specific nutrients you can find genes that:\n\nRaise or lower their expression in response to growth rate. Growth-rate dependent expression patterns can tell us a lot about cell cycle control, and how the cell responds to stress. The authors found that expression of &gt;25% of all yeast genes is linearly correlated with growth rate, independent of the limiting nutrient. They also found that the subset of negatively growth-correlated genes is enriched for peroxisomal functions, and positively correlated genes mainly encode ribosomal functions.\nRespond differently when different nutrients are being limited. If you see particular genes that respond very differently when a nutrient is sharply restricted, these genes might be involved in the transport or metabolism of that specific nutrient.\n\nYou can download the cleaned up version of the data here. The file is called brauer2007_tidy.csv. Later on we’ll actually start with the original raw data (minimally processed) and manipulate it so that we can make it more amenable for analysis.\n\n\n3.1.2 Reading in data\nWe need to load both the dplyr and readr packages for efficiently reading in and displaying this data. We’re also going to use many other functions from the dplyr package. Make sure you have these packages installed as described on the setup chapter (Appendix A).\n\n# Load packages\nlibrary(readr)\nlibrary(dplyr)\n\n# Read in data\nydat &lt;- read_csv(file=\"data/brauer2007_tidy.csv\")\n\n# Display the data\nydat\n\n# Optionally, bring up the data in a viewer window\n# View(ydat)\n\n# A tibble: 198,430 × 7\n   symbol systematic_name nutrient  rate expression bp                     mf   \n   &lt;chr&gt;  &lt;chr&gt;           &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;                  &lt;chr&gt;\n 1 SFB2   YNL049C         Glucose   0.05      -0.24 ER to Golgi transport  mole…\n 2 &lt;NA&gt;   YNL095C         Glucose   0.05       0.28 biological process un… mole…\n 3 QRI7   YDL104C         Glucose   0.05      -0.02 proteolysis and pepti… meta…\n 4 CFT2   YLR115W         Glucose   0.05      -0.33 mRNA polyadenylylatio… RNA …\n 5 SSO2   YMR183C         Glucose   0.05       0.05 vesicle fusion*        t-SN…\n 6 PSP2   YML017W         Glucose   0.05      -0.69 biological process un… mole…\n 7 RIB2   YOL066C         Glucose   0.05      -0.55 riboflavin biosynthes… pseu…\n 8 VMA13  YPR036W         Glucose   0.05      -0.75 vacuolar acidification hydr…\n 9 EDC3   YEL015W         Glucose   0.05      -0.24 deadenylylation-indep… mole…\n10 VPS5   YOR069W         Glucose   0.05      -0.16 protein retention in … prot…\n# ℹ 198,420 more rows"
  },
  {
    "objectID": "dplyr.html#the-dplyr-package",
    "href": "dplyr.html#the-dplyr-package",
    "title": "3  Data Manipulation with dplyr",
    "section": "3.2 The dplyr package",
    "text": "3.2 The dplyr package\nThe dplyr package is a relatively new R package that makes data manipulation fast and easy. It imports functionality from another package called magrittr that allows you to chain commands together into a pipeline that will completely change the way you write R code such that you’re writing code the way you’re thinking about the problem.\nWhen you read in data with the readr package (read_csv()) and you had the dplyr package loaded already, the data frame takes on this “special” class of data frames called a tbl (pronounced “tibble”), which you can see with class(ydat). If you have other “regular” data frames in your workspace, the as_tibble() function will convert it into the special dplyr tbl that displays nicely (e.g.: iris &lt;- as_tibble(iris)). You don’t have to turn all your data frame objects into tibbles, but it does make working with large datasets a bit easier.\nYou can read more about tibbles in Tibbles chapter in R for Data Science or in the tibbles vignette. They keep most of the features of data frames, and drop the features that used to be convenient but are now frustrating (i.e. converting character vectors to factors). You can read more about the differences between data frames and tibbles in this section of the tibbles vignette, but the major convenience for us concerns printing (aka displaying) a tibble to the screen. When you print (i.e., display) a tibble, it only shows the first 10 rows and all the columns that fit on one screen. It also prints an abbreviated description of the column type. You can control the default appearance with options:\n\noptions(tibble.print_max = n, tibble.print_min = m): if there are more than n rows, print only the first m rows. Use options(tibble.print_max = Inf) to always show all rows.\noptions(tibble.width = Inf) will always print all columns, regardless of the width of the screen."
  },
  {
    "objectID": "dplyr.html#dplyr-verbs",
    "href": "dplyr.html#dplyr-verbs",
    "title": "3  Data Manipulation with dplyr",
    "section": "3.3 dplyr verbs",
    "text": "3.3 dplyr verbs\nThe dplyr package gives you a handful of useful verbs for managing data. On their own they don’t do anything that base R can’t do. Here are some of the single-table verbs we’ll be working with in this lesson (single-table meaning that they only work on a single table – contrast that to two-table verbs used for joining data together, which we’ll cover in a later lesson).\n\nfilter()\nselect()\nmutate()\narrange()\nsummarize()\ngroup_by()\n\nThey all take a data frame or tibble as their input for the first argument, and they all return a data frame or tibble as output.\n\n3.3.1 filter()\nIf you want to filter rows of the data where some condition is true, use the filter() function.\n\nThe first argument is the data frame you want to filter, e.g. filter(mydata, ....\nThe second argument is a condition you must satisfy, e.g. filter(ydat, symbol == \"LEU1\"). If you want to satisfy all of multiple conditions, you can use the “and” operator, &. The “or” operator | (the pipe character, usually shift-backslash) will return a subset that meet any of the conditions.\n\n\n==: Equal to\n!=: Not equal to\n&gt;, &gt;=: Greater than, greater than or equal to\n&lt;, &lt;=: Less than, less than or equal to\n\nLet’s try it out. For this to work you have to have already loaded the dplyr package. Let’s take a look at LEU1, a gene involved in leucine synthesis.\n\n# First, make sure you've loaded the dplyr package\nlibrary(dplyr)\n\n# Look at a single gene involved in leucine synthesis pathway\nfilter(ydat, symbol == \"LEU1\")\n\n# A tibble: 36 × 7\n   symbol systematic_name nutrient  rate expression bp                   mf     \n   &lt;chr&gt;  &lt;chr&gt;           &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;                &lt;chr&gt;  \n 1 LEU1   YGL009C         Glucose   0.05      -1.12 leucine biosynthesis 3-isop…\n 2 LEU1   YGL009C         Glucose   0.1       -0.77 leucine biosynthesis 3-isop…\n 3 LEU1   YGL009C         Glucose   0.15      -0.67 leucine biosynthesis 3-isop…\n 4 LEU1   YGL009C         Glucose   0.2       -0.59 leucine biosynthesis 3-isop…\n 5 LEU1   YGL009C         Glucose   0.25      -0.2  leucine biosynthesis 3-isop…\n 6 LEU1   YGL009C         Glucose   0.3        0.03 leucine biosynthesis 3-isop…\n 7 LEU1   YGL009C         Ammonia   0.05      -0.76 leucine biosynthesis 3-isop…\n 8 LEU1   YGL009C         Ammonia   0.1       -1.17 leucine biosynthesis 3-isop…\n 9 LEU1   YGL009C         Ammonia   0.15      -1.2  leucine biosynthesis 3-isop…\n10 LEU1   YGL009C         Ammonia   0.2       -1.02 leucine biosynthesis 3-isop…\n# ℹ 26 more rows\n\n# Optionally, bring that result up in a View window\n# View(filter(ydat, symbol == \"LEU1\"))\n\n# Look at multiple genes\nfilter(ydat, symbol==\"LEU1\" | symbol==\"ADH2\")\n\n# A tibble: 72 × 7\n   symbol systematic_name nutrient  rate expression bp                   mf     \n   &lt;chr&gt;  &lt;chr&gt;           &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;                &lt;chr&gt;  \n 1 LEU1   YGL009C         Glucose   0.05      -1.12 leucine biosynthesis 3-isop…\n 2 ADH2   YMR303C         Glucose   0.05       6.28 fermentation*        alcoho…\n 3 LEU1   YGL009C         Glucose   0.1       -0.77 leucine biosynthesis 3-isop…\n 4 ADH2   YMR303C         Glucose   0.1        5.81 fermentation*        alcoho…\n 5 LEU1   YGL009C         Glucose   0.15      -0.67 leucine biosynthesis 3-isop…\n 6 ADH2   YMR303C         Glucose   0.15       5.64 fermentation*        alcoho…\n 7 LEU1   YGL009C         Glucose   0.2       -0.59 leucine biosynthesis 3-isop…\n 8 ADH2   YMR303C         Glucose   0.2        5.1  fermentation*        alcoho…\n 9 LEU1   YGL009C         Glucose   0.25      -0.2  leucine biosynthesis 3-isop…\n10 ADH2   YMR303C         Glucose   0.25       1.89 fermentation*        alcoho…\n# ℹ 62 more rows\n\n# Look at LEU1 expression at a low growth rate due to nutrient depletion\n# Notice how LEU1 is highly upregulated when leucine is depleted!\nfilter(ydat, symbol==\"LEU1\" & rate==.05)\n\n# A tibble: 6 × 7\n  symbol systematic_name nutrient   rate expression bp                   mf     \n  &lt;chr&gt;  &lt;chr&gt;           &lt;chr&gt;     &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;                &lt;chr&gt;  \n1 LEU1   YGL009C         Glucose    0.05      -1.12 leucine biosynthesis 3-isop…\n2 LEU1   YGL009C         Ammonia    0.05      -0.76 leucine biosynthesis 3-isop…\n3 LEU1   YGL009C         Phosphate  0.05      -0.81 leucine biosynthesis 3-isop…\n4 LEU1   YGL009C         Sulfate    0.05      -1.57 leucine biosynthesis 3-isop…\n5 LEU1   YGL009C         Leucine    0.05       3.84 leucine biosynthesis 3-isop…\n6 LEU1   YGL009C         Uracil     0.05      -2.07 leucine biosynthesis 3-isop…\n\n# But expression goes back down when the growth/nutrient restriction is relaxed\nfilter(ydat, symbol==\"LEU1\" & rate==.3)\n\n# A tibble: 6 × 7\n  symbol systematic_name nutrient   rate expression bp                   mf     \n  &lt;chr&gt;  &lt;chr&gt;           &lt;chr&gt;     &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;                &lt;chr&gt;  \n1 LEU1   YGL009C         Glucose     0.3       0.03 leucine biosynthesis 3-isop…\n2 LEU1   YGL009C         Ammonia     0.3      -0.22 leucine biosynthesis 3-isop…\n3 LEU1   YGL009C         Phosphate   0.3      -0.07 leucine biosynthesis 3-isop…\n4 LEU1   YGL009C         Sulfate     0.3      -0.76 leucine biosynthesis 3-isop…\n5 LEU1   YGL009C         Leucine     0.3       0.87 leucine biosynthesis 3-isop…\n6 LEU1   YGL009C         Uracil      0.3      -0.16 leucine biosynthesis 3-isop…\n\n# Show only stats for LEU1 and Leucine depletion. \n# LEU1 expression starts off high and drops\nfilter(ydat, symbol==\"LEU1\" & nutrient==\"Leucine\")\n\n# A tibble: 6 × 7\n  symbol systematic_name nutrient  rate expression bp                   mf      \n  &lt;chr&gt;  &lt;chr&gt;           &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;                &lt;chr&gt;   \n1 LEU1   YGL009C         Leucine   0.05       3.84 leucine biosynthesis 3-isopr…\n2 LEU1   YGL009C         Leucine   0.1        3.36 leucine biosynthesis 3-isopr…\n3 LEU1   YGL009C         Leucine   0.15       3.24 leucine biosynthesis 3-isopr…\n4 LEU1   YGL009C         Leucine   0.2        2.84 leucine biosynthesis 3-isopr…\n5 LEU1   YGL009C         Leucine   0.25       2.04 leucine biosynthesis 3-isopr…\n6 LEU1   YGL009C         Leucine   0.3        0.87 leucine biosynthesis 3-isopr…\n\n# What about LEU1 expression with other nutrients being depleted?\nfilter(ydat, symbol==\"LEU1\" & nutrient==\"Glucose\")\n\n# A tibble: 6 × 7\n  symbol systematic_name nutrient  rate expression bp                   mf      \n  &lt;chr&gt;  &lt;chr&gt;           &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;                &lt;chr&gt;   \n1 LEU1   YGL009C         Glucose   0.05      -1.12 leucine biosynthesis 3-isopr…\n2 LEU1   YGL009C         Glucose   0.1       -0.77 leucine biosynthesis 3-isopr…\n3 LEU1   YGL009C         Glucose   0.15      -0.67 leucine biosynthesis 3-isopr…\n4 LEU1   YGL009C         Glucose   0.2       -0.59 leucine biosynthesis 3-isopr…\n5 LEU1   YGL009C         Glucose   0.25      -0.2  leucine biosynthesis 3-isopr…\n6 LEU1   YGL009C         Glucose   0.3        0.03 leucine biosynthesis 3-isopr…\n\n\nLet’s look at this graphically. Don’t worry about what these commands are doing just yet - we’ll cover that later on when we talk about ggplot2. Here’s I’m taking the filtered dataset containing just expression estimates for LEU1 where I have 36 rows (one for each of 6 nutrients \\(\\times\\) 6 growth rates), and I’m piping that dataset to the plotting function, where I’m plotting rate on the x-axis, expression on the y-axis, mapping the value of nutrient to the color, and using a line plot to display the data.\n\nlibrary(ggplot2)\nfilter(ydat, symbol==\"LEU1\") |&gt; \n  ggplot(aes(rate, expression, colour=nutrient)) + geom_line(lwd=1.5)\n\n\n\n\n\n\n\n\nLook closely at that! LEU1 is highly expressed when starved of leucine because the cell has to synthesize its own! And as the amount of leucine in the environment (the growth rate) increases, the cell can worry less about synthesizing leucine, so LEU1 expression goes back down. Consequently the cell can devote more energy into other functions, and we see other genes’ expression very slightly raising.\n\n\n\n\n\n\nExercise 1\n\n\n\n\nDisplay the data where the gene ontology biological process (the bp variable) is “leucine biosynthesis” (case-sensitive) and the limiting nutrient was Leucine. (Answer should return a 24-by-7 data frame – 4 genes \\(\\times\\) 6 growth rates).\nGene/rate combinations had high expression (in the top 1% of expressed genes)? Hint: see ?quantile and try quantile(ydat$expression, probs=.99) to see the expression value which is higher than 99% of all the data, then filter() based on that. Try wrapping your answer with a View() function so you can see the whole thing. What does it look like those genes are doing? Answer should return a 1971-by-7 data frame.\n\n\n\n\n3.3.1.1 Aside: Writing Data to File\nWhat we’ve done up to this point is read in data from a file (read_csv(...)), and assigning that to an object in our workspace (ydat &lt;- ...). When we run operations like filter() on our data, consider two things:\n\nThe ydat object in our workspace is not being modified directly. That is, we can filter(ydat, ...), and a result is returned to the screen, but ydat remains the same. This effect is similar to what we demonstrated in our first session.\n\n\n# Assign the value '50' to the weight object.\nweight &lt;- 50\n\n# Print out weight to the screen (50)\nweight\n\n# What's the value of weight plus 10?\nweight + 10\n\n# Weight is still 50\nweight\n\n# Weight is only modified if we *reassign* weight to the modified value\nweight &lt;- weight+10\n# Weight is now 60\nweight\n\n\nMore importantly, the data file on disk (data/brauer2007_tidy.csv) is never modified. No matter what we do to ydat, the file is never modified. If we want to save the result of an operation to a file on disk, we can assign the result of an operation to an object, and write_csv that object to disk. See the help for ?write_csv (note, write_csv() with an underscore is part of the readr package – not to be confused with the built-in write.csv() function).\n\n\n# What's the result of this filter operation?\nfilter(ydat, nutrient==\"Leucine\" & bp==\"leucine biosynthesis\")\n\n# Assign the result to a new object\nleudat &lt;- filter(ydat, nutrient==\"Leucine\" & bp==\"leucine biosynthesis\")\n\n# Write that out to disk\nwrite_csv(leudat, \"leucinedata.csv\")\n\nNote that this is different than saving your entire workspace to an Rdata file, which would contain all the objects we’ve created (weight, ydat, leudat, etc).\n\n\n\n3.3.2 select()\nThe filter() function allows you to return only certain rows matching a condition. The select() function returns only certain columns. The first argument is the data, and subsequent arguments are the columns you want.\n\n# Select just the symbol and systematic_name\nselect(ydat, symbol, systematic_name)\n\n# A tibble: 198,430 × 2\n   symbol systematic_name\n   &lt;chr&gt;  &lt;chr&gt;          \n 1 SFB2   YNL049C        \n 2 &lt;NA&gt;   YNL095C        \n 3 QRI7   YDL104C        \n 4 CFT2   YLR115W        \n 5 SSO2   YMR183C        \n 6 PSP2   YML017W        \n 7 RIB2   YOL066C        \n 8 VMA13  YPR036W        \n 9 EDC3   YEL015W        \n10 VPS5   YOR069W        \n# ℹ 198,420 more rows\n\n# Alternatively, just remove columns. Remove the bp and mf columns.\nselect(ydat, -bp, -mf)\n\n# A tibble: 198,430 × 5\n   symbol systematic_name nutrient  rate expression\n   &lt;chr&gt;  &lt;chr&gt;           &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n 1 SFB2   YNL049C         Glucose   0.05      -0.24\n 2 &lt;NA&gt;   YNL095C         Glucose   0.05       0.28\n 3 QRI7   YDL104C         Glucose   0.05      -0.02\n 4 CFT2   YLR115W         Glucose   0.05      -0.33\n 5 SSO2   YMR183C         Glucose   0.05       0.05\n 6 PSP2   YML017W         Glucose   0.05      -0.69\n 7 RIB2   YOL066C         Glucose   0.05      -0.55\n 8 VMA13  YPR036W         Glucose   0.05      -0.75\n 9 EDC3   YEL015W         Glucose   0.05      -0.24\n10 VPS5   YOR069W         Glucose   0.05      -0.16\n# ℹ 198,420 more rows\n\n# Notice that the original data doesn't change!\nydat\n\n# A tibble: 198,430 × 7\n   symbol systematic_name nutrient  rate expression bp                     mf   \n   &lt;chr&gt;  &lt;chr&gt;           &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;                  &lt;chr&gt;\n 1 SFB2   YNL049C         Glucose   0.05      -0.24 ER to Golgi transport  mole…\n 2 &lt;NA&gt;   YNL095C         Glucose   0.05       0.28 biological process un… mole…\n 3 QRI7   YDL104C         Glucose   0.05      -0.02 proteolysis and pepti… meta…\n 4 CFT2   YLR115W         Glucose   0.05      -0.33 mRNA polyadenylylatio… RNA …\n 5 SSO2   YMR183C         Glucose   0.05       0.05 vesicle fusion*        t-SN…\n 6 PSP2   YML017W         Glucose   0.05      -0.69 biological process un… mole…\n 7 RIB2   YOL066C         Glucose   0.05      -0.55 riboflavin biosynthes… pseu…\n 8 VMA13  YPR036W         Glucose   0.05      -0.75 vacuolar acidification hydr…\n 9 EDC3   YEL015W         Glucose   0.05      -0.24 deadenylylation-indep… mole…\n10 VPS5   YOR069W         Glucose   0.05      -0.16 protein retention in … prot…\n# ℹ 198,420 more rows\n\n\nNotice above how the original data doesn’t change. We’re selecting out only certain columns of interest and throwing away columns we don’t care about. If we wanted to keep this data, we would need to reassign the result of the select() operation to a new object. Let’s make a new object called nogo that does not contain the GO annotations. Notice again how the original data is unchanged.\n\n# create a new dataset without the go annotations.\nnogo &lt;- select(ydat, -bp, -mf)\nnogo\n\n# A tibble: 198,430 × 5\n   symbol systematic_name nutrient  rate expression\n   &lt;chr&gt;  &lt;chr&gt;           &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n 1 SFB2   YNL049C         Glucose   0.05      -0.24\n 2 &lt;NA&gt;   YNL095C         Glucose   0.05       0.28\n 3 QRI7   YDL104C         Glucose   0.05      -0.02\n 4 CFT2   YLR115W         Glucose   0.05      -0.33\n 5 SSO2   YMR183C         Glucose   0.05       0.05\n 6 PSP2   YML017W         Glucose   0.05      -0.69\n 7 RIB2   YOL066C         Glucose   0.05      -0.55\n 8 VMA13  YPR036W         Glucose   0.05      -0.75\n 9 EDC3   YEL015W         Glucose   0.05      -0.24\n10 VPS5   YOR069W         Glucose   0.05      -0.16\n# ℹ 198,420 more rows\n\n# we could filter this new dataset\nfilter(nogo, symbol==\"LEU1\" & rate==.05)\n\n# A tibble: 6 × 5\n  symbol systematic_name nutrient   rate expression\n  &lt;chr&gt;  &lt;chr&gt;           &lt;chr&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1 LEU1   YGL009C         Glucose    0.05      -1.12\n2 LEU1   YGL009C         Ammonia    0.05      -0.76\n3 LEU1   YGL009C         Phosphate  0.05      -0.81\n4 LEU1   YGL009C         Sulfate    0.05      -1.57\n5 LEU1   YGL009C         Leucine    0.05       3.84\n6 LEU1   YGL009C         Uracil     0.05      -2.07\n\n# Notice how the original data is unchanged - still have all 7 columns\nydat\n\n# A tibble: 198,430 × 7\n   symbol systematic_name nutrient  rate expression bp                     mf   \n   &lt;chr&gt;  &lt;chr&gt;           &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;                  &lt;chr&gt;\n 1 SFB2   YNL049C         Glucose   0.05      -0.24 ER to Golgi transport  mole…\n 2 &lt;NA&gt;   YNL095C         Glucose   0.05       0.28 biological process un… mole…\n 3 QRI7   YDL104C         Glucose   0.05      -0.02 proteolysis and pepti… meta…\n 4 CFT2   YLR115W         Glucose   0.05      -0.33 mRNA polyadenylylatio… RNA …\n 5 SSO2   YMR183C         Glucose   0.05       0.05 vesicle fusion*        t-SN…\n 6 PSP2   YML017W         Glucose   0.05      -0.69 biological process un… mole…\n 7 RIB2   YOL066C         Glucose   0.05      -0.55 riboflavin biosynthes… pseu…\n 8 VMA13  YPR036W         Glucose   0.05      -0.75 vacuolar acidification hydr…\n 9 EDC3   YEL015W         Glucose   0.05      -0.24 deadenylylation-indep… mole…\n10 VPS5   YOR069W         Glucose   0.05      -0.16 protein retention in … prot…\n# ℹ 198,420 more rows\n\n\n\n\n3.3.3 mutate()\nThe mutate() function adds new columns to the data. Remember, it doesn’t actually modify the data frame you’re operating on, and the result is transient unless you assign it to a new object or reassign it back to itself (generally, not always a good practice).\nThe expression level reported here is the \\(log_2\\) of the sample signal divided by the signal in the reference channel, where the reference RNA for all samples was taken from the glucose-limited chemostat grown at a dilution rate of 0.25 \\(h^{-1}\\). Let’s mutate this data to add a new variable called “signal” that’s the actual raw signal ratio instead of the log-transformed signal.\n\nmutate(nogo, signal=2^expression)\n\nMutate has a nice little feature too in that it’s “lazy.” You can mutate and add one variable, then continue mutating to add more variables based on that variable. Let’s make another column that’s the square root of the signal ratio.\n\nmutate(nogo, signal=2^expression, sigsr=sqrt(signal))\n\n# A tibble: 198,430 × 7\n   symbol systematic_name nutrient  rate expression signal sigsr\n   &lt;chr&gt;  &lt;chr&gt;           &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 SFB2   YNL049C         Glucose   0.05      -0.24  0.847 0.920\n 2 &lt;NA&gt;   YNL095C         Glucose   0.05       0.28  1.21  1.10 \n 3 QRI7   YDL104C         Glucose   0.05      -0.02  0.986 0.993\n 4 CFT2   YLR115W         Glucose   0.05      -0.33  0.796 0.892\n 5 SSO2   YMR183C         Glucose   0.05       0.05  1.04  1.02 \n 6 PSP2   YML017W         Glucose   0.05      -0.69  0.620 0.787\n 7 RIB2   YOL066C         Glucose   0.05      -0.55  0.683 0.826\n 8 VMA13  YPR036W         Glucose   0.05      -0.75  0.595 0.771\n 9 EDC3   YEL015W         Glucose   0.05      -0.24  0.847 0.920\n10 VPS5   YOR069W         Glucose   0.05      -0.16  0.895 0.946\n# ℹ 198,420 more rows\n\n\nAgain, don’t worry about the code here to make the plot – we’ll learn about this later. Why do you think we log-transform the data prior to analysis?\n\nlibrary(tidyr)\nmutate(nogo, signal=2^expression, sigsr=sqrt(signal)) |&gt; \n  gather(unit, value, expression:sigsr) |&gt; \n  ggplot(aes(value)) + geom_histogram(bins=100) + facet_wrap(~unit, scales=\"free\")\n\n\n\n\n\n\n3.3.4 arrange()\nThe arrange() function does what it sounds like. It takes a data frame or tbl and arranges (or sorts) by column(s) of interest. The first argument is the data, and subsequent arguments are columns to sort on. Use the desc() function to arrange by descending.\n\n# arrange by gene symbol\narrange(ydat, symbol)\n\n# A tibble: 198,430 × 7\n   symbol systematic_name nutrient  rate expression bp                   mf     \n   &lt;chr&gt;  &lt;chr&gt;           &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;                &lt;chr&gt;  \n 1 AAC1   YMR056C         Glucose   0.05       1.5  aerobic respiration* ATP:AD…\n 2 AAC1   YMR056C         Glucose   0.1        1.54 aerobic respiration* ATP:AD…\n 3 AAC1   YMR056C         Glucose   0.15       1.16 aerobic respiration* ATP:AD…\n 4 AAC1   YMR056C         Glucose   0.2        1.04 aerobic respiration* ATP:AD…\n 5 AAC1   YMR056C         Glucose   0.25       0.84 aerobic respiration* ATP:AD…\n 6 AAC1   YMR056C         Glucose   0.3        0.01 aerobic respiration* ATP:AD…\n 7 AAC1   YMR056C         Ammonia   0.05       0.8  aerobic respiration* ATP:AD…\n 8 AAC1   YMR056C         Ammonia   0.1        1.47 aerobic respiration* ATP:AD…\n 9 AAC1   YMR056C         Ammonia   0.15       0.97 aerobic respiration* ATP:AD…\n10 AAC1   YMR056C         Ammonia   0.2        0.76 aerobic respiration* ATP:AD…\n# ℹ 198,420 more rows\n\n# arrange by expression (default: increasing)\narrange(ydat, expression)\n\n# A tibble: 198,430 × 7\n   symbol systematic_name nutrient   rate expression bp                    mf   \n   &lt;chr&gt;  &lt;chr&gt;           &lt;chr&gt;     &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;                 &lt;chr&gt;\n 1 SUL1   YBR294W         Phosphate  0.05      -6.5  sulfate transport     sulf…\n 2 SUL1   YBR294W         Phosphate  0.1       -6.34 sulfate transport     sulf…\n 3 ADH2   YMR303C         Phosphate  0.1       -6.15 fermentation*         alco…\n 4 ADH2   YMR303C         Phosphate  0.3       -6.04 fermentation*         alco…\n 5 ADH2   YMR303C         Phosphate  0.25      -5.89 fermentation*         alco…\n 6 SUL1   YBR294W         Uracil     0.05      -5.55 sulfate transport     sulf…\n 7 SFC1   YJR095W         Phosphate  0.2       -5.52 fumarate transport*   succ…\n 8 JEN1   YKL217W         Phosphate  0.3       -5.44 lactate transport     lact…\n 9 MHT1   YLL062C         Phosphate  0.05      -5.36 sulfur amino acid me… homo…\n10 SFC1   YJR095W         Phosphate  0.25      -5.35 fumarate transport*   succ…\n# ℹ 198,420 more rows\n\n# arrange by decreasing expression\narrange(ydat, desc(expression))\n\n# A tibble: 198,430 × 7\n   symbol systematic_name nutrient   rate expression bp                    mf   \n   &lt;chr&gt;  &lt;chr&gt;           &lt;chr&gt;     &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;                 &lt;chr&gt;\n 1 GAP1   YKR039W         Ammonia    0.05       6.64 amino acid transport* L-pr…\n 2 DAL5   YJR152W         Ammonia    0.05       6.64 allantoate transport  alla…\n 3 GAP1   YKR039W         Ammonia    0.1        6.64 amino acid transport* L-pr…\n 4 DAL5   YJR152W         Ammonia    0.1        6.64 allantoate transport  alla…\n 5 DAL5   YJR152W         Ammonia    0.15       6.64 allantoate transport  alla…\n 6 DAL5   YJR152W         Ammonia    0.2        6.64 allantoate transport  alla…\n 7 DAL5   YJR152W         Ammonia    0.25       6.64 allantoate transport  alla…\n 8 DAL5   YJR152W         Ammonia    0.3        6.64 allantoate transport  alla…\n 9 GIT1   YCR098C         Phosphate  0.05       6.64 glycerophosphodieste… glyc…\n10 PHM6   YDR281C         Phosphate  0.05       6.64 biological process u… mole…\n# ℹ 198,420 more rows\n\n\n\n\n\n\n\n\nExercise 2\n\n\n\n\nFirst, re-run the command you used above to filter the data for genes involved in the “leucine biosynthesis” biological process and where the limiting nutrient is Leucine.\nWrap this entire filtered result with a call to arrange() where you’ll arrange the result of #1 by the gene symbol.\nWrap this entire result in a View() statement so you can see the entire result.\n\n\n\n\n\n3.3.5 summarize()\nThe summarize() function summarizes multiple values to a single value. On its own the summarize() function doesn’t seem to be all that useful. The dplyr package provides a few convenience functions called n() and n_distinct() that tell you the number of observations or the number of distinct values of a particular variable.\nNotice that summarize takes a data frame and returns a data frame. In this case it’s a 1x1 data frame with a single row and a single column. The name of the column, by default is whatever the expression was used to summarize the data. This usually isn’t pretty, and if we wanted to work with this resulting data frame later on, we’d want to name that returned value something easier to deal with.\n\n# Get the mean expression for all genes\nsummarize(ydat, mean(expression))\n\n# A tibble: 1 × 1\n  `mean(expression)`\n               &lt;dbl&gt;\n1            0.00337\n\n# Use a more friendly name, e.g., meanexp, or whatever you want to call it.\nsummarize(ydat, meanexp=mean(expression))\n\n# A tibble: 1 × 1\n  meanexp\n    &lt;dbl&gt;\n1 0.00337\n\n# Measure the correlation between rate and expression \nsummarize(ydat, r=cor(rate, expression))\n\n# A tibble: 1 × 1\n        r\n    &lt;dbl&gt;\n1 -0.0220\n\n# Get the number of observations\nsummarize(ydat, n())\n\n# A tibble: 1 × 1\n   `n()`\n   &lt;int&gt;\n1 198430\n\n# The number of distinct gene symbols in the data \nsummarize(ydat, n_distinct(symbol))\n\n# A tibble: 1 × 1\n  `n_distinct(symbol)`\n                 &lt;int&gt;\n1                 4211\n\n\n\n\n3.3.6 group_by()\nWe saw that summarize() isn’t that useful on its own. Neither is group_by() All this does is takes an existing data frame and coverts it into a grouped data frame where operations are performed by group.\n\nydat\n\n# A tibble: 198,430 × 7\n   symbol systematic_name nutrient  rate expression bp                     mf   \n   &lt;chr&gt;  &lt;chr&gt;           &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;                  &lt;chr&gt;\n 1 SFB2   YNL049C         Glucose   0.05      -0.24 ER to Golgi transport  mole…\n 2 &lt;NA&gt;   YNL095C         Glucose   0.05       0.28 biological process un… mole…\n 3 QRI7   YDL104C         Glucose   0.05      -0.02 proteolysis and pepti… meta…\n 4 CFT2   YLR115W         Glucose   0.05      -0.33 mRNA polyadenylylatio… RNA …\n 5 SSO2   YMR183C         Glucose   0.05       0.05 vesicle fusion*        t-SN…\n 6 PSP2   YML017W         Glucose   0.05      -0.69 biological process un… mole…\n 7 RIB2   YOL066C         Glucose   0.05      -0.55 riboflavin biosynthes… pseu…\n 8 VMA13  YPR036W         Glucose   0.05      -0.75 vacuolar acidification hydr…\n 9 EDC3   YEL015W         Glucose   0.05      -0.24 deadenylylation-indep… mole…\n10 VPS5   YOR069W         Glucose   0.05      -0.16 protein retention in … prot…\n# ℹ 198,420 more rows\n\ngroup_by(ydat, nutrient)\n\n# A tibble: 198,430 × 7\n# Groups:   nutrient [6]\n   symbol systematic_name nutrient  rate expression bp                     mf   \n   &lt;chr&gt;  &lt;chr&gt;           &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;                  &lt;chr&gt;\n 1 SFB2   YNL049C         Glucose   0.05      -0.24 ER to Golgi transport  mole…\n 2 &lt;NA&gt;   YNL095C         Glucose   0.05       0.28 biological process un… mole…\n 3 QRI7   YDL104C         Glucose   0.05      -0.02 proteolysis and pepti… meta…\n 4 CFT2   YLR115W         Glucose   0.05      -0.33 mRNA polyadenylylatio… RNA …\n 5 SSO2   YMR183C         Glucose   0.05       0.05 vesicle fusion*        t-SN…\n 6 PSP2   YML017W         Glucose   0.05      -0.69 biological process un… mole…\n 7 RIB2   YOL066C         Glucose   0.05      -0.55 riboflavin biosynthes… pseu…\n 8 VMA13  YPR036W         Glucose   0.05      -0.75 vacuolar acidification hydr…\n 9 EDC3   YEL015W         Glucose   0.05      -0.24 deadenylylation-indep… mole…\n10 VPS5   YOR069W         Glucose   0.05      -0.16 protein retention in … prot…\n# ℹ 198,420 more rows\n\ngroup_by(ydat, nutrient, rate)\n\n# A tibble: 198,430 × 7\n# Groups:   nutrient, rate [36]\n   symbol systematic_name nutrient  rate expression bp                     mf   \n   &lt;chr&gt;  &lt;chr&gt;           &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;                  &lt;chr&gt;\n 1 SFB2   YNL049C         Glucose   0.05      -0.24 ER to Golgi transport  mole…\n 2 &lt;NA&gt;   YNL095C         Glucose   0.05       0.28 biological process un… mole…\n 3 QRI7   YDL104C         Glucose   0.05      -0.02 proteolysis and pepti… meta…\n 4 CFT2   YLR115W         Glucose   0.05      -0.33 mRNA polyadenylylatio… RNA …\n 5 SSO2   YMR183C         Glucose   0.05       0.05 vesicle fusion*        t-SN…\n 6 PSP2   YML017W         Glucose   0.05      -0.69 biological process un… mole…\n 7 RIB2   YOL066C         Glucose   0.05      -0.55 riboflavin biosynthes… pseu…\n 8 VMA13  YPR036W         Glucose   0.05      -0.75 vacuolar acidification hydr…\n 9 EDC3   YEL015W         Glucose   0.05      -0.24 deadenylylation-indep… mole…\n10 VPS5   YOR069W         Glucose   0.05      -0.16 protein retention in … prot…\n# ℹ 198,420 more rows\n\n\nThe real power comes in where group_by() and summarize() are used together. First, write the group_by() statement. Then wrap the result of that with a call to summarize().\n\n# Get the mean expression for each gene\n# group_by(ydat, symbol)\nsummarize(group_by(ydat, symbol), meanexp=mean(expression))\n\n# A tibble: 4,211 × 2\n   symbol  meanexp\n   &lt;chr&gt;     &lt;dbl&gt;\n 1 AAC1    0.529  \n 2 AAC3   -0.216  \n 3 AAD10   0.438  \n 4 AAD14  -0.0717 \n 5 AAD16   0.242  \n 6 AAD4   -0.792  \n 7 AAD6    0.290  \n 8 AAH1    0.0461 \n 9 AAP1   -0.00361\n10 AAP1'  -0.421  \n# ℹ 4,201 more rows\n\n# Get the correlation between rate and expression for each nutrient\n# group_by(ydat, nutrient)\nsummarize(group_by(ydat, nutrient), r=cor(rate, expression))\n\n# A tibble: 6 × 2\n  nutrient        r\n  &lt;chr&gt;       &lt;dbl&gt;\n1 Ammonia   -0.0175\n2 Glucose   -0.0112\n3 Leucine   -0.0384\n4 Phosphate -0.0194\n5 Sulfate   -0.0166\n6 Uracil    -0.0353"
  },
  {
    "objectID": "dplyr.html#the-pipe",
    "href": "dplyr.html#the-pipe",
    "title": "3  Data Manipulation with dplyr",
    "section": "3.4 The pipe: |>",
    "text": "3.4 The pipe: |&gt;\n\n3.4.1 How |&gt; works\nThis is where things get awesome. The dplyr package imports functionality from the magrittr package that lets you pipe the output of one function to the input of another, so you can avoid nesting functions. It looks like this: |&gt;. You don’t have to load the magrittr package to use it since dplyr imports its functionality when you load the dplyr package.\nHere’s the simplest way to use it. Remember the tail() function. It expects a data frame as input, and the next argument is the number of lines to print. These two commands are identical:\n\ntail(ydat, 5)\n\n# A tibble: 5 × 7\n  symbol systematic_name nutrient  rate expression bp                      mf   \n  &lt;chr&gt;  &lt;chr&gt;           &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;                   &lt;chr&gt;\n1 KRE1   YNL322C         Uracil     0.3       0.28 cell wall organization… stru…\n2 MTL1   YGR023W         Uracil     0.3       0.27 cell wall organization… mole…\n3 KRE9   YJL174W         Uracil     0.3       0.43 cell wall organization… mole…\n4 UTH1   YKR042W         Uracil     0.3       0.19 mitochondrion organiza… mole…\n5 &lt;NA&gt;   YOL111C         Uracil     0.3       0.04 biological process unk… mole…\n\nydat |&gt; tail(5)\n\n# A tibble: 5 × 7\n  symbol systematic_name nutrient  rate expression bp                      mf   \n  &lt;chr&gt;  &lt;chr&gt;           &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;                   &lt;chr&gt;\n1 KRE1   YNL322C         Uracil     0.3       0.28 cell wall organization… stru…\n2 MTL1   YGR023W         Uracil     0.3       0.27 cell wall organization… mole…\n3 KRE9   YJL174W         Uracil     0.3       0.43 cell wall organization… mole…\n4 UTH1   YKR042W         Uracil     0.3       0.19 mitochondrion organiza… mole…\n5 &lt;NA&gt;   YOL111C         Uracil     0.3       0.04 biological process unk… mole…\n\n\nLet’s use one of the dplyr verbs.\n\nfilter(ydat, nutrient==\"Leucine\")\n\n# A tibble: 33,178 × 7\n   symbol systematic_name nutrient  rate expression bp                     mf   \n   &lt;chr&gt;  &lt;chr&gt;           &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;                  &lt;chr&gt;\n 1 SFB2   YNL049C         Leucine   0.05       0.18 ER to Golgi transport  mole…\n 2 &lt;NA&gt;   YNL095C         Leucine   0.05       0.16 biological process un… mole…\n 3 QRI7   YDL104C         Leucine   0.05      -0.3  proteolysis and pepti… meta…\n 4 CFT2   YLR115W         Leucine   0.05      -0.27 mRNA polyadenylylatio… RNA …\n 5 SSO2   YMR183C         Leucine   0.05      -0.59 vesicle fusion*        t-SN…\n 6 PSP2   YML017W         Leucine   0.05      -0.17 biological process un… mole…\n 7 RIB2   YOL066C         Leucine   0.05      -0.02 riboflavin biosynthes… pseu…\n 8 VMA13  YPR036W         Leucine   0.05      -0.11 vacuolar acidification hydr…\n 9 EDC3   YEL015W         Leucine   0.05       0.12 deadenylylation-indep… mole…\n10 VPS5   YOR069W         Leucine   0.05      -0.2  protein retention in … prot…\n# ℹ 33,168 more rows\n\nydat |&gt; filter(nutrient==\"Leucine\")\n\n# A tibble: 33,178 × 7\n   symbol systematic_name nutrient  rate expression bp                     mf   \n   &lt;chr&gt;  &lt;chr&gt;           &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;                  &lt;chr&gt;\n 1 SFB2   YNL049C         Leucine   0.05       0.18 ER to Golgi transport  mole…\n 2 &lt;NA&gt;   YNL095C         Leucine   0.05       0.16 biological process un… mole…\n 3 QRI7   YDL104C         Leucine   0.05      -0.3  proteolysis and pepti… meta…\n 4 CFT2   YLR115W         Leucine   0.05      -0.27 mRNA polyadenylylatio… RNA …\n 5 SSO2   YMR183C         Leucine   0.05      -0.59 vesicle fusion*        t-SN…\n 6 PSP2   YML017W         Leucine   0.05      -0.17 biological process un… mole…\n 7 RIB2   YOL066C         Leucine   0.05      -0.02 riboflavin biosynthes… pseu…\n 8 VMA13  YPR036W         Leucine   0.05      -0.11 vacuolar acidification hydr…\n 9 EDC3   YEL015W         Leucine   0.05       0.12 deadenylylation-indep… mole…\n10 VPS5   YOR069W         Leucine   0.05      -0.2  protein retention in … prot…\n# ℹ 33,168 more rows\n\n\n\n\n3.4.2 Nesting versus |&gt;\nSo what?\nNow, think about this for a minute. What if we wanted to get the correlation between the growth rate and expression separately for each limiting nutrient only for genes in the leucine biosynthesis pathway, and return a sorted list of those correlation coeffients rounded to two digits? Mentally we would do something like this:\n\nTake the ydat dataset\nthen filter() it for genes in the leucine biosynthesis pathway\nthen group_by() the limiting nutrient\nthen summarize() to get the correlation (cor()) between rate and expression\nthen mutate() to round the result of the above calculation to two significant digits\nthen arrange() by the rounded correlation coefficient above\n\nBut in code, it gets ugly. First, take the ydat dataset\n\nydat\n\nthen filter() it for genes in the leucine biosynthesis pathway\n\nfilter(ydat, bp==\"leucine biosynthesis\")\n\nthen group_by() the limiting nutrient\n\ngroup_by(filter(ydat, bp==\"leucine biosynthesis\"), nutrient)\n\nthen summarize() to get the correlation (cor()) between rate and expression\n\nsummarize(group_by(filter(ydat, bp == \"leucine biosynthesis\"), nutrient), r = cor(rate,\n    expression))\n\nthen mutate() to round the result of the above calculation to two significant digits\n\nmutate(summarize(group_by(filter(ydat, bp == \"leucine biosynthesis\"), nutrient),\n    r = cor(rate, expression)), r = round(r, 2))\n\nthen arrange() by the rounded correlation coefficient above\n\narrange(\n  mutate(\n    summarize(\n      group_by(\n        filter(ydat, bp==\"leucine biosynthesis\"), \n      nutrient), \n    r=cor(rate, expression)), \n  r=round(r, 2)), \nr)\n\n# A tibble: 6 × 2\n  nutrient      r\n  &lt;chr&gt;     &lt;dbl&gt;\n1 Leucine   -0.58\n2 Glucose   -0.04\n3 Ammonia    0.16\n4 Sulfate    0.33\n5 Phosphate  0.44\n6 Uracil     0.58\n\n\nNow compare that with the mental process of what you’re actually trying to accomplish. The way you would do this without pipes is completely inside-out and backwards from the way you express in words and in thought what you want to do. The pipe operator |&gt; allows you to pass the output data frame from one function to the input data frame to another function.\n\n\n\nNesting functions versus piping\n\n\nThis is how we would do that in code. It’s as simple as replacing the word “then” in words to the symbol |&gt; in code. (There’s a keyboard shortcut that I’ll use frequently to insert the |&gt; sequence – you can see what it is by clicking the Tools menu in RStudio, then selecting Keyboard Shortcut Help. On Mac, it’s CMD-SHIFT-M.)\n\nydat |&gt; \n  filter(bp==\"leucine biosynthesis\") |&gt;\n  group_by(nutrient) |&gt; \n  summarize(r=cor(rate, expression)) |&gt; \n  mutate(r=round(r,2)) |&gt; \n  arrange(r)\n\n# A tibble: 6 × 2\n  nutrient      r\n  &lt;chr&gt;     &lt;dbl&gt;\n1 Leucine   -0.58\n2 Glucose   -0.04\n3 Ammonia    0.16\n4 Sulfate    0.33\n5 Phosphate  0.44\n6 Uracil     0.58"
  },
  {
    "objectID": "dplyr.html#exercises",
    "href": "dplyr.html#exercises",
    "title": "3  Data Manipulation with dplyr",
    "section": "3.5 Exercises",
    "text": "3.5 Exercises\nHere’s a warm-up round. Try the following.\n\n\n\n\n\n\nExercise 3\n\n\n\nShow the limiting nutrient and expression values for the gene ADH2 when the growth rate is restricted to 0.05. Hint: 2 pipes: filter and select.\n\n\n# A tibble: 6 × 2\n  nutrient  expression\n  &lt;chr&gt;          &lt;dbl&gt;\n1 Glucose         6.28\n2 Ammonia         0.55\n3 Phosphate      -4.6 \n4 Sulfate        -1.18\n5 Leucine         4.15\n6 Uracil          0.63\n\n\n\n\n\n\n\n\n\n\nExercise 4\n\n\n\nWhat are the four most highly expressed genes when the growth rate is restricted to 0.05 by restricting glucose? Show only the symbol, expression value, and GO terms. Hint: 4 pipes: filter, arrange, head, and select.\n\n\n# A tibble: 4 × 4\n  symbol expression bp                  mf                            \n  &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;                         \n1 ADH2         6.28 fermentation*       alcohol dehydrogenase activity\n2 HSP26        5.86 response to stress* unfolded protein binding      \n3 MLS1         5.64 glyoxylate cycle    malate synthase activity      \n4 HXT5         5.56 hexose transport    glucose transporter activity* \n\n\n\n\n\n\n\n\n\n\nExercise 5\n\n\n\nWhen the growth rate is restricted to 0.05, what is the average expression level across all genes in the “response to stress” biological process, separately for each limiting nutrient? What about genes in the “protein biosynthesis” biological process? Hint: 3 pipes: filter, group_by, summarize.\n\n\n# A tibble: 6 × 2\n  nutrient  meanexp\n  &lt;chr&gt;       &lt;dbl&gt;\n1 Ammonia     0.943\n2 Glucose     0.743\n3 Leucine     0.811\n4 Phosphate   0.981\n5 Sulfate     0.743\n6 Uracil      0.731\n\n\n# A tibble: 6 × 2\n  nutrient  meanexp\n  &lt;chr&gt;       &lt;dbl&gt;\n1 Ammonia    -1.61 \n2 Glucose    -0.691\n3 Leucine    -0.574\n4 Phosphate  -0.750\n5 Sulfate    -0.913\n6 Uracil     -0.880\n\n\n\n\nThat was easy, right? How about some tougher ones.\n\n\n\n\n\n\nExercise 6\n\n\n\nFirst, some review. How do we see the number of distinct values of a variable? Use n_distinct() within a summarize() call.\n\nydat |&gt; summarize(n_distinct(mf))\n\n# A tibble: 1 × 1\n  `n_distinct(mf)`\n             &lt;int&gt;\n1             1086\n\n\n\n\n\n\n\n\n\n\nExercise 7\n\n\n\nWhich 10 biological process annotations have the most genes associated with them? What about molecular functions? Hint: 4 pipes: group_by, summarize with n_distinct, arrange, head.\n\n\n# A tibble: 10 × 2\n   bp                                                               n\n   &lt;chr&gt;                                                        &lt;int&gt;\n 1 biological process unknown                                     269\n 2 protein biosynthesis                                           182\n 3 protein amino acid phosphorylation*                             78\n 4 protein biosynthesis*                                           73\n 5 cell wall organization and biogenesis*                          64\n 6 regulation of transcription from RNA polymerase II promoter*    49\n 7 nuclear mRNA splicing, via spliceosome                          47\n 8 DNA repair*                                                     44\n 9 ER to Golgi transport*                                          42\n10 aerobic respiration*                                            42\n\n\n# A tibble: 10 × 2\n   mf                                         n\n   &lt;chr&gt;                                  &lt;int&gt;\n 1 molecular function unknown               886\n 2 structural constituent of ribosome       185\n 3 protein binding                          107\n 4 RNA binding                               63\n 5 protein binding*                          53\n 6 DNA binding*                              44\n 7 structural molecule activity              43\n 8 GTPase activity                           40\n 9 structural constituent of cytoskeleton    39\n10 transcription factor activity             38\n\n\n\n\n\n\n\n\n\n\nExercise 8\n\n\n\nHow many distinct genes are there where we know what process the gene is involved in but we don’t know what it does? Hint: 3 pipes; filter where bp!=\"biological process unknown\" & mf==\"molecular function unknown\", and after selecting columns of interest, pipe the output to distinct(). The answer should be 737, and here are a few:\n\n\n# A tibble: 737 × 3\n   symbol bp                                                              mf    \n   &lt;chr&gt;  &lt;chr&gt;                                                           &lt;chr&gt; \n 1 SFB2   ER to Golgi transport                                           molec…\n 2 EDC3   deadenylylation-independent decapping                           molec…\n 3 PER1   response to unfolded protein*                                   molec…\n 4 PEX25  peroxisome organization and biogenesis*                         molec…\n 5 BNI5   cytokinesis*                                                    molec…\n 6 CSN12  adaptation to pheromone during conjugation with cellular fusion molec…\n 7 SEC39  secretory pathway                                               molec…\n 8 ABC1   ubiquinone biosynthesis                                         molec…\n 9 PRP46  nuclear mRNA splicing, via spliceosome                          molec…\n10 MAM3   mitochondrion organization and biogenesis*                      molec…\n# ℹ 727 more rows\n\n\n\n\n\n\n\n\n\n\nExercise 9\n\n\n\nWhen the growth rate is restricted to 0.05 by limiting Glucose, which biological processes are the most upregulated? Show a sorted list with the most upregulated BPs on top, displaying the biological process and the average expression of all genes in that process rounded to two digits. Hint: 5 pipes: filter, group_by, summarize, mutate, arrange.\n\n\n# A tibble: 881 × 2\n   bp                                            meanexp\n   &lt;chr&gt;                                           &lt;dbl&gt;\n 1 fermentation*                                    6.28\n 2 glyoxylate cycle                                 5.28\n 3 oxygen and reactive oxygen species metabolism    5.04\n 4 fumarate transport*                              5.03\n 5 acetyl-CoA biosynthesis*                         4.32\n 6 gluconeogenesis                                  3.64\n 7 fatty acid beta-oxidation                        3.57\n 8 lactate transport                                3.48\n 9 carnitine metabolism                             3.3 \n10 alcohol metabolism*                              3.25\n# ℹ 871 more rows\n\n\n\n\n\n\n\n\n\n\nExercise 10\n\n\n\nGroup the data by limiting nutrient (primarily) then by biological process. Get the average expression for all genes annotated with each process, separately for each limiting nutrient, where the growth rate is restricted to 0.05. Arrange the result to show the most upregulated processes on top. The initial result will look like the result below. Pipe this output to a View() statement. What’s going on? Why didn’t the arrange() work? Hint: 5 pipes: filter, group_by, summarize, arrange, View.\n\n\n# A tibble: 5,257 × 3\n# Groups:   nutrient [6]\n   nutrient  bp                                            meanexp\n   &lt;chr&gt;     &lt;chr&gt;                                           &lt;dbl&gt;\n 1 Ammonia   allantoate transport                             6.64\n 2 Ammonia   amino acid transport*                            6.64\n 3 Phosphate glycerophosphodiester transport                  6.64\n 4 Glucose   fermentation*                                    6.28\n 5 Ammonia   allantoin transport                              5.56\n 6 Glucose   glyoxylate cycle                                 5.28\n 7 Ammonia   proline catabolism*                              5.14\n 8 Ammonia   urea transport                                   5.14\n 9 Glucose   oxygen and reactive oxygen species metabolism    5.04\n10 Glucose   fumarate transport*                              5.03\n# ℹ 5,247 more rows\n\n\n\n\n\n\n\n\n\n\nExercise 11\n\n\n\nLet’s try to further process that result to get only the top three most upregulated biolgocal processes for each limiting nutrient. Google search “dplyr first result within group.” You’ll need a filter(row_number()......) in there somewhere. Hint: 5 pipes: filter, group_by, summarize, arrange, filter(row_number().... Note: dplyr’s pipe syntax used to be %.% before it changed to |&gt;. So when looking around, you might still see some people use the old syntax. Now if you try to use the old syntax, you’ll get a deprecation warning.\n\n\n# A tibble: 18 × 3\n# Groups:   nutrient [6]\n   nutrient  bp                                            meanexp\n   &lt;chr&gt;     &lt;chr&gt;                                           &lt;dbl&gt;\n 1 Ammonia   allantoate transport                             6.64\n 2 Ammonia   amino acid transport*                            6.64\n 3 Phosphate glycerophosphodiester transport                  6.64\n 4 Glucose   fermentation*                                    6.28\n 5 Ammonia   allantoin transport                              5.56\n 6 Glucose   glyoxylate cycle                                 5.28\n 7 Glucose   oxygen and reactive oxygen species metabolism    5.04\n 8 Uracil    fumarate transport*                              4.32\n 9 Phosphate vacuole fusion, non-autophagic                   4.20\n10 Leucine   fermentation*                                    4.15\n11 Phosphate regulation of cell redox homeostasis*            4.03\n12 Leucine   fumarate transport*                              3.72\n13 Leucine   glyoxylate cycle                                 3.65\n14 Sulfate   protein ubiquitination                           3.4 \n15 Sulfate   fumarate transport*                              3.27\n16 Uracil    pyridoxine metabolism                            3.11\n17 Uracil    asparagine catabolism*                           3.06\n18 Sulfate   sulfur amino acid metabolism*                    2.69\n\n\n\n\n\n\n\n\n\n\nExercise 12\n\n\n\nThere’s a slight problem with the examples above. We’re getting the average expression of all the biological processes separately by each nutrient. But some of these biological processes only have a single gene in them! If we tried to do the same thing to get the correlation between rate and expression, the calculation would work, but we’d get a warning about a standard deviation being zero. The correlation coefficient value that results is NA, i.e., missing. While we’re summarizing the correlation between rate and expression, let’s also show the number of distinct genes within each grouping.\n\nydat |&gt; \n  group_by(nutrient, bp) |&gt; \n  summarize(r=cor(rate, expression), ngenes=n_distinct(symbol))\n\nWarning: There was 1 warning in `summarize()`.\nℹ In argument: `r = cor(rate, expression)`.\nℹ In group 110: `nutrient = \"Ammonia\"` and `bp = \"allantoate transport\"`.\nCaused by warning in `cor()`:\n! the standard deviation is zero\n\n\n# A tibble: 5,286 × 4\n# Groups:   nutrient [6]\n   nutrient bp                                              r ngenes\n   &lt;chr&gt;    &lt;chr&gt;                                       &lt;dbl&gt;  &lt;int&gt;\n 1 Ammonia  'de novo' IMP biosynthesis*                0.312       8\n 2 Ammonia  'de novo' pyrimidine base biosynthesis    -0.0482      3\n 3 Ammonia  'de novo' pyrimidine base biosynthesis*    0.167       4\n 4 Ammonia  35S primary transcript processing          0.508      13\n 5 Ammonia  35S primary transcript processing*         0.424      30\n 6 Ammonia  AMP biosynthesis*                          0.464       1\n 7 Ammonia  ATP synthesis coupled proton transport     0.112      15\n 8 Ammonia  ATP synthesis coupled proton transport*   -0.541       2\n 9 Ammonia  C-terminal protein amino acid methylation  0.813       1\n10 Ammonia  D-ribose metabolism                       -0.837       1\n# ℹ 5,276 more rows\n\n\nTake the above code and continue to process the result to show only results where the process has at least 5 genes. Add a column corresponding to the absolute value of the correlation coefficient, and show for each nutrient the singular process with the highest correlation between rate and expression, regardless of direction. Hint: 4 more pipes: filter, mutate, arrange, and filter again with row_number()==1. Ignore the warning.\n\n\n# A tibble: 6 × 5\n# Groups:   nutrient [6]\n  nutrient  bp                                              r ngenes  absr\n  &lt;chr&gt;     &lt;chr&gt;                                       &lt;dbl&gt;  &lt;int&gt; &lt;dbl&gt;\n1 Glucose   telomerase-independent telomere maintenance -0.95      7  0.95\n2 Ammonia   telomerase-independent telomere maintenance -0.91      7  0.91\n3 Leucine   telomerase-independent telomere maintenance -0.9       7  0.9 \n4 Phosphate telomerase-independent telomere maintenance -0.9       7  0.9 \n5 Uracil    telomerase-independent telomere maintenance -0.81      7  0.81\n6 Sulfate   translational elongation*                    0.79      5  0.79"
  },
  {
    "objectID": "tidyr.html#tidy-data",
    "href": "tidyr.html#tidy-data",
    "title": "4  Tidy Data and Advanced Data Manipulation",
    "section": "4.1 Tidy data",
    "text": "4.1 Tidy data\nSo far we’ve dealt exclusively with tidy data – data that’s easy to work with, manipulate, and visualize. That’s because our dataset has two key properties:\n\nEach column is a variable.\nEach row is an observation.\n\nYou can read a lot more about tidy data in this paper. Let’s load some untidy data and see if we can see the difference. This is some made-up data for five different patients (Jon, Ann, Bill, Kate, and Joe) given three different drugs (A, B, and C), at two doses (10 and 20), and measuring their heart rate. Download the heartrate2dose.csv file. Load readr and dplyr, and import and display the data.\n\nlibrary(readr)\nlibrary(dplyr)\nhr &lt;- read_csv(\"data/heartrate2dose.csv\")\nhr\n\n# A tibble: 5 × 7\n  name   a_10  a_20  b_10  b_20  c_10  c_20\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 jon      60    55    65    60    70    70\n2 ann      65    60    70    65    75    75\n3 bill     70    65    75    70    80    80\n4 kate     75    70    80    75    85    85\n5 joe      80    75    85    80    90    90\n\n\nNotice how with the yeast data each variable (symbol, nutrient, rate, expression, etc.) were each in their own column. In this heart rate data, we have four variables: name, drug, dose, and heart rate. Name is in a column, but drug is in the header row. Furthermore the drug and dose are tied together in the same column, and the heart rate is scattered around the entire table. If we wanted to do things like filter the dataset where drug==\"a\" or dose==20 or heartrate&gt;=80 we couldn’t do it because these variables aren’t in columns."
  },
  {
    "objectID": "tidyr.html#the-tidyr-package",
    "href": "tidyr.html#the-tidyr-package",
    "title": "4  Tidy Data and Advanced Data Manipulation",
    "section": "4.2 The tidyr package",
    "text": "4.2 The tidyr package\nThe tidyr package helps with this. There are several functions in the tidyr package but the ones we’re going to use are separate() and gather(). The gather() function takes multiple columns, and gathers them into key-value pairs: it makes “wide” data longer. The separate() function separates one column into multiple columns. So, what we need to do is gather all the drug/dose data into a column with their corresponding heart rate, and then separate that column into two separate columns for the drug and dose.\nBefore we get started, load the tidyr package, and look at the help pages for ?gather and ?separate. Notice how each of these functions takes a data frame as input and returns a data frame as output. Thus, we can pipe from one function to the next.\n\nlibrary(tidyr)\n\n\n4.2.1 gather()\nThe help for ?gather tells us that we first pass in a data frame (or omit the first argument, and pipe in the data with |&gt;). The next two arguments are the names of the key and value columns to create, and all the relevant arguments that come after that are the columns we want to gather together. Here’s one way to do it.\n\nhr |&gt; gather(key=drugdose, value=hr, a_10, a_20, b_10, b_20, c_10, c_20)\n\n# A tibble: 30 × 3\n   name  drugdose    hr\n   &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt;\n 1 jon   a_10        60\n 2 ann   a_10        65\n 3 bill  a_10        70\n 4 kate  a_10        75\n 5 joe   a_10        80\n 6 jon   a_20        55\n 7 ann   a_20        60\n 8 bill  a_20        65\n 9 kate  a_20        70\n10 joe   a_20        75\n# ℹ 20 more rows\n\n\nBut that gets cumbersome to type all those names. What if we had 100 drugs and 3 doses of each? There are two other ways of specifying which columns to gather. The help for ?gather tells you how to do this:\n\n... Specification of columns to gather. Use bare variable names. Select all variables between x and z with x:z, exclude y with -y. For more options, see the select documentation.\n\nSo, we could accomplish the same thing by doing this:\n\nhr |&gt; gather(key=drugdose, value=hr, a_10:c_20)\n\n# A tibble: 30 × 3\n   name  drugdose    hr\n   &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt;\n 1 jon   a_10        60\n 2 ann   a_10        65\n 3 bill  a_10        70\n 4 kate  a_10        75\n 5 joe   a_10        80\n 6 jon   a_20        55\n 7 ann   a_20        60\n 8 bill  a_20        65\n 9 kate  a_20        70\n10 joe   a_20        75\n# ℹ 20 more rows\n\n\nBut what if we didn’t know the drug names or doses, but we did know that the only other column in there that we don’t want to gather is name?\n\nhr |&gt; gather(key=drugdose, value=hr, -name)\n\n# A tibble: 30 × 3\n   name  drugdose    hr\n   &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt;\n 1 jon   a_10        60\n 2 ann   a_10        65\n 3 bill  a_10        70\n 4 kate  a_10        75\n 5 joe   a_10        80\n 6 jon   a_20        55\n 7 ann   a_20        60\n 8 bill  a_20        65\n 9 kate  a_20        70\n10 joe   a_20        75\n# ℹ 20 more rows\n\n\n\n\n4.2.2 separate()\nFinally, look at the help for ?separate. We can pipe in data and omit the first argument. The second argument is the column to separate; the into argument is a character vector of the new column names, and the sep argument is a character used to separate columns, or a number indicating the position to split at.\n\nSide note, and 60-second lesson on vectors: We can create arbitrary-length vectors, which are simply variables that contain an arbitrary number of values. To create a numeric vector, try this: c(5, 42, 22908). That creates a three element vector. Try c(\"cat\", \"dog\").\n\n\nhr |&gt; \n  gather(key=drugdose, value=hr, -name) |&gt; \n  separate(drugdose, into=c(\"drug\", \"dose\"), sep=\"_\")\n\n# A tibble: 30 × 4\n   name  drug  dose     hr\n   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n 1 jon   a     10       60\n 2 ann   a     10       65\n 3 bill  a     10       70\n 4 kate  a     10       75\n 5 joe   a     10       80\n 6 jon   a     20       55\n 7 ann   a     20       60\n 8 bill  a     20       65\n 9 kate  a     20       70\n10 joe   a     20       75\n# ℹ 20 more rows\n\n\n\n\n4.2.3 |&gt; it all together\nLet’s put it all together with gather |&gt; separate |&gt; filter |&gt; group_by |&gt; summarize.\nIf we create a new data frame that’s a tidy version of hr, we can do those kinds of manipulations we talked about before:\n\n# Create a new data.frame\nhrtidy &lt;- hr |&gt; \n  gather(key=drugdose, value=hr, -name) |&gt; \n  separate(drugdose, into=c(\"drug\", \"dose\"), sep=\"_\")\n\n# Optionally, view it\n# View(hrtidy)\n\n# filter\nhrtidy |&gt; filter(drug==\"a\")\n\n# A tibble: 10 × 4\n   name  drug  dose     hr\n   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n 1 jon   a     10       60\n 2 ann   a     10       65\n 3 bill  a     10       70\n 4 kate  a     10       75\n 5 joe   a     10       80\n 6 jon   a     20       55\n 7 ann   a     20       60\n 8 bill  a     20       65\n 9 kate  a     20       70\n10 joe   a     20       75\n\nhrtidy |&gt; filter(dose==20)\n\n# A tibble: 15 × 4\n   name  drug  dose     hr\n   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n 1 jon   a     20       55\n 2 ann   a     20       60\n 3 bill  a     20       65\n 4 kate  a     20       70\n 5 joe   a     20       75\n 6 jon   b     20       60\n 7 ann   b     20       65\n 8 bill  b     20       70\n 9 kate  b     20       75\n10 joe   b     20       80\n11 jon   c     20       70\n12 ann   c     20       75\n13 bill  c     20       80\n14 kate  c     20       85\n15 joe   c     20       90\n\nhrtidy |&gt; filter(hr&gt;=80)\n\n# A tibble: 10 × 4\n   name  drug  dose     hr\n   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n 1 joe   a     10       80\n 2 kate  b     10       80\n 3 joe   b     10       85\n 4 joe   b     20       80\n 5 bill  c     10       80\n 6 kate  c     10       85\n 7 joe   c     10       90\n 8 bill  c     20       80\n 9 kate  c     20       85\n10 joe   c     20       90\n\n# analyze\nhrtidy |&gt;\n  filter(name!=\"joe\") |&gt; \n  group_by(drug, dose) |&gt;\n  summarize(meanhr=mean(hr))\n\n# A tibble: 6 × 3\n# Groups:   drug [3]\n  drug  dose  meanhr\n  &lt;chr&gt; &lt;chr&gt;  &lt;dbl&gt;\n1 a     10      67.5\n2 a     20      62.5\n3 b     10      72.5\n4 b     20      67.5\n5 c     10      77.5\n6 c     20      77.5"
  },
  {
    "objectID": "tidyr.html#tidy-the-yeast-data",
    "href": "tidyr.html#tidy-the-yeast-data",
    "title": "4  Tidy Data and Advanced Data Manipulation",
    "section": "4.3 Tidy the yeast data",
    "text": "4.3 Tidy the yeast data\nNow, let’s take a look at the yeast data again. The data we’ve been working with up to this point was already cleaned up to a good degree. All of our variables (symbol, nutrient, rate, expression, GO terms, etc.) were each in their own column. Make sure you have the necessary libraries loaded, and read in the tidy data once more into an object called ydat.\n\n# Load libraries\nlibrary(readr)\nlibrary(dplyr)\nlibrary(tidyr)\n\n# Import data\nydat &lt;- read_csv(\"data/brauer2007_tidy.csv\")\n\n# Optionally, View\n# View(ydat)\n\n# Or just display to the screen\nydat\n\n# A tibble: 198,430 × 7\n   symbol systematic_name nutrient  rate expression bp                     mf   \n   &lt;chr&gt;  &lt;chr&gt;           &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;                  &lt;chr&gt;\n 1 SFB2   YNL049C         Glucose   0.05      -0.24 ER to Golgi transport  mole…\n 2 &lt;NA&gt;   YNL095C         Glucose   0.05       0.28 biological process un… mole…\n 3 QRI7   YDL104C         Glucose   0.05      -0.02 proteolysis and pepti… meta…\n 4 CFT2   YLR115W         Glucose   0.05      -0.33 mRNA polyadenylylatio… RNA …\n 5 SSO2   YMR183C         Glucose   0.05       0.05 vesicle fusion*        t-SN…\n 6 PSP2   YML017W         Glucose   0.05      -0.69 biological process un… mole…\n 7 RIB2   YOL066C         Glucose   0.05      -0.55 riboflavin biosynthes… pseu…\n 8 VMA13  YPR036W         Glucose   0.05      -0.75 vacuolar acidification hydr…\n 9 EDC3   YEL015W         Glucose   0.05      -0.24 deadenylylation-indep… mole…\n10 VPS5   YOR069W         Glucose   0.05      -0.16 protein retention in … prot…\n# ℹ 198,420 more rows\n\n\nBut let’s take a look to see what this data originally looked like.\n\nyorig &lt;- read_csv(\"data/brauer2007_messy.csv\")\n# View(yorig)\nyorig\n\n# A tibble: 5,536 × 40\n   GID       YORF  NAME  GWEIGHT G0.05  G0.1 G0.15  G0.2 G0.25  G0.3 N0.05  N0.1\n   &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 GENE1331X A_06… SFB2…       1 -0.24 -0.13 -0.21 -0.15 -0.05 -0.05  0.2   0.24\n 2 GENE4924X A_06… NA::…       1  0.28  0.13 -0.4  -0.48 -0.11  0.17  0.31  0   \n 3 GENE4690X A_06… QRI7…       1 -0.02 -0.27 -0.27 -0.02  0.24  0.25  0.23  0.06\n 4 GENE1177X A_06… CFT2…       1 -0.33 -0.41 -0.24 -0.03 -0.03  0     0.2  -0.25\n 5 GENE511X  A_06… SSO2…       1  0.05  0.02  0.4   0.34 -0.13 -0.14 -0.35 -0.09\n 6 GENE2133X A_06… PSP2…       1 -0.69 -0.03  0.23  0.2   0    -0.27  0.17 -0.4 \n 7 GENE1002X A_06… RIB2…       1 -0.55 -0.3  -0.12 -0.03 -0.16 -0.11  0.04  0   \n 8 GENE5478X A_06… VMA1…       1 -0.75 -0.12 -0.07  0.02 -0.32 -0.41  0.11 -0.16\n 9 GENE2065X A_06… EDC3…       1 -0.24 -0.22  0.14  0.06  0    -0.13  0.3   0.07\n10 GENE2440X A_06… VPS5…       1 -0.16 -0.38  0.05  0.14 -0.04 -0.01  0.39  0.2 \n# ℹ 5,526 more rows\n# ℹ 28 more variables: N0.15 &lt;dbl&gt;, N0.2 &lt;dbl&gt;, N0.25 &lt;dbl&gt;, N0.3 &lt;dbl&gt;,\n#   P0.05 &lt;dbl&gt;, P0.1 &lt;dbl&gt;, P0.15 &lt;dbl&gt;, P0.2 &lt;dbl&gt;, P0.25 &lt;dbl&gt;, P0.3 &lt;dbl&gt;,\n#   S0.05 &lt;dbl&gt;, S0.1 &lt;dbl&gt;, S0.15 &lt;dbl&gt;, S0.2 &lt;dbl&gt;, S0.25 &lt;dbl&gt;, S0.3 &lt;dbl&gt;,\n#   L0.05 &lt;dbl&gt;, L0.1 &lt;dbl&gt;, L0.15 &lt;dbl&gt;, L0.2 &lt;dbl&gt;, L0.25 &lt;dbl&gt;, L0.3 &lt;dbl&gt;,\n#   U0.05 &lt;dbl&gt;, U0.1 &lt;dbl&gt;, U0.15 &lt;dbl&gt;, U0.2 &lt;dbl&gt;, U0.25 &lt;dbl&gt;, U0.3 &lt;dbl&gt;\n\n\nThere are several issues here.\n\nMultiple variables are stored in one column. The NAME column contains lots of information, split up by ::’s.\nNutrient and rate variables are stuck in column headers. That is, the column names contain the values of two variables: nutrient (G, N, P, S, L, U) and growth rate (0.05-0.3). Remember, with tidy data, each column is a variable and each row is an observation. Here, we have not one observation per row, but 36 (6 nutrients \\(\\times\\) 6 rates)! There’s no way we could filter this data by a certain nutrient, or try to calculate statistics between rate and expression.\nExpression values are scattered throughout the table. Related to the problem above, and just like our heart rate example, expression isn’t a single-column variable as in the cleaned tidy data, but it’s scattered around these 36 columns.\nOther important information is in a separate table. We’re missing all the gene ontology information we had in the tidy data (no information about biological process (bp) or molecular function (mf)).\n\nLet’s tackle these issues one at a time, all on a |&gt; pipeline.\n\n4.3.1 separate() the NAME\nLet’s separate() the NAME column into multiple different variables. The first row looks like this:\n\nSFB2::YNL049C::1082129\n\nThat is, it looks like we’ve got the gene symbol, the systematic name, and some other number (that isn’t discussed in the paper). Let’s separate()!\n\nyorig |&gt; \n  separate(NAME, into=c(\"symbol\", \"systematic_name\", \"somenumber\"), sep=\"::\")\n\n# A tibble: 5,536 × 42\n   GID   YORF  symbol systematic_name somenumber GWEIGHT G0.05  G0.1 G0.15  G0.2\n   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;           &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 GENE… A_06… SFB2   YNL049C         1082129          1 -0.24 -0.13 -0.21 -0.15\n 2 GENE… A_06… NA     YNL095C         1086222          1  0.28  0.13 -0.4  -0.48\n 3 GENE… A_06… QRI7   YDL104C         1085955          1 -0.02 -0.27 -0.27 -0.02\n 4 GENE… A_06… CFT2   YLR115W         1081958          1 -0.33 -0.41 -0.24 -0.03\n 5 GENE… A_06… SSO2   YMR183C         1081214          1  0.05  0.02  0.4   0.34\n 6 GENE… A_06… PSP2   YML017W         1083036          1 -0.69 -0.03  0.23  0.2 \n 7 GENE… A_06… RIB2   YOL066C         1081766          1 -0.55 -0.3  -0.12 -0.03\n 8 GENE… A_06… VMA13  YPR036W         1086860          1 -0.75 -0.12 -0.07  0.02\n 9 GENE… A_06… EDC3   YEL015W         1082963          1 -0.24 -0.22  0.14  0.06\n10 GENE… A_06… VPS5   YOR069W         1083389          1 -0.16 -0.38  0.05  0.14\n# ℹ 5,526 more rows\n# ℹ 32 more variables: G0.25 &lt;dbl&gt;, G0.3 &lt;dbl&gt;, N0.05 &lt;dbl&gt;, N0.1 &lt;dbl&gt;,\n#   N0.15 &lt;dbl&gt;, N0.2 &lt;dbl&gt;, N0.25 &lt;dbl&gt;, N0.3 &lt;dbl&gt;, P0.05 &lt;dbl&gt;, P0.1 &lt;dbl&gt;,\n#   P0.15 &lt;dbl&gt;, P0.2 &lt;dbl&gt;, P0.25 &lt;dbl&gt;, P0.3 &lt;dbl&gt;, S0.05 &lt;dbl&gt;, S0.1 &lt;dbl&gt;,\n#   S0.15 &lt;dbl&gt;, S0.2 &lt;dbl&gt;, S0.25 &lt;dbl&gt;, S0.3 &lt;dbl&gt;, L0.05 &lt;dbl&gt;, L0.1 &lt;dbl&gt;,\n#   L0.15 &lt;dbl&gt;, L0.2 &lt;dbl&gt;, L0.25 &lt;dbl&gt;, L0.3 &lt;dbl&gt;, U0.05 &lt;dbl&gt;, U0.1 &lt;dbl&gt;,\n#   U0.15 &lt;dbl&gt;, U0.2 &lt;dbl&gt;, U0.25 &lt;dbl&gt;, U0.3 &lt;dbl&gt;\n\n\nNow, let’s select() out the stuff we don’t want.\n\nyorig |&gt; \n  separate(NAME, into=c(\"symbol\", \"systematic_name\", \"somenumber\"), sep=\"::\") |&gt; \n  select(-GID, -YORF, -somenumber, -GWEIGHT)\n\n# A tibble: 5,536 × 38\n   symbol systematic_name G0.05  G0.1 G0.15  G0.2 G0.25  G0.3 N0.05  N0.1 N0.15\n   &lt;chr&gt;  &lt;chr&gt;           &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 SFB2   YNL049C         -0.24 -0.13 -0.21 -0.15 -0.05 -0.05  0.2   0.24 -0.2 \n 2 NA     YNL095C          0.28  0.13 -0.4  -0.48 -0.11  0.17  0.31  0    -0.63\n 3 QRI7   YDL104C         -0.02 -0.27 -0.27 -0.02  0.24  0.25  0.23  0.06 -0.66\n 4 CFT2   YLR115W         -0.33 -0.41 -0.24 -0.03 -0.03  0     0.2  -0.25 -0.49\n 5 SSO2   YMR183C          0.05  0.02  0.4   0.34 -0.13 -0.14 -0.35 -0.09 -0.08\n 6 PSP2   YML017W         -0.69 -0.03  0.23  0.2   0    -0.27  0.17 -0.4  -0.54\n 7 RIB2   YOL066C         -0.55 -0.3  -0.12 -0.03 -0.16 -0.11  0.04  0    -0.63\n 8 VMA13  YPR036W         -0.75 -0.12 -0.07  0.02 -0.32 -0.41  0.11 -0.16 -0.26\n 9 EDC3   YEL015W         -0.24 -0.22  0.14  0.06  0    -0.13  0.3   0.07 -0.3 \n10 VPS5   YOR069W         -0.16 -0.38  0.05  0.14 -0.04 -0.01  0.39  0.2   0.27\n# ℹ 5,526 more rows\n# ℹ 27 more variables: N0.2 &lt;dbl&gt;, N0.25 &lt;dbl&gt;, N0.3 &lt;dbl&gt;, P0.05 &lt;dbl&gt;,\n#   P0.1 &lt;dbl&gt;, P0.15 &lt;dbl&gt;, P0.2 &lt;dbl&gt;, P0.25 &lt;dbl&gt;, P0.3 &lt;dbl&gt;, S0.05 &lt;dbl&gt;,\n#   S0.1 &lt;dbl&gt;, S0.15 &lt;dbl&gt;, S0.2 &lt;dbl&gt;, S0.25 &lt;dbl&gt;, S0.3 &lt;dbl&gt;, L0.05 &lt;dbl&gt;,\n#   L0.1 &lt;dbl&gt;, L0.15 &lt;dbl&gt;, L0.2 &lt;dbl&gt;, L0.25 &lt;dbl&gt;, L0.3 &lt;dbl&gt;, U0.05 &lt;dbl&gt;,\n#   U0.1 &lt;dbl&gt;, U0.15 &lt;dbl&gt;, U0.2 &lt;dbl&gt;, U0.25 &lt;dbl&gt;, U0.3 &lt;dbl&gt;\n\n\n\n\n4.3.2 gather() the data\nLet’s gather the data from wide to long format so we get nutrient/rate (key) and expression (value) in their own columns.\n\nyorig |&gt; \n  separate(NAME, into=c(\"symbol\", \"systematic_name\", \"somenumber\"), sep=\"::\") |&gt; \n  select(-GID, -YORF, -somenumber, -GWEIGHT) |&gt; \n  gather(key=nutrientrate, value=expression, G0.05:U0.3)\n\n# A tibble: 199,296 × 4\n   symbol systematic_name nutrientrate expression\n   &lt;chr&gt;  &lt;chr&gt;           &lt;chr&gt;             &lt;dbl&gt;\n 1 SFB2   YNL049C         G0.05             -0.24\n 2 NA     YNL095C         G0.05              0.28\n 3 QRI7   YDL104C         G0.05             -0.02\n 4 CFT2   YLR115W         G0.05             -0.33\n 5 SSO2   YMR183C         G0.05              0.05\n 6 PSP2   YML017W         G0.05             -0.69\n 7 RIB2   YOL066C         G0.05             -0.55\n 8 VMA13  YPR036W         G0.05             -0.75\n 9 EDC3   YEL015W         G0.05             -0.24\n10 VPS5   YOR069W         G0.05             -0.16\n# ℹ 199,286 more rows\n\n\nAnd while we’re at it, let’s separate() that newly created key column. Take a look at the help for ?separate again. The sep argument could be a delimiter or a number position to split at. Let’s split after the first character. While we’re at it, let’s hold onto this intermediate data frame before we add gene ontology information. Call it ynogo.\n\nynogo &lt;- yorig |&gt; \n  separate(NAME, into=c(\"symbol\", \"systematic_name\", \"somenumber\"), sep=\"::\") |&gt; \n  select(-GID, -YORF, -somenumber, -GWEIGHT) |&gt; \n  gather(key=nutrientrate, value=expression, G0.05:U0.3) |&gt; \n  separate(nutrientrate, into=c(\"nutrient\", \"rate\"), sep=1)\n\n\n\n4.3.3 inner_join() to GO\nIt’s rare that a data analysis involves only a single table of data. You normally have many tables that contribute to an analysis, and you need flexible tools to combine them. The dplyr package has several tools that let you work with multiple tables at once. Do a Google image search for “SQL Joins”, and look at RStudio’s Data Wrangling Cheat Sheet to learn more.\nFirst, let’s import the dataset that links the systematic name to gene ontology information. It’s the brauer2007_sysname2go.csv file. Let’s call the imported data frame sn2go.\n\n# Import the data\nsn2go &lt;- read_csv(\"data/brauer2007_sysname2go.csv\")\n\n# Take a look\n# View(sn2go)\nhead(sn2go)\n\n# A tibble: 6 × 3\n  systematic_name bp                           mf                           \n  &lt;chr&gt;           &lt;chr&gt;                        &lt;chr&gt;                        \n1 YNL049C         ER to Golgi transport        molecular function unknown   \n2 YNL095C         biological process unknown   molecular function unknown   \n3 YDL104C         proteolysis and peptidolysis metalloendopeptidase activity\n4 YLR115W         mRNA polyadenylylation*      RNA binding                  \n5 YMR183C         vesicle fusion*              t-SNARE activity             \n6 YML017W         biological process unknown   molecular function unknown   \n\n\nNow, look up some help for ?inner_join. Inner join will return a table with all rows from the first table where there are matching rows in the second table, and returns all columns from both tables. Let’s give this a try.\n\nyjoined &lt;- inner_join(ynogo, sn2go, by=\"systematic_name\")\n# View(yjoined)\nyjoined\n\n# A tibble: 199,296 × 7\n   symbol systematic_name nutrient rate  expression bp                     mf   \n   &lt;chr&gt;  &lt;chr&gt;           &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                  &lt;chr&gt;\n 1 SFB2   YNL049C         G        0.05       -0.24 ER to Golgi transport  mole…\n 2 NA     YNL095C         G        0.05        0.28 biological process un… mole…\n 3 QRI7   YDL104C         G        0.05       -0.02 proteolysis and pepti… meta…\n 4 CFT2   YLR115W         G        0.05       -0.33 mRNA polyadenylylatio… RNA …\n 5 SSO2   YMR183C         G        0.05        0.05 vesicle fusion*        t-SN…\n 6 PSP2   YML017W         G        0.05       -0.69 biological process un… mole…\n 7 RIB2   YOL066C         G        0.05       -0.55 riboflavin biosynthes… pseu…\n 8 VMA13  YPR036W         G        0.05       -0.75 vacuolar acidification hydr…\n 9 EDC3   YEL015W         G        0.05       -0.24 deadenylylation-indep… mole…\n10 VPS5   YOR069W         G        0.05       -0.16 protein retention in … prot…\n# ℹ 199,286 more rows\n\n# The glimpse function makes it possible to see a little bit of everything in your data.\nglimpse(yjoined)\n\nRows: 199,296\nColumns: 7\n$ symbol          &lt;chr&gt; \"SFB2\", \"NA\", \"QRI7\", \"CFT2\", \"SSO2\", \"PSP2\", \"RIB2\", …\n$ systematic_name &lt;chr&gt; \"YNL049C\", \"YNL095C\", \"YDL104C\", \"YLR115W\", \"YMR183C\",…\n$ nutrient        &lt;chr&gt; \"G\", \"G\", \"G\", \"G\", \"G\", \"G\", \"G\", \"G\", \"G\", \"G\", \"G\",…\n$ rate            &lt;chr&gt; \"0.05\", \"0.05\", \"0.05\", \"0.05\", \"0.05\", \"0.05\", \"0.05\"…\n$ expression      &lt;dbl&gt; -0.24, 0.28, -0.02, -0.33, 0.05, -0.69, -0.55, -0.75, …\n$ bp              &lt;chr&gt; \"ER to Golgi transport\", \"biological process unknown\",…\n$ mf              &lt;chr&gt; \"molecular function unknown\", \"molecular function unkn…\n\n\nThere are many different kinds of two-table verbs/joins in dplyr. In this example, every systematic name in ynogo had a corresponding entry in sn2go, but if this weren’t the case, those un-annotated genes would have been removed entirely by the inner_join. A left_join would have returned all the rows in ynogo, but would have filled in bp and mf with missing values (NA) when there was no corresponding entry. See also: right_join, semi_join, and anti_join.\n\n\n4.3.4 Finishing touches\nWe’re almost there but we have an obvious discrepancy in the number of rows between yjoined and ydat.\n\nnrow(yjoined)\n\n[1] 199296\n\nnrow(ydat)\n\n[1] 198430\n\n\nBefore we can figure out what rows are different, we need to make sure all of the columns are the same class and do something more miscellaneous cleanup.\nIn particular:\n\nConvert rate to a numeric column\nMake sure NA values are coded properly\nCreate (and merge) values to convert “G” to “Glucose”, “L” to “Leucine”, etc.\nRename and reorder columns\n\nThe code below implements those operations on yjoined.\n\nnutrientlookup &lt;-\n  tibble(nutrient = c(\"G\", \"L\", \"N\", \"P\", \"S\", \"U\"), nutrientname = c(\"Glucose\", \"Leucine\", \"Ammonia\",\"Phosphate\", \"Sulfate\",\"Uracil\"))\n\nyjoined &lt;-\n  yjoined |&gt;\n  mutate(rate = as.numeric(rate)) |&gt;\n  mutate(symbol = ifelse(symbol == \"NA\", NA, symbol)) |&gt;\n  left_join(nutrientlookup) |&gt;\n  select(-nutrient) |&gt;\n  select(symbol:systematic_name, nutrient = nutrientname, rate:mf)\n\nNow we can determine what rows are different between yjoined and ydat using anti_join, which will return all of the rows that do not match.\n\nanti_join(yjoined, ydat) \n\n# A tibble: 866 × 7\n   symbol systematic_name nutrient  rate expression bp                     mf   \n   &lt;chr&gt;  &lt;chr&gt;           &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;                  &lt;chr&gt;\n 1 &lt;NA&gt;   YLL030C         Glucose   0.05         NA &lt;NA&gt;                   &lt;NA&gt; \n 2 &lt;NA&gt;   YOR050C         Glucose   0.05         NA &lt;NA&gt;                   &lt;NA&gt; \n 3 &lt;NA&gt;   YPR039W         Glucose   0.05         NA &lt;NA&gt;                   &lt;NA&gt; \n 4 &lt;NA&gt;   YOL013W-B       Glucose   0.05         NA &lt;NA&gt;                   &lt;NA&gt; \n 5 HXT12  YIL170W         Glucose   0.05         NA biological process un… mole…\n 6 &lt;NA&gt;   YPR013C         Glucose   0.05         NA biological process un… mole…\n 7 &lt;NA&gt;   YOR314W         Glucose   0.05         NA &lt;NA&gt;                   &lt;NA&gt; \n 8 &lt;NA&gt;   YJL064W         Glucose   0.05         NA &lt;NA&gt;                   &lt;NA&gt; \n 9 &lt;NA&gt;   YPR136C         Glucose   0.05         NA &lt;NA&gt;                   &lt;NA&gt; \n10 &lt;NA&gt;   YDR015C         Glucose   0.05         NA &lt;NA&gt;                   &lt;NA&gt; \n# ℹ 856 more rows\n\n\nHmmmm … so yjoined has some rows that have missing (NA) expression values. Let’s try removing those and then comparing the data frame contents one more time.\n\nyjoined &lt;-\n  yjoined |&gt;\n  filter(!is.na(expression))\n\nnrow(yjoined)\n\n[1] 198430\n\nnrow(ydat)\n\n[1] 198430\n\nall.equal(ydat, yjoined)\n\n[1] \"Attributes: &lt; Names: 1 string mismatch &gt;\"                                              \n[2] \"Attributes: &lt; Length mismatch: comparison on first 2 components &gt;\"                     \n[3] \"Attributes: &lt; Component \\\"class\\\": Lengths (4, 3) differ (string compare on first 3) &gt;\"\n[4] \"Attributes: &lt; Component \\\"class\\\": 3 string mismatches &gt;\"                              \n[5] \"Attributes: &lt; Component 2: target is externalptr, current is numeric &gt;\"                \n\n\nLooks like that did it!"
  },
  {
    "objectID": "ggplot2.html#review",
    "href": "ggplot2.html#review",
    "title": "5  Data Visualization with ggplot2",
    "section": "5.1 Review",
    "text": "5.1 Review\n\n5.1.1 Gapminder data\nWe’re going to work with a different dataset for this section. It’s a cleaned-up excerpt from the Gapminder data. Download the gapminder.csv data by clicking here or using the link above.\nLet’s read in the data to an object called gm and take a look with View. Remember, we need to load both the dplyr and readr packages for efficiently reading in and displaying this data.\n\n# Load packages\nlibrary(readr)\nlibrary(dplyr)\n\n# Download the data locally and read the file\ngm &lt;- read_csv(file=\"data/gapminder.csv\")\n\n# Show the first few lines of the data\ngm\n\n# A tibble: 1,704 × 6\n   country     continent  year lifeExp      pop gdpPercap\n   &lt;chr&gt;       &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1 Afghanistan Asia       1952    28.8  8425333      779.\n 2 Afghanistan Asia       1957    30.3  9240934      821.\n 3 Afghanistan Asia       1962    32.0 10267083      853.\n 4 Afghanistan Asia       1967    34.0 11537966      836.\n 5 Afghanistan Asia       1972    36.1 13079460      740.\n 6 Afghanistan Asia       1977    38.4 14880372      786.\n 7 Afghanistan Asia       1982    39.9 12881816      978.\n 8 Afghanistan Asia       1987    40.8 13867957      852.\n 9 Afghanistan Asia       1992    41.7 16317921      649.\n10 Afghanistan Asia       1997    41.8 22227415      635.\n# ℹ 1,694 more rows\n\n# Optionally bring up data in a viewer window.\n# View(gm)\n\nThis particular excerpt has 1704 observations on six variables:\n\ncountry a categorical variable 142 levels\ncontinent, a categorical variable with 5 levels\nyear: going from 1952 to 2007 in increments of 5 years\npop: population\ngdpPercap: GDP per capita\nlifeExp: life expectancy\n\n\n\n5.1.2 dplyr review\nThe dplyr package gives you a handful of useful verbs for managing data. On their own they don’t do anything that base R can’t do. Here are some of the single-table verbs we’ll be working with in this lesson (single-table meaning that they only work on a single table – contrast that to two-table verbs used for joining data together). They all take a data.frame or tbl as their input for the first argument, and they all return a data.frame or tbl as output.\n\nfilter(): filters rows of the data where some condition is true\nselect(): selects out particular columns of interest\nmutate(): adds new columns or changes values of existing columns\narrange(): arranges a data frame by the value of a column\nsummarize(): summarizes multiple values to a single value, most useful when combined with…\ngroup_by(): groups a data frame by one or more variable. Most data operations are useful done on groups defined by variables in the the dataset. The group_by function takes an existing data frame and converts it into a grouped data frame where summarize() operations are performed by group.\n\nAdditionally, the |&gt; operator allows you to “chain” operations together. Rather than nesting functions inside out, the |&gt; operator allows you to write operations left-to-right, top-to-bottom. Let’s say we wanted to get the average life expectancy and GDP (not GDP per capita) for Asian countries for each year.\n\nThe |&gt; would allow us to do this:\n\ngm |&gt;\n  mutate(gdp=gdpPercap*pop) |&gt;\n  filter(continent==\"Asia\") |&gt;\n  group_by(year) |&gt;\n  summarize(mean(lifeExp), mean(gdp))\n\n# A tibble: 12 × 3\n    year `mean(lifeExp)`   `mean(gdp)`\n   &lt;dbl&gt;           &lt;dbl&gt;         &lt;dbl&gt;\n 1  1952            46.3  34095762661.\n 2  1957            49.3  47267432088.\n 3  1962            51.6  60136869012.\n 4  1967            54.7  84648519224.\n 5  1972            57.3 124385747313.\n 6  1977            59.6 159802590186.\n 7  1982            62.6 194429049919.\n 8  1987            64.9 241784763369.\n 9  1992            66.5 307100497486.\n10  1997            68.0 387597655323.\n11  2002            69.2 458042336179.\n12  2007            70.7 627513635079.\n\n\nInstead of this:\n\nsummarize(\n  group_by(\n    filter(\n      mutate(gm, gdp=gdpPercap*pop), \n    continent==\"Asia\"), \n  year), \nmean(lifeExp), mean(gdp))"
  },
  {
    "objectID": "ggplot2.html#about-ggplot2",
    "href": "ggplot2.html#about-ggplot2",
    "title": "5  Data Visualization with ggplot2",
    "section": "5.2 About ggplot2",
    "text": "5.2 About ggplot2\nggplot2 is a widely used R package that extends R’s visualization capabilities. It takes the hassle out of things like creating legends, mapping other variables to scales like color, or faceting plots into small multiples. We’ll learn about what all these things mean shortly.\nWhere does the “gg” in ggplot2 come from? The ggplot2 package provides an R implementation of Leland Wilkinson’s Grammar of Graphics (1999). The Grammar of Graphics allows you to think beyond the garden variety plot types (e.g. scatterplot, barplot) and the consider the components that make up a plot or graphic, such as how data are represented on the plot (as lines, points, etc.), how variables are mapped to coordinates or plotting shape or color, what transformation or statistical summary is required, and so on.\nSpecifically, ggplot2 allows you to build a plot layer-by-layer by specifying:\n\na geom, which specifies how the data are represented on the plot (points, lines, bars, etc.),\naesthetics that map variables in the data to axes on the plot or to plotting size, shape, color, etc.,\na stat, a statistical transformation or summary of the data applied prior to plotting,\nfacets, which we’ve already seen above, that allow the data to be divided into chunks on the basis of other categorical or continuous variables and the same plot drawn for each chunk.\n\nFirst, a note about qplot(). The qplot() function is a quick and dirty way of making ggplot2 plots. You might see it if you look for help with ggplot2, and it’s even covered extensively in the ggplot2 book. And if you’re used to making plots with built-in base graphics, the qplot() function will probably feel more familiar. But the sooner you abandon the qplot() syntax the sooner you’ll start to really understand ggplot2’s approach to building up plots layer by layer. So we’re not going to use it at all in this class."
  },
  {
    "objectID": "ggplot2.html#plotting-bivariate-data-continuous-y-by-continuous-x",
    "href": "ggplot2.html#plotting-bivariate-data-continuous-y-by-continuous-x",
    "title": "5  Data Visualization with ggplot2",
    "section": "5.3 Plotting bivariate data: continuous Y by continuous X",
    "text": "5.3 Plotting bivariate data: continuous Y by continuous X\nThe ggplot function has two required arguments: the data used for creating the plot, and an aesthetic mapping to describe how variables in said data are mapped to things we can see on the plot.\nFirst let’s load the package:\n\nlibrary(ggplot2)\n\nNow, let’s lay out the plot. If we want to plot a continuous Y variable by a continuous X variable we’re probably most interested in a scatter plot. Here, we’re telling ggplot that we want to use the gm dataset, and the aesthetic mapping will map gdpPercap onto the x-axis and lifeExp onto the y-axis. Remember that the variable names are case sensitive!\n\nggplot(gm, aes(x = gdpPercap, y = lifeExp))\n\n\n\n\nWhen we do that we get a blank canvas with no data showing (you might get an error if you’re using an old version of ggplot2). That’s because all we’ve done is laid out a two-dimensional plot specifying what goes on the x and y axes, but we haven’t told it what kind of geometric object to plot. The obvious choice here is a point. Check out docs.ggplot2.org to see what kind of geoms are available.\n\nggplot(gm, aes(x = gdpPercap, y = lifeExp)) + geom_point()\n\n\n\n\nHere, we’ve built our plot in layers. First, we create a canvas for plotting layers to come using the ggplot function, specifying which data to use (here, the gm data frame), and an aesthetic mapping of gdpPercap to the x-axis and lifeExp to the y-axis. We next add a layer to the plot, specifying a geom, or a way of visually representing the aesthetic mapping.\nNow, the typical workflow for building up a ggplot2 plot is to first construct the figure and save that to a variable (for example, p), and as you’re experimenting, you can continue to re-define the p object as you develop “keeper commands”.\nFirst, let’s construct the graphic. Notice that we don’t have to specify x= and y= if we specify the arguments in the correct order (x is first, y is second).\n\np &lt;- ggplot(gm, aes(gdpPercap, lifeExp))\n\nThe p object now contains the canvas, but nothing else. Try displaying it by just running p. Let’s experiment with adding points and a different scale to the x-axis.\n\n# Experiment with adding poings\np + geom_point()\n\n\n\n# Experiment with a different scale\np + geom_point() + scale_x_log10()\n\n\n\n\nI like the look of using a log scale for the x-axis. Let’s make that stick.\n\np &lt;- p + scale_x_log10()\n\nNow, if we re-ran p still nothing would show up because the p object just contains a blank canvas. Now, re-plot again with a layer of points:\n\np + geom_point()\n\n\n\n\nNow notice what I’ve saved to p at this point: only the basic plot layout and the log10 mapping on the x-axis. I didn’t save any layers yet because I want to fiddle around with the points for a bit first.\nAbove we implied the aesthetic mappings for the x- and y- axis should be gdpPercap and lifeExp, but we can also add aesthetic mappings to the geoms themselves. For instance, what if we wanted to color the points by the value of another variable in the dataset, say, continent?\n\np + geom_point(aes(color=continent))\n\n\n\n\nNotice the difference here. If I wanted the colors to be some static value, I wouldn’t wrap that in a call to aes(). I would just specify it outright. Same thing with other features of the points. For example, lets make all the points huge (size=8) blue (color=\"blue\") semitransparent (alpha=(1/4)) triangles (pch=17):\n\np + geom_point(color=\"blue\", pch=17, size=8, alpha=1/4)\n\n\n\n\nNow, this time, let’s map the aesthetics of the point character to certain features of the data. For instance, let’s give the points different colors and character shapes according to the continent, and map the size of the point onto the life Expectancy:\n\np + geom_point(aes(col=continent, shape=continent, size=lifeExp))\n\n\n\n\nNow, this isn’t a great plot because there are several aesthetic mappings that are redundant. Life expectancy is mapped to both the y-axis and the size of the points – the size mapping is superfluous. Similarly, continent is mapped to both the color and the point character (the shape is superfluous). Let’s get rid of that, but let’s make the points a little bigger outsize of an aesthetic mapping.\n\np + geom_point(aes(col=continent), size=3)\n\n\n\n\n\n\n\n\n\n\nExercise 1\n\n\n\nRe-create this same plot from scratch without saving anything to a variable. That is, start from the ggplot call.\n\nStart with the ggplot() function.\nUse the gm data.\nMap gdpPercap to the x-axis and lifeExp to the y-axis.\nAdd points to the plot\n\nMake the points size 3\nMap continent onto the aesthetics of the point\n\nUse a log10 scale for the x-axis.\n\n\n\n\n\n\n\n\n\n5.3.1 Adding layers\nLet’s add a fitted curve to the points. Recreate the plot in the p object if you need to.\n\np &lt;- ggplot(gm, aes(gdpPercap, lifeExp)) + scale_x_log10()\np + geom_point() + geom_smooth()\n\n\n\n\nBy default geom_smooth() will try to lowess for data with n&lt;1000 or generalized additive models for data with n&gt;1000. We can change that behavior by tweaking the parameters to use a thick red line, use a linear model instead of a GAM, and to turn off the standard error stripes.\n\np + geom_point() + geom_smooth(lwd=2, se=FALSE, method=\"lm\", col=\"red\")\n\n\n\n\nBut let’s add back in our aesthetic mapping to the continents. Notice what happens here. We’re mapping continent as an aesthetic mapping to the color of the points only – so geom_smooth() still works only on the entire data.\n\np + geom_point(aes(color = continent)) + geom_smooth()\n\n\n\n\nBut notice what happens here: we make the call to aes() outside of the geom_point() call, and the continent variable gets mapped as an aesthetic to any further geoms. So here, we get separate smoothing lines for each continent. Let’s do it again but remove the standard error stripes and make the lines a bit thicker.\n\np + aes(color = continent) + geom_point() + geom_smooth()\np + aes(color = continent) + geom_point() + geom_smooth(se=F, lwd=2)\n\n\n\n\n\n\n5.3.2 Faceting\nFacets display subsets of the data in different panels. There are a couple ways to do this, but facet_wrap() tries to sensibly wrap a series of facets into a 2-dimensional grid of small multiples. Just give it a formula specifying which variables to facet by. We can continue adding more layers, such as smoothing. If you have a look at the help for ?facet_wrap() you’ll see that we can control how the wrapping is laid out.\n\np + geom_point() + facet_wrap(~continent)\np + geom_point() + geom_smooth() + facet_wrap(~continent, ncol=1)\n\n\n\n\n\n\n5.3.3 Saving plots\nThere are a few ways to save ggplots. The quickest way, that works in an interactive session, is to use the ggsave() function. You give it a file name and by default it saves the last plot that was printed to the screen.\n\np + geom_point()\nggsave(file=\"myplot.png\")\n\nBut if you’re running this through a script, the best way to do it is to pass ggsave() the object containing the plot that is meant to be saved. We can also adjust things like the width, height, and resolution. ggsave() also recognizes the name of the file extension and saves the appropriate kind of file. Let’s save a PDF.\n\npfinal &lt;- p + geom_point() + geom_smooth() + facet_wrap(~continent, ncol=1)\nggsave(pfinal, file=\"myplot.pdf\", width=5, height=15)\n\n\n\n\n\n\n\nExercise 2\n\n\n\n\nMake a scatter plot of lifeExp on the y-axis against year on the x.\nMake a series of small multiples faceting on continent.\nAdd a fitted curve, smooth or lm, with and without facets.\nBonus: using geom_line() and and aesthetic mapping country to group=, make a “spaghetti plot”, showing semitransparent lines connected for each country, faceted by continent. Add a smoothed loess curve with a thick (lwd=3) line with no standard error stripe. Reduce the opacity (alpha=) of the individual black lines. Don’t show Oceania countries (that is, filter() the data where continent!=\"Oceania\" before you plot it)."
  },
  {
    "objectID": "ggplot2.html#plotting-bivariate-data-continuous-y-by-categorical-x",
    "href": "ggplot2.html#plotting-bivariate-data-continuous-y-by-categorical-x",
    "title": "5  Data Visualization with ggplot2",
    "section": "5.4 Plotting bivariate data: continuous Y by categorical X",
    "text": "5.4 Plotting bivariate data: continuous Y by categorical X\nWith the last example we examined the relationship between a continuous Y variable against a continuous X variable. A scatter plot was the obvious kind of data visualization. But what if we wanted to visualize a continuous Y variable against a categorical X variable? We sort of saw what that looked like in the last exercise. year is a continuous variable, but in this dataset, it’s broken up into 5-year segments, so you could almost think of each year as a categorical variable. But a better example would be life expectancy against continent or country.\nFirst, let’s set up the basic plot:\n\np &lt;- ggplot(gm, aes(continent, lifeExp)) \n\nThen add points:\n\np + geom_point()\n\n\n\n\nThat’s not terribly useful. There’s a big overplotting problem. We can try to solve with transparency:\n\np + geom_point(alpha=1/4)\n\n\n\n\nBut that really only gets us so far. What if we spread things out by adding a little bit of horizontal noise (aka “jitter”) to the data.\n\np + geom_jitter()\n\n\n\n\nNote that the little bit of horizontal noise that’s added to the jitter is random. If you run that command over and over again, each time it will look slightly different. The idea is to visualize the density at each vertical position, and spreading out the points horizontally allows you to do that. If there were still lots of over-plotting you might think about adding some transparency by setting the alpha= value for the jitter.\n\np + geom_jitter(alpha=1/2)\n\n\n\n\nProbably a more common visualization is to show a box plot:\n\np + geom_boxplot()\n\n\n\n\nBut why not show the summary and the raw data?\n\np + geom_jitter() + geom_boxplot()\n\n\n\n\nNotice how in that example we first added the jitter layer then added the boxplot layer. But the boxplot is now superimposed over the jitter layer. Let’s make the jitter layer go on top. Also, go back to just the boxplots. Notice that the outliers are represented as points. But there’s no distinction between the outlier point from the boxplot geom and all the other points from the jitter geom. Let’s change that. Notice the British spelling.\n\np + geom_boxplot(outlier.colour = \"red\") + geom_jitter(alpha=1/2)\n\n\n\n\nThere’s another geom that’s useful here, called a voilin plot.\n\np + geom_violin()\n\n\n\np + geom_violin() + geom_jitter(alpha=1/2)\n\n\n\n\nLet’s go back to our boxplot for a moment.\n\np + geom_boxplot()\n\n\n\n\nThis plot would be a lot more effective if the continents were shown in some sort of order other than alphabetical. To do that, we’ll have to go back to our basic build of the plot again and use the reorder function in our original aesthetic mapping. Here, reorder is taking the first variable, which is some categorical variable, and ordering it by the level of the mean of the second variable, which is a continuous variable. It looks like this\n\np &lt;- ggplot(gm, aes(x=reorder(continent, lifeExp), y=lifeExp))\n\n\np + geom_boxplot()\n\n\n\n\n\n\n\n\n\n\nExercise 3\n\n\n\n\nMake a jittered strip plot of GDP per capita against continent.\nMake a box plot of GDP per capita against continent.\nUsing a log10 y-axis scale, overlay semitransparent jittered points on top of box plots, where outlying points are colored.\nBONUS: Try to reorder the continents on the x-axis by GDP per capita. Why isn’t this working as expected? See ?reorder for clues.\n\n\n\n\n\n\n\n\n\n\n\n\n# A tibble: 5 × 2\n  continent `mean(gdpPercap)`\n  &lt;chr&gt;                 &lt;dbl&gt;\n1 Africa                2194.\n2 Americas              7136.\n3 Asia                  7902.\n4 Europe               14469.\n5 Oceania              18622.\n\n\n# A tibble: 5 × 2\n  continent `mean(log10(gdpPercap))`\n  &lt;chr&gt;                        &lt;dbl&gt;\n1 Africa                        3.15\n2 Americas                      3.74\n3 Asia                          3.51\n4 Europe                        4.06\n5 Oceania                       4.25"
  },
  {
    "objectID": "ggplot2.html#plotting-univariate-continuous-data",
    "href": "ggplot2.html#plotting-univariate-continuous-data",
    "title": "5  Data Visualization with ggplot2",
    "section": "5.5 Plotting univariate continuous data",
    "text": "5.5 Plotting univariate continuous data\nWhat if we just wanted to visualize distribution of a single continuous variable? A histogram is the usual go-to visualization. Here we only have one aesthetic mapping instead of two.\n\np &lt;- ggplot(gm, aes(lifeExp))\n\n\np + geom_histogram()\n\n\n\n\nWhen we do this ggplot lets us know that we’re automatically selecting the width of the bins, and we might want to think about this a little further.\n\np + geom_histogram(bins=30)\n\n\n\np + geom_histogram(bins=10)\n\n\n\np + geom_histogram(bins=200)\n\n\n\n\n\np + geom_histogram(bins=60)\n\n\n\n\nAlternative we could plot a smoothed density curve instead of a histogram:\n\np + geom_density()\n\n\n\n\nBack to histograms. What if we wanted to color this by continent?\n\np + geom_histogram(aes(color=continent))\n\n\n\n\nThat’s not what we had in mind. That’s just the outline of the bars. We want to change the fill color of the bars.\n\np + geom_histogram(aes(fill=continent))\n\n\n\n\nWell, that’s not exactly what we want either. If you look at the help for ?geom_histogram you’ll see that by default it stacks overlapping points. This isn’t really an effective visualization. Let’s change the position argument.\n\np + geom_histogram(aes(fill=continent), position=\"identity\")\n\n\n\n\nBut the problem there is that the histograms are blocking each other. What if we tried transparency?\n\np + geom_histogram(aes(fill=continent), position=\"identity\", alpha=1/3)\n\n\n\n\nThat’s somewhat helpful, and might work for two distributions, but it gets cumbersome with 5. Let’s go back and try this with density plots, first changing the color of the line:\n\np + geom_density(aes(color=continent))\n\n\n\n\nThen by changing the color of the fill and setting the transparency to 25%:\n\np + geom_density(aes(fill=continent), alpha=1/4)\n\n\n\n\n\n\n\n\n\n\nExercise 4\n\n\n\n\nPlot a histogram of GDP Per Capita.\nDo the same but use a log10 x-axis.\nStill on the log10 x-axis scale, try a density plot mapping continent to the fill of each density distribution, and reduce the opacity.\nStill on the log10 x-axis scale, make a histogram faceted by continent and filled by continent. Facet with a single column (see ?facet_wrap for help).\nSave this figure to a 6x10 PDF file."
  },
  {
    "objectID": "ggplot2.html#publication-ready-plots-themes",
    "href": "ggplot2.html#publication-ready-plots-themes",
    "title": "5  Data Visualization with ggplot2",
    "section": "5.6 Publication-ready plots & themes",
    "text": "5.6 Publication-ready plots & themes\nLet’s make a plot we made earlier (life expectancy versus the log of GDP per capita with points colored by continent with lowess smooth curves overlaid without the standard error ribbon):\n\np &lt;- ggplot(gm, aes(gdpPercap, lifeExp)) \np &lt;- p + scale_x_log10()\np &lt;- p + aes(col=continent) + geom_point() + geom_smooth(lwd=2, se=FALSE)\n\nGive the plot a title and axis labels:\n\np &lt;- p + ggtitle(\"Life expectancy vs GDP by Continent\")\np &lt;- p + xlab(\"GDP Per Capita (USD)\") + ylab(\"Life Expectancy (years)\")\n\nBy default, the “gray” theme is the usual background (I’ve changed this course website to use the black and white background for all images).\n\np + theme_gray()\n\n\n\n\nWe could also get a black and white background:\n\np + theme_bw()\n\n\n\n\nOr go a step further and remove the gridlines:\n\np + theme_classic()\n\n\n\n\nFinally, there’s another package that gives us lots of different themes. Install it if you don’t have it already. Install all its dependencies along with it.\n\ninstall.packages(\"ggthemes\", dependencies = TRUE)\n\n\nlibrary(ggthemes)\np &lt;- ggplot(gm, aes(gdpPercap, lifeExp)) \np &lt;- p + scale_x_log10()\np &lt;- p + aes(col=continent) + geom_point() + geom_smooth(lwd=2, se=FALSE)\np + theme_excel()\np + theme_excel() + scale_colour_excel()\np + theme_gdocs() + scale_colour_gdocs()\np + theme_stata() + scale_colour_stata()\np + theme_wsj() + scale_colour_wsj()\np + theme_economist() \np + theme_fivethirtyeight()\np + theme_tufte()"
  },
  {
    "objectID": "tidyeda.html#chapter-overview",
    "href": "tidyeda.html#chapter-overview",
    "title": "6  Refresher: Tidy Exploratory Data Analysis",
    "section": "6.1 Chapter overview",
    "text": "6.1 Chapter overview\nThis is a refresher chapter designed to be read after completing all the chapters that came before it.\nThe data and analyses here were inspired by the Tidy Tuesday project – a weekly social data project in R from the R for Data Science online learning community @R4DScommunity.\nWe’re going to use two different data sets. One containing data on movie budgets and profits that was featured in a FiveThirtyEight article on horror movies and profits, and another with data on college majors and income from the American Community Survey.\nPackages needed for this analysis are loaded below. If you don’t have one of these packages installed, simply install it once using install.packages(\"PackageName\"). A quick note on the tidyverse package (https://www.tidyverse.org/): the tidyverse is a collection of other packages that are often used together. When you install or load tidyverse, you also install and load all the packages that we’ve used previously: dplyr, tidyr, ggplot2, as well as several others. Because we’ll be using so many different packages from the tidyverse collection, it’s more efficient load this “meta-package” rather than loading each individual package separately.\n\nlibrary(tidyverse)\nlibrary(ggrepel)\nlibrary(scales)\nlibrary(lubridate)\n\nI’ll demonstrate some functionality from these other packages. They’re handy to have installed, but are not strictly required.\n\nlibrary(plotly)\nlibrary(DT)"
  },
  {
    "objectID": "tidyeda.html#horror-movies-profit",
    "href": "tidyeda.html#horror-movies-profit",
    "title": "6  Refresher: Tidy Exploratory Data Analysis",
    "section": "6.2 Horror Movies & Profit",
    "text": "6.2 Horror Movies & Profit\n\n6.2.1 About the data\nThe raw data can be downloaded here: movies.csv.\nThis data was featured in the FiveThirtyEight article, “Scary Movies Are The Best Investment In Hollywood”.\n\n“Horror movies get nowhere near as much draw at the box office as the big-time summer blockbusters or action/adventure movies – the horror genre accounts for only 3.7 percent of the total box-office haul this year – but there’s a huge incentive for studios to continue pushing them out.\nThe return-on-investment potential for horror movies is absurd. For example, “Paranormal Activity” was made for $450,000 and pulled in $194 million – 431 times the original budget. That’s an extreme, I-invested-in-Microsoft-when-Bill-Gates-was-working-in-a-garage case, but it’s not rare. And that’s what makes horror such a compelling genre to produce.”\n\n– Quote from Walt Hickey for fivethirtyeight article.\nData dictionary (data from the-numbers.com):\n\n\n\n\n\n\n\n\n\nHeader\nDescription\n\n\n\n\nrelease_date\nmonth-day-year\n\n\nmovie\nMovie title\n\n\nproduction_budget\nMoney spent to create the film\n\n\ndomestic_gross\nGross revenue from USA\n\n\nworldwide_gross\nGross worldwide revenue\n\n\ndistributor\nThe distribution company\n\n\nmpaa_rating\nAppropriate age rating by the US-based rating agency\n\n\ngenre\nFilm category\n\n\n\n\n\n\n\n6.2.2 Import and clean\nIf you haven’t already loaded the packages we need, go ahead and do that now.\n\nlibrary(tidyverse)\nlibrary(ggrepel)\nlibrary(scales)\nlibrary(lubridate)\n\nNow, use the read_csv() function from readr (loaded when you load tidyverse), to read in the movies.csv dataset into a new object called mov_raw.\n\nmov_raw &lt;- read_csv(\"data/movies.csv\")\nmov_raw\n\nLet’s clean up the data a bit. Remember, construct your pipeline one step at a time first. Once you’re happy with the result, assign the results to a new object, mov.\n\nGet rid of the blank X1 Variable.\nChange release date into an actual date.\nCalculate the return on investment as the worldwide_gross/production_budget.\nCalculate the percentage of total gross as domestic revenue.\nGet the year, month, and day out of the release date.\nRemove rows where the revenue is $0 (unreleased movies, or data integrity problems), and remove rows missing information about the distributor. Go ahead and remove any data where the rating is unavailable also.\n\n\nmov &lt;- mov_raw |&gt;\n  select(-...1) |&gt;\n  mutate(release_date = mdy(release_date)) |&gt;\n  mutate(roi = worldwide_gross / production_budget) |&gt;\n  mutate(pct_domestic = domestic_gross / worldwide_gross) |&gt;\n  mutate(year = year(release_date)) |&gt; \n  mutate(month = month(release_date, label = TRUE)) |&gt; \n  mutate(day = wday(release_date, label = TRUE)) |&gt; \n  arrange(desc(release_date)) |&gt;\n  filter(worldwide_gross &gt; 0) |&gt;\n  filter(!is.na(distributor)) |&gt;\n  filter(!is.na(mpaa_rating))\nmov\n\nLet’s take a look at the distribution of release date.\n\nggplot(mov, aes(year)) + geom_histogram(bins=40)\n\n\n\n\nThere doesn’t appear to be much documented berfore 1975, so let’s restrict (read: filter) the dataset to movies made since 1975. Also, we’re going to be doing some analyses by year, and since the data for 2018 is still incomplete, let’s remove all of 2018. Let’s get anything produced in 1975 and after (&gt;=1975) but before 2018 (&lt;2018). Add the final filter statement to the assignment, and make the plot again.\n\nmov &lt;- mov_raw |&gt;\n  select(-...1) |&gt;\n  mutate(release_date = mdy(release_date)) |&gt;\n  mutate(roi = worldwide_gross / production_budget) |&gt;\n  mutate(pct_domestic = domestic_gross / worldwide_gross) |&gt;\n  mutate(year = year(release_date)) |&gt; \n  mutate(month = month(release_date, label = TRUE)) |&gt; \n  mutate(day = wday(release_date, label = TRUE)) |&gt; \n  arrange(desc(release_date)) |&gt;\n  filter(worldwide_gross &gt; 0) |&gt;\n  filter(!is.na(distributor)) |&gt;\n  filter(!is.na(mpaa_rating)) |&gt; \n  filter(year&gt;=1975 & year &lt;2018)\nmov\n\n\n\n6.2.3 Exploratory Data Analysis\nWhich days are movies released on? The dplyr count() function counts the number of occurances of a particular variable. It’s shorthand for a group_by() followed by summarize(n=n()). The geom_col() makes a bar chart where the height of the bar is the count of the number of cases, y, at each x position. Feel free to add labels if you want.\n\nmov |&gt; \n  count(day, sort=TRUE) |&gt; \n  ggplot(aes(day, n)) + \n  geom_col() + \n  labs(x=\"\", y=\"Number of movies released\", \n       title=\"Which days are movies released on?\", \n       caption=\"Adapted from @jaseziv\") + \n  theme_classic()\n\n\n\n\n\n\n\n\n\n\nExercise 1\n\n\n\nDoes the day a movie is release affect revenue? Make a boxplot showing the worldwide gross revenue for each day.\n\n\n\n\n\n\n\nWhat about month? Just swap day for month in the code.\n\nmov |&gt; \n  ggplot(aes(month, worldwide_gross)) + \n  geom_boxplot(col=\"gray10\", fill=\"gray90\") + \n  scale_y_log10(labels=dollar_format()) +\n  labs(x=\"Release month\",\n       y=\"Worldwide gross revenue\", \n       title=\"Does the day a movie is release affect revenue?\", \n       caption=\"Adapted from @jaseziv\") + \n  theme_classic()\n\n\n\n\nWe could also get a quantitative look at the average revenue by day using a group-by summarize operation:\n\nmov |&gt; \n  group_by(day) |&gt; \n  summarize(rev=mean(worldwide_gross))\n\n# A tibble: 7 × 2\n  day          rev\n  &lt;ord&gt;      &lt;dbl&gt;\n1 Sun    70256412.\n2 Mon   141521289.\n3 Tue   177233110.\n4 Wed   130794183.\n5 Thu   194466996.\n6 Fri    90769834.\n7 Sat    89889497.\n\n\nIt looks like summer months and holiday months at the end of the year fare well. Let’s look at a table and run a regression analysis.\n\nmov |&gt; \n  group_by(month) |&gt; \n  summarize(rev=mean(worldwide_gross))\n\n\nmov |&gt; \n  mutate(month=factor(month, ordered=FALSE)) |&gt; \n  lm(worldwide_gross~month, data=_) |&gt; \n  summary()\n\nWhat does the worldwide movie market look like by decade? Let’s first group by year and genre and compute the sum of the worldwide gross revenue. After we do that, let’s plot a barplot showing year on the x-axis and the sum of the revenue on the y-axis, where we’re passing the genre variable to the fill aesthetic of the bar.\n\nmov |&gt; \n  group_by(year, genre) |&gt; \n  summarize(revenue=sum(worldwide_gross)) |&gt; \n  ggplot(aes(year, revenue)) + \n  geom_col(aes(fill=genre)) + \n  scale_y_continuous(labels=dollar_format()) + \n  labs(x=\"\", y=\"Worldwide revenue\", title=\"Worldwide Film Market by Decade\")\n\n\n\n\nWhich distributors produce the highest grossing movies by genre? First let’s lump all distributors together into 5 major distributors with the most movies, lumping all others into an “Other” category. The fct_lump function from the forcats package (loaded with tidyverse) will do this for you. Take a look at just that result first. Then let’s plot a geom_col(), which plots the actual value of the thing we put on the y-axis (worldwide gross revenue in this case). Because geom_col() puts all the values on top of one another, the highest value will be the one displayed. Let’s add position=\"dodge\" so they’re beside one another instead of stacked. We can continue to add additional things to make the plot pretty. I like the look of this better when we flip the coordinate system with coord_flip().\n\nmov |&gt; \n  mutate(distributor=fct_lump(distributor, 5)) |&gt; \n  ggplot(aes(distributor, worldwide_gross)) + geom_col(aes(fill=genre), position=\"dodge\") + \n  scale_y_continuous(labels = dollar_format()) + \n  labs(x=\"\",\n       y=\"Worldwide revenue\", \n       title=\"Which distributors produce the highest grossing movies by genre?\",\n       caption=\"Adapted from @JamesCBorders\") + \n  coord_flip()\n\n\n\n\nIt looks like Universal made the highest-grossing action and adventure movies, while Warner Bros made the highest grossing horror movies.\nBut what about return on investment?\n\nmov |&gt; \n  group_by(genre) |&gt; \n  summarize(roi=mean(roi))\n\n# A tibble: 5 × 2\n  genre       roi\n  &lt;chr&gt;     &lt;dbl&gt;\n1 Action     2.82\n2 Adventure  3.60\n3 Comedy     3.48\n4 Drama      3.40\n5 Horror    11.2 \n\n\nIt looks like horror movies have overwhelmingly the highest return on investment. Let’s look at this across the top distributors.\n\n\n\n\n\n\nExercise 2\n\n\n\nModify the code above to look at return on investment instead of worldwide gross revenue.\n\n\n\n\n\n\n\nLet’s make a scatter plot showing the worldwide gross revenue over the production budget. Let’s make the size of the point relative to the ROI. Let’s add a “breakeven” line that has a slope of 1 and a y-intercept of zero. Let’s facet by genre.\n\nmov |&gt;\n  ggplot(aes(production_budget, worldwide_gross)) +\n  geom_point(aes(size = roi)) +\n  geom_abline(slope = 1, intercept = 0, col = \"red\") +\n  facet_wrap( ~ genre) +\n  scale_x_log10(labels = dollar_format()) +\n  scale_y_log10(labels = dollar_format()) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(x = \"Production Budget\", \n       y = \"Worldwide gross revenue\", \n       size = \"Return on Investment\")\n\n\n\n\nGenerally most of the points lie above the “breakeven” line. This is good – if movies weren’t profitable they wouldn’t keep making them. Proportionally there seem to be many more larger points in the Horror genre, indicative of higher ROI.\nLet’s create a faceted grid showing distributor by genre. Paramount and Other distributors have the largest share of low-budget high-revenue horror films.\n\nmov |&gt;\n  mutate(distributor = fct_lump(distributor, 5)) |&gt;\n  ggplot(aes(production_budget, worldwide_gross)) +\n  geom_point(aes(size = roi)) +\n  geom_abline(slope = 1, intercept = 0) +\n  facet_grid(distributor ~ genre) +\n  scale_x_log10(labels = dollar_format()) + \n  scale_y_log10(labels = dollar_format()) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(x = \"Production Budget\", \n       y = \"Worldwide gross revenue\", \n       size = \"Return on Investment\")\n\n\n\n\nWhat were those super profitable movies? Looks like they’re mostly horror movies. One thing that’s helpful to do here is to make movies a factor variable, reordering its levels by the median ROI. Look at the help for ?fct_reorder for this. I also like to coord_flip() this plot.\n\nmov |&gt; \n  arrange(desc(roi)) |&gt; \n  head(20) |&gt; \n  mutate(movie=fct_reorder(movie, roi)) |&gt;\n  ggplot(aes(movie, roi)) +\n  geom_col(aes(fill=genre)) + \n  labs(x=\"Movie\", \n       y=\"Return On Investment\", \n       title=\"Top 20 most profitable movies\", \n       caption=\"Adapted from @DaveBloom11\") + \n  coord_flip() + \n  geom_text(aes(label=paste0(round(roi), \"x \"), hjust=1), col=\"white\")\n\n\n\n\nIt might be informative to run the same analysis for movies that had either exclusive US distribution, or no US distribution at all. We could simply filter for movies with 100% of the revenue coming from domestic gross revenue US only, or 0% from domestic (no US distribution). Just add a filter statement in the pipeline prior to plotting.\n\nmov |&gt; \n  filter(pct_domestic==1) |&gt; \n  arrange(desc(roi)) |&gt; \n  head(20) |&gt; \n  mutate(movie=fct_reorder(movie, roi)) |&gt; \n  ggplot(aes(movie, roi)) +\n  geom_col(aes(fill=genre)) + \n  labs(x=\"Movie\", \n       y=\"Return On Investment\", \n       title=\"Top 20 most profitable movies with US-only distribution\", \n       caption=\"Adapted from @DaveBloom11\") + \n  coord_flip() + \n  geom_text(aes(label=paste0(round(roi), \"x \"), hjust=1), col=\"white\")\n\n\nmov |&gt; \n  filter(pct_domestic==0) |&gt; \n  arrange(desc(roi)) |&gt; \n  head(20) |&gt; \n  mutate(movie=fct_reorder(movie, roi)) |&gt; \n  ggplot(aes(movie, roi)) +\n  geom_col(aes(fill=genre)) + \n  labs(x=\"Movie\", \n       y=\"Return On Investment\", \n       title=\"Top 20 most profitable movies with no US distribution\", \n       caption=\"Adapted from @DaveBloom11\") + \n  coord_flip()\n\nWhat about movie ratings? R-rated movies have a lower average revenue but ROI isn’t substantially less. The n() function is a helper function that just returns the number of rows for each group in a grouped data frame. We can see that while G-rated movies have the highest mean revenue, there were relatively few of them produced, and had a lower total revenue. There were more R-rated movies, but PG-13 movies really drove the total revenue worldwide.\n\nmov |&gt;\n  group_by(mpaa_rating) |&gt;\n  summarize(\n    meanrev = mean(worldwide_gross),\n    totrev = sum(worldwide_gross),\n    roi = mean(roi),\n    number = n()\n  )\n\n# A tibble: 4 × 5\n  mpaa_rating    meanrev       totrev   roi number\n  &lt;chr&gt;            &lt;dbl&gt;        &lt;dbl&gt; &lt;dbl&gt;  &lt;int&gt;\n1 G           189913348   13863674404  4.42     73\n2 PG          147227422.  78324988428  4.64    532\n3 PG-13       113477939. 120173136920  3.06   1059\n4 R            63627931.  92451383780  4.42   1453\n\n\nAre there fewer R-rated movies being produced? Not really. Let’s look at the overall number of movies with any particular rating faceted by genre.\n\nmov |&gt; \n  count(mpaa_rating, genre) |&gt; \n  ggplot(aes(mpaa_rating, n)) + \n  geom_col() + \n  facet_wrap(~genre) +\n  labs(x=\"MPAA Rating\",\n       y=\"Number of films\", \n       title=\"Number of films by rating for each genre\")\n\n\n\n\nWhat about the distributions of ratings?\n\nmov |&gt; \n  ggplot(aes(worldwide_gross)) + \n  geom_histogram() + \n  facet_wrap(~mpaa_rating) + \n  scale_x_log10(labels=dollar_format()) + \n  labs(x=\"Worldwide gross revenue\", \n       y=\"Count\",\n       title=\"Distribution of revenue by genre\")\n\n\n\n\n\nmov |&gt; \n  ggplot(aes(mpaa_rating, worldwide_gross)) + \n  geom_boxplot(col=\"gray10\", fill=\"gray90\") + \n  scale_y_log10(labels=dollar_format()) + \n  labs(x=\"MPAA Rating\", y=\"Worldwide gross revenue\", title=\"Revenue by rating\")\n\n\n\n\nBut, dont be fooled. Yes, on average G-rated movies look to perform better. But there aren’t that many of them being produced, and they aren’t bringing in the lions share of revenue.\n\nmov |&gt; \n  count(mpaa_rating) |&gt; \n  ggplot(aes(mpaa_rating, n)) + \n  geom_col() + \n  labs(x=\"MPAA Rating\", \n       y=\"Count\",\n       title=\"Total number of movies produced for each rating\")\n\n\n\n\n\nmov |&gt; \n  group_by(mpaa_rating) |&gt; \n  summarize(total_revenue=sum(worldwide_gross)) |&gt; \n  ggplot(aes(mpaa_rating, total_revenue)) + \n  geom_col() + \n  scale_y_continuous(label=dollar_format()) + \n  labs(x=\"MPAA Rating\", \n       y=\"Total worldwide revenue\",\n       title=\"Total worldwide revenue for each rating\")\n\n\n\n\n\n\n6.2.4 Join to IMDB reviews\nLook back at the dplyr reference on joins. An inner join lets you take two tables, match by a common column (or columns), and return rows with an entry in both, returning all columns in each table. I’ve downloaded all the data underlying IMDB (imdb.com/interfaces), and created a reduced dataset having ratings for all the movies in IMDB. Let’s join the movie data we have here with IMDB ratings. Download the data here: movies_imdb.csv. Once you’ve downloaded it, read it in with read_csv():\n\nimdb &lt;- read_csv(\"data/movies_imdb.csv\")\nimdb\n\nThere are 177,519 movies in this dataset. There are 3,117 movies in the data we’ve already been using. Let’s see how many we have that intersect in both:\n\nmovimdb &lt;- inner_join(mov, imdb, by=\"movie\")\nmovimdb\n\nIt turns out there are only 2,591 rows in the joined dataset. That’s because there were some rows in mov that weren’t in imdb, and vice versa. Some of these are truly cases where there isn’t an entry in one. Others are cases where it’s Star Wars Ep. I: The Phantom Menace in one dataset but Star Wars: Episode I - The Phantom Menace in another, or Mr. & Mrs. Smith versus Mr. and Mrs. Smith. Others might be ascii versus unicode text incompatibility, e.g. the hyphen “-” versus the endash, “–”.\nNow that you have the datasets joined, try a few more exercises!\n\n\n\n\n\n\nExercise 3\n\n\n\nSeparately for each MPAA rating, display the mean IMDB rating and mean number of votes cast.\n\n\n# A tibble: 4 × 3\n  mpaa_rating meanimdb meanvotes\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;\n1 G               6.54   132015.\n2 PG              6.31    81841.\n3 PG-13           6.25   102740.\n4 R               6.58   107575.\n\n\n\n\n\n\n\n\n\n\nExercise 4\n\n\n\nDo the same but for each movie genre.\n\n\n# A tibble: 5 × 3\n  genre     meanimdb meanvotes\n  &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt;\n1 Action        6.28   154681.\n2 Adventure     6.27   130027.\n3 Comedy        6.08    71288.\n4 Drama         6.88    91101.\n5 Horror        5.90    89890.\n\n\n\n\n\n\n\n\n\n\nExercise 5\n\n\n\nDo the same but for each distributor, after lumping distributors in a mutate statement to the top 4 distributors, as we’ve done before.\n\n\n# A tibble: 5 × 3\n  distributor        meanimdb meanvotes\n  &lt;fct&gt;                 &lt;dbl&gt;     &lt;dbl&gt;\n1 Paramount Pictures     6.44   130546.\n2 Sony Pictures          6.25   111913.\n3 Universal              6.44   130028.\n4 Warner Bros.           6.37   133997.\n5 Other                  6.46    86070.\n\n\n\n\n\n\n\n\n\n\nExercise 6\n\n\n\nCreate a boxplot visually summarizing what you saw in #1 and #2 above. That is, show the distribution of IMDB ratings for each genre, but map the fill aesthetic for the boxplot onto the MPAA rating. Here we can see that Dramas tend to get a higher IMDB rating overall. Across most categories R rated movies fare better. We also see from this that there are no Action or Horror movies rated G (understandably!). In fact, after this I actually wanted to see what the “Horror” movies were having a PG rating that seemed to do better than PG-13 or R rated Horror movies.\n\n\n\n\n\n\nmovimdb |&gt; \n  filter(mpaa_rating==\"PG\", genre==\"Horror\") |&gt; \n  select(release_date, movie, worldwide_gross, imdb, votes)\n\n# A tibble: 5 × 5\n  release_date movie                    worldwide_gross  imdb  votes\n  &lt;date&gt;       &lt;chr&gt;                              &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 2015-10-16   Goosebumps                     158905324   6.3  67744\n2 1983-06-24   Twilight Zone: The Movie        29500000   6.5  29313\n3 1982-06-04   Poltergeist                    121706019   7.4 124178\n4 1978-06-16   Jaws 2                         208900376   5.7  61131\n5 1975-06-20   Jaws                           470700000   8   492525\n\n\n\n\n\n\n\n\n\n\nExercise 7\n\n\n\nCreate a scatter plot of worldwide gross revenue by IMDB rating, with the gross revenue on a log scale. Color the points by genre. Add a trendline with method=\"lm\".\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 8\n\n\n\nCreate the same plot, this time putting the number of votes on the x-axis, and make both the x and y-axes log scale.\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 9\n\n\n\nCreate the above plots, but this time plot the ROI instead of the gross revenue.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 10\n\n\n\nIs there a relationship between the release date and the IMDB ratings or votes cast? Surprisingly, there doesn’t appear to be one.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 11\n\n\n\nIs there a relationship between the IMDB rating and the number of votes cast? It appears so, at least as you get toward the movies with the very largest number of ratings.\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 12\n\n\n\nLooking at that above plot, I’m interested in (a) what are those movies with the largest number of votes? and (b) what are those movies with at least 50,000 votes that have the worst scores?\n\nmovimdb |&gt; \n  arrange(desc(votes)) |&gt; \n  head(10) |&gt; \n  select(release_date, movie, roi, imdb, votes)\n\n# A tibble: 10 × 5\n   release_date movie                      roi  imdb   votes\n   &lt;date&gt;       &lt;chr&gt;                    &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1 1994-09-23   The Shawshank Redemption  1.13   9.3 2009031\n 2 1999-10-15   Fight Club                1.55   8.8 1607508\n 3 1994-10-14   Pulp Fiction             26.6    8.9 1568242\n 4 1994-07-06   Forrest Gump             12.4    8.8 1529711\n 5 1999-03-31   The Matrix                7.13   8.7 1441344\n 6 2014-11-05   Interstellar              4.05   8.6 1221035\n 7 2005-06-15   Batman Begins             2.39   8.3 1149747\n 8 2009-08-21   Inglourious Basterds      4.53   8.3 1070753\n 9 1998-07-24   Saving Private Ryan       7.46   8.6 1058789\n10 1993-12-15   Schindler's List         12.9    8.9 1036894\n\n\nNo surprises there. These are some of the most universally loved films ever made. Interesting that the return on investment varies wildly (1.13x for the highest rated movie of all time, up to 26x for Pulp Fiction, which had to pay for an all-star cast).\n\nmovimdb |&gt; \n  filter(votes&gt;50000) |&gt; \n  arrange(imdb) |&gt; \n  head(10) |&gt; \n  select(release_date, movie, roi, imdb, votes)\n\n# A tibble: 10 × 5\n   release_date movie                      roi  imdb  votes\n   &lt;date&gt;       &lt;chr&gt;                    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1 2008-08-29   Disaster Movie           1.84    1.9  80918\n 2 2007-01-26   Epic Movie               4.34    2.3  96271\n 3 2006-02-17   Date Movie               4.26    2.8  53781\n 4 2011-11-11   Jack and Jill            1.91    3.3  68909\n 5 2004-07-23   Catwoman                 0.821   3.3  98513\n 6 1997-06-20   Batman & Robin           1.91    3.7 212085\n 7 1997-06-13   Speed 2: Cruise Control  1.37    3.8  67296\n 8 1994-12-23   Street Fighter           2.84    3.8  58912\n 9 2015-02-13   Fifty Shades of Grey    14.3     4.1 269355\n10 2010-07-01   The Last Airbender       2.13    4.1 133813\n\n\nInteresting that several of these having such terrible reviews still have fairly high return on investment (&gt;14x for Fifty Shades of Grey!)."
  },
  {
    "objectID": "tidyeda.html#college-majors-income",
    "href": "tidyeda.html#college-majors-income",
    "title": "6  Refresher: Tidy Exploratory Data Analysis",
    "section": "6.3 College Majors & Income",
    "text": "6.3 College Majors & Income\n\n6.3.1 About the data\nThis is the data behind the FiveThirtyEight article, “The Economic Guide To Picking A College Major”.\n\nAll data is from American Community Survey 2010-2012 Public Use Microdata Series.\nOriginal data and more: http://www.census.gov/programs-surveys/acs/data/pums.html.\nDocumentation: http://www.census.gov/programs-surveys/acs/technical-documentation/pums.html\n\nData Dictionary:\n\n\n\n\n\n\n\n\n\nHeader\nDescription\n\n\n\n\nRank\nRank by median earnings\n\n\nMajor_code\nMajor code, FO1DP in ACS PUMS\n\n\nMajor\nMajor description\n\n\nMajor_category\nCategory of major from Carnevale et al\n\n\nTotal\nTotal number of people with major\n\n\nSample_size\nSample size (unweighted) of full-time, year-round ONLY (used for earnings)\n\n\nMen\nMale graduates\n\n\nWomen\nFemale graduates\n\n\nShareWomen\nWomen as share of total\n\n\nEmployed\nNumber employed (ESR == 1 or 2)\n\n\nFull_time\nEmployed 35 hours or more\n\n\nPart_time\nEmployed less than 35 hours\n\n\nFull_time_year_round\nEmployed at least 50 weeks (WKW == 1) and at least 35 hours (WKHP &gt;= 35)\n\n\nUnemployed\nNumber unemployed (ESR == 3)\n\n\nUnemployment_rate\nUnemployed / (Unemployed + Employed)\n\n\nMedian\nMedian earnings of full-time, year-round workers\n\n\nP25th\n25th percentile of earnigns\n\n\nP75th\n75th percentile of earnings\n\n\nCollege_jobs\nNumber with job requiring a college degree\n\n\nNon_college_jobs\nNumber with job not requiring a college degree\n\n\nLow_wage_jobs\nNumber in low-wage service jobs\n\n\n\n\n\n\n\n6.3.2 Import and clean\nIf you haven’t already loaded the packages we need, go ahead and do that now.\n\nlibrary(tidyverse)\nlibrary(ggrepel)\nlibrary(scales)\nlibrary(lubridate)\n\nNow, use the read_csv() function from readr (loaded when you load tidyverse), to read in the grads.csv dataset into a new object called grads_raw.\nRead in the raw data.\n\ngrads_raw &lt;- read_csv(\"data/grads.csv\")\ngrads_raw\n\nNow clean it up a little bit. Remember, construct your pipeline one step at a time first. Once you’re happy with the result, assign the results to a new object, grads.\n\nMake sure the data is arranged descending by Median income. It should be already, but don’t make any assumptions.\nMake the Major sentence case so it’s not ALL CAPS. This uses the str_to_title() function from the stringr package, loaded with tidyverse.\nMake it a factor variable with levels ordered according to median income.\nDo the same for Major_category – make it a factor variable with levels ordered according to median income.\nAdd a new variable, pct_college, that’s the proportion of graduates employed in a job requiring a college degree. We’ll do some analysis with this later on to look at under-employment.\nThere’s one entry (“Military technologies”) that has no data about employment. This new variable is therefore missing. Let’s remove this entry.\nThere’s an entry with an unknown number of total majors, men, or women (“Food Science”). Let’s remove it by removing anything with a missing Total number.\n\n\ngrads &lt;- grads_raw |&gt;\n  arrange(desc(Median)) |&gt;\n  mutate(Major = str_to_title(Major)) |&gt; \n  mutate(Major = fct_reorder(Major, Median)) |&gt; \n  mutate(Major_category = fct_reorder(Major_category, Median)) |&gt; \n  mutate(pct_college=College_jobs/(College_jobs+Non_college_jobs)) |&gt; \n  filter(!is.na(pct_college)) |&gt; \n  filter(!is.na(Total))\ngrads\n\n\n\n6.3.3 Exploratory Data Analysis\nLet’s start with an exercise.\n\n\n\n\n\n\nExercise 13\n\n\n\nRemake table 1 from the FiveThirtyEight article.\n\nUse the select() function to get only the columns you care about.\nUse head(10) or tail(10) to show the first or last few rows.\n\n\n\n                                       Major    Major_category Total Median\n1                      Petroleum Engineering       Engineering  2339 110000\n2             Mining And Mineral Engineering       Engineering   756  75000\n3                  Metallurgical Engineering       Engineering   856  73000\n4  Naval Architecture And Marine Engineering       Engineering  1258  70000\n5                       Chemical Engineering       Engineering 32260  65000\n6                        Nuclear Engineering       Engineering  2573  65000\n7                          Actuarial Science          Business  3777  62000\n8                 Astronomy And Astrophysics Physical Sciences  1792  62000\n9                     Mechanical Engineering       Engineering 91227  60000\n10                    Electrical Engineering       Engineering 81527  60000\n\n\n\n\n                                           Major            Major_category\n1  Communication Disorders Sciences And Services                    Health\n2                      Early Childhood Education                 Education\n3                        Other Foreign Languages Humanities & Liberal Arts\n4                         Drama And Theater Arts                      Arts\n5                       Composition And Rhetoric Humanities & Liberal Arts\n6                                        Zoology    Biology & Life Science\n7                         Educational Psychology  Psychology & Social Work\n8                            Clinical Psychology  Psychology & Social Work\n9                          Counseling Psychology  Psychology & Social Work\n10                               Library Science                 Education\n   Total Median\n1  38279  28000\n2  37589  28000\n3  11204  27500\n4  43249  27000\n5  18953  27000\n6   8409  26000\n7   2854  25000\n8   2838  25000\n9   4626  23400\n10  1098  22000\n\n\n\n\nIf you have the DT package installed, you can make an interactive table just like the one in the FiveThirtyEight article.\n\nlibrary(DT)\ngrads |&gt; \n  select(Major, Major_category, Total, Median) |&gt; \n  datatable()\n\n\n\n\n\n\nLet’s continue with more exploratory data analysis (EDA). Let’s plot median income by the total number of majors. Is there a correlation between the number of people majoring in a topic and that major’s median income? The expand_limits lets you put $0 on the Y-axis. You might try making the x-axis scale logarithmic.\n\nggplot(grads, aes(Total, Median)) + \n  geom_point() + \n  geom_smooth(method=\"lm\") + \n  expand_limits(y=0) + \n  scale_x_log10(label=scales::number_format()) + \n  scale_y_continuous(label=dollar_format()) + \n  labs(x=\"Total number of majors\", \n       y=\"Median income\", \n       title=\"Median income as a function of major popularity\")\n\n\n\n\nYou could run a regression analysis to see if there’s a trend.\n\nlm(Median~(Total), data=grads) |&gt; summary()\n\nWhat categories of majors make more money than others? Let’s make a boxplot of median income by major category. Let’s expand the limits to include 0 on the y-axis, and flip the coordinate system.\n\ngrads |&gt;\n  ggplot(aes(Major_category, Median)) +\n  geom_boxplot(aes(fill = Major_category)) +\n  expand_limits(y = 0) +\n  coord_flip() +\n  scale_y_continuous(labels = dollar_format()) +\n  theme(legend.position = \"none\") + \n  labs(x=\"Major category\",\n       y=\"Median income\", \n       title=\"Median income by major category\",\n       caption=\"Adapted from @drob\")\n\n\n\n\nWhat about unemployment rates? Let’s to the same thing here but before ggplot’ing, let’s mutate the major category to relevel it descending by the unemployment rate. Therefore the highest unemployment rate will be the first level of the factor. Let’s expand limits again, and flip the coordinate system.\n\ngrads |&gt;\n  mutate(Major_category=fct_reorder(Major_category, -Unemployment_rate)) |&gt; \n  ggplot(aes(Major_category, Unemployment_rate, fill = Major_category)) +\n  geom_boxplot() +\n  expand_limits(y = 0) +\n  coord_flip() +\n  scale_y_continuous(labels = percent_format()) +\n  theme(legend.position = \"none\") + \n  labs(x=\"Major category\", \n       y=\"Unemployment rate\",\n       title=\"Unemployment rate by major category\")\n\n\n\n\nMost of these make sense except for the high median and large variability of “Computers & Mathematics” category. Especially considering how these had the second highest median salary. Let’s see what these were. Perhaps it was the larger number of Computer and Information Systems, and Communication Technologies majors under this category that were dragging up the Unemployment rate.\n\ngrads |&gt; \n  filter(Major_category==\"Computers & Mathematics\") |&gt; \n  select(Major, Median, Sample_size, Unemployment_rate)\n\n\n\n\n\n\n\nExercise 14\n\n\n\nWhat about “underemployment?” Which majors have more students finding jobs requiring college degrees? This time make a boxplot of each major category’s percentage of majors having jobs requiring a college degree (pct_college). Do the same factor reordering.\n\n\n\n\n\n\n\nWhat are the highest earning majors? First, filter to majors having at least 100 samples to use for income data. Try changing head(20) to tail(20) to get the lowest earners.\n\ngrads |&gt;\n  filter(Sample_size &gt;= 100) |&gt;\n  head(20) |&gt;\n  ggplot(aes(Major, Median, color = Major_category)) +\n  geom_point() +\n  geom_errorbar(aes(ymin = P25th, ymax = P75th)) +\n  expand_limits(y = 0) +\n  scale_y_continuous(labels = dollar_format()) +\n  coord_flip() +\n  labs(title = \"What are the highest-earning majors?\",\n       subtitle = \"Top 20 majors with at least 100 graduates surveyed.\\nBars represent the 25th to 75th percentile.\",\n       x = \"\",\n       y = \"Median salary of gradates\", \n       caption=\"Adapted from @drob\")\n\n\n\n\nHow do the top majors break down by gender? This plot first gets the top 20 most popular majors by total overall students. It reorders the “Major” variable by the total number of people taking it. It then gathers the “Men” and “Women” variable into a column with the number of men or women, with a key column called “Gender” indicating whether you’re looking at men or women. It plots the total number in that major, and color-codes by gender.\n\ngrads |&gt;\n  arrange(desc(Total)) |&gt;\n  head(20) |&gt;\n  mutate(Major = fct_reorder(Major, Total)) |&gt;\n  gather(Gender, Number, Men, Women) |&gt;\n  ggplot(aes(Major, Number, fill = Gender)) +\n  geom_col() +\n  coord_flip() + \n  scale_y_continuous(labels=number_format()) + \n  labs(x=\"\", y=\"Total number of majors\", title=\"Gender breakdown by top majors\")\n\n\n\n\nWhat do earnings look like by gender? Let’s plot median salary by the Share of women in that major, making the size of the point proportional to the number of students enrolled in that major. Let’s also lump all the major categories together if they’re not one of the top four. I’m also passing the label= aesthetic mapping. You’ll see why in a few moments. For now, there is no geom that takes advantage of the label aesthetic.\n\np &lt;- grads |&gt; \n  mutate(Major_category = fct_lump(Major_category, 4)) |&gt;\n  ggplot(aes(ShareWomen, Median, label=Major)) + \n  geom_point(aes(size=Total, color=Major_category)) + \n  geom_smooth(method=\"lm\") + \n  expand_limits(y=0) + \n  scale_size_continuous(labels=number_format()) + \n  scale_y_continuous(labels=dollar_format()) + \n  scale_x_continuous(labels=percent_format()) + \n  labs(x=\"Proportion of women with major\", \n       title=\"Median income by the proportion of women in each major\")\np\n\n\n\n\nIf you have the plotly package installed, you can make an interactive graphic. Try hovering over the points, or using your mouse to click+drag a box around a segment of the plot to zoom in on.\n\nlibrary(plotly)\nggplotly(p)\n\n\n\n\n\nLet’s run a regression analysis to see if the proportion of women in the major is correlated with salary. It looks like every percentage point increase in the proportion of women in a particular major is correlated with a $23,650 decrease in salary.\n\nlm(Median ~ ShareWomen, data = grads, weights = Sample_size) |&gt; \n  summary()\n\n\nCall:\nlm(formula = Median ~ ShareWomen, data = grads, weights = Sample_size)\n\nWeighted Residuals:\n    Min      1Q  Median      3Q     Max \n-260544  -61278  -13324   33834  865216 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)    52079       1441  36.147   &lt;2e-16\nShareWomen    -23660       2410  -9.816   &lt;2e-16\n\nResidual standard error: 123300 on 169 degrees of freedom\nMultiple R-squared:  0.3631,    Adjusted R-squared:  0.3594 \nF-statistic: 96.36 on 1 and 169 DF,  p-value: &lt; 2.2e-16\n\n\nLet’s run a similar analysis looking at the median income as a function of the percentage of majors getting a job requiring a college degree.\n\ngrads |&gt; \n  mutate(Major_category = fct_lump(Major_category, 4)) |&gt;\n  ggplot(aes(pct_college, Median)) + \n  geom_point(aes(size=Total, col=Major_category)) + \n  geom_smooth() + \n  scale_x_continuous(label=percent_format()) + \n  scale_y_continuous(label=dollar_format()) + \n  scale_size_continuous(label=number_format()) + \n  expand_limits(y=0) + \n  labs(x=\"% of Major's Grads Employed in Jobs Requiring a College Degree\", \n       y=\"Median salary\", \n       title=\"Median income by percent with jobs requiring a college degree\", \n       caption=\"Adapted from @backerman150\")\n\n\n\n\nHere’s Table 2 in the FiveThirtyEight piece. It uses the mutate_at function to run an arbitrary function on any number of variables defined in the vars() function. See the help for ?mutate_at to learn more.\n\nlibrary(DT)\ngrads |&gt; \n  select(Major, Total, Median, P25th, P75th, Part_time, Non_college_jobs, Low_wage_jobs) |&gt; \n  mutate_at(vars(Part_time, Non_college_jobs, Low_wage_jobs), funs(percent(./Total))) |&gt; \n  mutate_at(vars(Median, P25th, P75th), funs(dollar)) |&gt; \n  datatable()"
  },
  {
    "objectID": "rmarkdown.html#who-cares-about-reproducible-research",
    "href": "rmarkdown.html#who-cares-about-reproducible-research",
    "title": "7  Reproducible Reporting with RMarkdown",
    "section": "7.1 Who cares about reproducible research?",
    "text": "7.1 Who cares about reproducible research?\nScience is plagued by reproducibility problems. Especially genomics!\n\nScientists in the United States spend $28 billion each year on basic biomedical research that cannot be repeated successfully.1\nA reproducibility study in psychology found that only 39 of 100 studies could be reproduced.2\nThe Journal Nature on the issue of reproducibility:3\n\n“Nature and the Nature research journals will introduce editorial measures to address the problem by improving the consistency and quality of reporting in life-sciences articles… we will give more space to methods sections. We will examine statistics more closely and encourage authors to be transparent, for example by including their raw data.”\n\nNature also released a checklist, unfortunately with wimpy computational check (see #18).\n\nOn microarray reproducibility:4\n\n18 Nat. Genet. microarray experiments\nLess than 50% reproducible\nProblems:\n\nMissing data (38%)\nMissing software/hardware details (50%)\nMissing method/processing details (66%)\n\n\nNGS: run-of-the-mill variant calling (align, process, call variants):5\n\n299 articles published in 2011 citing the 1000 Genomes project pilot publication\nOnly 19 were NGS studies with similar design\nOnly 10 used tools recommended by 1000G.\nOnly 4 used full 1000G workflow (realignment & quality score recalibration).\n\n\nConsider this figure:\n\nHow do we reproduce it? What do we need?\n\nThe data.\n\nData points themselves.\nOther metadata.\n\nThe code.\n\nShould be readable.\nComments in the code / well-documented so a normal person can figure out how it runs.\nHow were the trend lines drawn?\nWhat version of software / packages were used?\n\n\nThis kind of information is rarely available in scientific publications, but it’s now extraordinarly easy to put this kind of information on the web.\nCould I replicate Figure 1 from your last publication? If not, what would you and your co-authors need to provide or do so I could replicate Figure 1 from your last publication?\nAs scientists we should aim for robust and reproducible research\n\n“Robust research is about doing small things that stack the deck in your favor to prevent mistakes.”\n—Vince Buffalo, author of Bioinformatics Data Skills (2015).\nReproducible research can be repeated by other researchers with the same results.\n\n\n7.1.1 Reproducibility is hard!\n\nGenomics data is too large and high dimensional to easily inspect or visualize. Workflows involve multiple steps and it’s hard to inspect every step.\nUnlike in the wet lab, we don’t always know what to expect of our genomics data analysis.\nIt can be hard to distinguish good from bad results.\nScientific code is usually only run once to generate results for a publication, and is more likely to contain silent bugs. (code that may produces unknowingly incorrect output rather than stopping with an error message).\n\n\n\n7.1.2 What’s in it for you?\nYeah, it takes a lot of effort to be robust and reproducible. However, it will make your life (and science) easier!\n\nMost likely, you will have to re-run your analysis more than once.\n\nIn the future, you or a collaborator may have to re-visit part of the project.\nYour most likely collaborator is your future self, and your past self doesn’t answer emails.\nYou can make modularized parts of the project into re-useable tools for the future.\n\nReproducibility makes you easier to work and collaborate with.\n\n\n\n7.1.3 Some recommendations for reproducible research\n\nWrite code for humans, write data for computers.\n\nCode should be broken down into small chunks that may be re-used.\n\nMake names/variables consistent, distinctive and meaningful.\n\nAdopt a style be consistent.6\nWrite concise and clear comments.\n\nMake incremental changes. Work in small steps with frequent feedback. Use version control. See http://swcarpentry.github.io/git-novice/ for resources on version control.\nMake assertions and be loud, in code and in your methods. Add tests in your code to make sure it’s doing what you expect. See http://software-carpentry.org/v4/test/ for resources on testing code.\nUse existing libraries (packages) whenever possible. Don’t reinvent the wheel. Use functions that have already been developed and tested by others.\nPrevent catastrophe and help reproducibility by making your data read-only. Rather than modifying your original data directly, always use a workflow that reads in data, processes/modifies, then writes out intermediate and final files as necessary.\nEncapsulate the full project into one directory that is supported with version control. See: Noble, William Stafford. “A quick guide to organizing computational biology projects.” PLoS Comput Biol 5.7 (2009): e1000424.\nRelease your code and data. Simple. Without your code and data, your research is not reproducible.\n\nGitHub (https://github.com/) is a great place for storing, distributing, collaborating, and version-controlling code.\nRPubs (http://rpubs.com/) allows you to share dynamic documents you write in RStudio online.\nFigshare (http://figshare.com/) and Zenodo (https://zenodo.org/) allow you to upload any kind of research output, publishable or not, free and unlimited. Instantly get permanently available, citable DOI for your research output.\n“Data/code is available upon request” or “Data/code is available at the lab’s website” are completely unacceptable in the 21st century.\n\nWrite code that uses relative paths.\n\nDon’t use hard-coded absolute paths (i.e. /Users/stephen/Data/seq-data.csv or C:\\Stephen\\Documents\\Data\\Project1\\data.txt).\nPut the data in the project directory and reference it relative to where the code is, e.g., data/gapminder.csv, etc.\n\n\nAlways set your seed. If you’re doing anything that involves random/monte-carlo approaches, always use set.seed().\nDocument everything and use code as documentation.\n\nDocument why you do something, not mechanics.\nDocument your methods and workflows.\nDocument the origin of all data in your project directory.\nDocument when and how you downloaded the data.\nRecord data version info.\nRecord software version info with session_info().\nUse dynamic documentation to make your life easier."
  },
  {
    "objectID": "rmarkdown.html#rmarkdown",
    "href": "rmarkdown.html#rmarkdown",
    "title": "7  Reproducible Reporting with RMarkdown",
    "section": "7.2 RMarkdown",
    "text": "7.2 RMarkdown\nRMarkdown is a variant of Markdown that lets you embed R code chunks that execute when you compile the document. What, what? Markdown? Compile? What’s all this about?\n\n7.2.1 Markdown\nEver heard of HTML? It’s what drives the internet. HTML is a markup language - that’s what the ML stands for. The terminology evolved from “marking up” paper manuscripts by editors, where the editor would instruct an author or typesetter how to render the resulting text. Markup languages let you annotate text that you want to display with instructions about how to display it.\nI emphasize text because this is fundamentally different than word processing. When you use MS Word, for example, you’re creating a special proprietary binary file (the .docx) file that shows you how a document looks. By contrast, writing in a markup language like HTML or Markdown, you’re writing plain old text, using a text editor. The toolchain used to render the markup text into what you see on a display or in a PDF has always been and will always bee free and open.\nYou can learn Markdown in about 5 minutes. Let’s open up a web-based Markdown editor like http://dillinger.io/ or use a desktop Markdown editor like MarkdownPad (Windows) or MacDown (Mac).\n\n\n7.2.2 RMarkdown workflow\nRMarkdown is an enhanced version of Markdown that lets you embed R code into the document. When the document is compiled/rendered, the R code is executed by R, the output is then automatically rendered as Markdown with the rest of the document. The Markdown is then further processed to final output formats like HTML, PDF, DOCX, etc."
  },
  {
    "objectID": "rmarkdown.html#authoring-rmarkdown-documents",
    "href": "rmarkdown.html#authoring-rmarkdown-documents",
    "title": "7  Reproducible Reporting with RMarkdown",
    "section": "7.3 Authoring RMarkdown documents",
    "text": "7.3 Authoring RMarkdown documents\n\nNote: Before going any further, open up the options (Tools, Global Options), click the RMarkdown section, and uncheck the box, “Show output inline for all R Markdown documents.”\n\n\n7.3.1 From scratch\nFirst, open RStudio. Create a new project. Quit RStudio, then launch RStudio using the project file (.Rproj) you just created.\nNext, download the gapminder data from the data page. Put this file in your R project directory. Maybe put it in a subdirectory called “data.” Importantly, now your code and data will live in the same place.\nLet’s create a bare-bones RMarkdown document that compiles to HTML. In RStudio, select File, New File, R Markdown…. Don’t worry about the title and author fields. When the new document launches, select everything then delete it. Let’s author an RMarkdown file from scratch. Save it as fromscratch.Rmd.\n\n # Introduction \n  \n This is my first RMarkdown document! \n  \n # Let's embed some R code \n  \n Let's load the **Gapminder** data: \n  \n\n ```{r} \n library(dplyr) \n library(readr) \n gm &lt;- read_csv('data/gapminder.csv') \n head(gm) \n ``` \n\n\n The mean life expectancy is `r mean(gm$lifeExp)` years. \n  \n The years surveyed in this data include: `r unique(gm$year)`. \n  \n # Session Information \n  \n\n ```{r} \n sessionInfo() \n ``` \n\nHit the Knit HTML button in the editor window. You should see the rendered document pop up.\nSo let’s break that down to see exactly what happened there. Recall the RMarkdown Workflow shown above. You start with an RMarkdown document (Rmd). When you hit the Knit HTML button, The knitr R package parses through your source document and executes all the R code chunks defined by the R code chunk blocks. The source code itself and the results are then turned back into regular markdown, inserted into an intermediate markdown file (.md), and finally rendered into HTML by Pandoc.\nTry this. Instead of using the button, load the knitr package and just knit the document to markdown format. Run this in the console.\n\nlibrary(knitr)\nknit(\"fromscratch.Rmd\")\n\nNow, open up that regular markdown file and take a look.\n\n# Introduction\n\nThis is my first RMarkdown document!\n\n# Let's embed some R code\n\nLet's load the **Gapminder** data:\n\n\n```r\nlibrary(dplyr)\nlibrary(readr)\ngm &lt;- read_csv(\"data/gapminder.csv\")\nhead(gm)\n```\n\n```\n##       country continent year lifeExp      pop gdpPercap\n## 1 Afghanistan      Asia 1952  28.801  8425333  779.4453\n## 2 Afghanistan      Asia 1957  30.332  9240934  820.8530\n## 3 Afghanistan      Asia 1962  31.997 10267083  853.1007\n## 4 Afghanistan      Asia 1967  34.020 11537966  836.1971\n## 5 Afghanistan      Asia 1972  36.088 13079460  739.9811\n## 6 Afghanistan      Asia 1977  38.438 14880372  786.1134\n```\n\nThe mean life expectancy is 59.4744394 years.\n\nThe years surveyed in this data include: 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 2007.\n\n\n\n7.3.2 From a template with YAML metadata\nGo ahead and start a new R Markdown document. Fill in some title and author information.\nThis is going to put a YAML header in the file that looks something like this:\n---\ntitle: \"Gapminder Analysis\"\nauthor: \"Stephen Turner\"\ndate: \"January 1, 2017\"\noutput: html_document\n---\nThe stuff between the three ---s is metadata. You can read more about what kind of metadata can be included in the RMarkdown documentation. Try clicking the little wrench icon and setting some options, like including a table of contents and figure captions. Notice how the metadata front matter changes.\n---\ntitle: \"Gapminder analysis\"\nauthor: \"Stephen Turner\"\ndate: \"January 1, 2017\"\noutput: \n  html_document: \n    fig_caption: yes\n    toc: yes\n---\nNow, delete everything in that document below the metadata header and paste in what we had written before (above). Save this document under a different name (rmdwithmeta.Rmd for example). You’ll now see that your HTML document takes the metadata and makes a nicely formatted title.\nLet’s add a plot in there. Open up a new R chunk with this:\n\n ```{r, fig.cap='Life Exp vs GDP'} \n library(ggplot2) \n ggplot(gm, aes(gdpPercap, lifeExp)) + geom_point() \n ``` \n\nUsing RStudio you can fiddle around with different ways to make the graphic and keep the one you want. Maybe it looks like this:\n\n ```{r, fig.cap='Life Exp vs GDP'} \n library(ggplot2) \n ggplot(gm, aes(gdpPercap, lifeExp)) +  \n   geom_point() +  \n   scale_x_log10() +  \n   aes(col=continent) \n ``` \n\n\n\n7.3.3 Chunk options\nYou can modify the behavior of an R chunk with options. Options are passed in after a comma on the fence, as shown below.\n\n ```{r optionalChunkName, echo=TRUE, results='hide'} \n # R code here \n ``` \n\nSome commonly used options include:\n\necho: (TRUE by default) whether to include R source code in the output file.\nresults takes several possible values:\n\nmarkup (the default) takes the result of the R evaluation and turns it into markdown that is rendered as usual.\nhide will hide results.\nhold will hold all the output pieces and push them to the end of a chunk. Useful if you’re running commands that result in lots of little pieces of output in the same chunk.\nasis writes the raw results from R directly into the document. Only really useful for tables.\n\ninclude: (TRUE by default) if this is set to FALSE the R code is still evaluated, but neither the code nor the results are returned in the output document.\nfig.width, fig.height: used to control the size of graphics in the output.\n\nTry modifying your first R chunk to use different values for echo, results, and include.\n\n ```{r} \n gm &lt;- read.csv('data/gapminder.csv') \n head(gm) \n tail(gm) \n ``` \n\nSee the full list of options here: http://yihui.name/knitr/options/. There are lots!\nA special note about caching: The cache= option is automatically set to FALSE. That is, every time you render the Rmd, all the R code is run again from scratch. If you use cache=TRUE, for this chunk, knitr will save the results of the evaluation into a directory that you specify. When you re-render the document, knitr will first check if there are previously cached results under the cache directory before really evaluating the chunk; if cached results exist and this code chunk has not been changed since last run (use MD5 sum to verify), the cached results will be (lazy-) loaded, otherwise new cache will be built; if a cached chunk depends on other chunks (see the dependson option) and any one of these chunks has changed, this chunk must be forcibly updated (old cache will be purged). See the documentation for caching.\n\n\n7.3.4 Tables\nThe knitr package that runs the RMarkdown document in the background also has a function called kable that helps with printing tables nicely. It’s only useful when you set echo=FALSE and results='asis'. Try this.\n\n ```{r} \n head(gm) \n ``` \n\nVersus this:\n\n ```{r, results='asis'} \n library(knitr) \n kable(head(gm)) \n ``` \n\n\n\n7.3.5 Changing output formats\nNow try this. If you were successfully able to get a LaTeX distribution installed, you can render this document as a PDF instead of HTML. Try changing the line in the metadata from html_document to pdf_document. Notice how the Knit HTML button in RStudio now changes to Knit PDF. Try it. If you didn’t get a LaTeX engine installed this won’t work. Go back to the setup instructions after class to give this a try."
  },
  {
    "objectID": "rmarkdown.html#distributing-analyses-rpubs",
    "href": "rmarkdown.html#distributing-analyses-rpubs",
    "title": "7  Reproducible Reporting with RMarkdown",
    "section": "7.4 Distributing Analyses: Rpubs",
    "text": "7.4 Distributing Analyses: Rpubs\nRPubs.com is a free service from RStudio that allows you to seamlessly publish the results of your R analyses online. Sign up for an account at RPubs.com, then sign in on your browser.\nMake sure your RMarkdown metadata is set to render to HTML rather than PDF. Render the document. Now notice the little Publish button in the HTML viewer pane. Click this. Sign in when asked, and give your document a name (usually the same name as the title of your Rmd).\nHere are a few examples of documents I’ve published:\n\nhttp://rpubs.com/turnersd/daily_show_guests: Analysis of every guest who’s ever been on The Daily Show with Jon Stewart.\nhttp://rpubs.com/turnersd/twoaxes: How to plot two different tracks of data with one axis on the left and one axis on the right.\nhttp://rpubs.com/turnersd/anscombe: Analysis of Anscombe’s Quartet data.\n\nNote how RPubs doesn’t share your code! RPubs is a great way to share your analysis but doesn’t let you share the source code. This is a huge barrier to reproducibility. There are plenty of ways to do this. One way is to go to gist.github.com and upload your code as a text file, then link back to the gist in your republished RPubs document."
  },
  {
    "objectID": "rmarkdown.html#footnotes",
    "href": "rmarkdown.html#footnotes",
    "title": "7  Reproducible Reporting with RMarkdown",
    "section": "",
    "text": "Freedman, et al. “The economics of reproducibility in preclinical research.” PLoS Biol 13.6 (2015): e1002165.↩︎\nhttp://www.nature.com/news/first-results-from-psychology-s-largest-reproducibility-test-1.17433↩︎\nhttp://www.nature.com/news/reproducibility-1.17552↩︎\nIoannidis, John PA, et al. “Repeatability of published microarray gene expression analyses.” Nature genetics 41.2 (2009): 149-155.↩︎\nNekrutenko, Anton, and James Taylor. “Next-generation sequencing data interpretation: enhancing reproducibility and accessibility.” Nature Reviews Genetics 13.9 (2012): 667-672.↩︎\nhttp://adv-r.had.co.nz/Style.html↩︎"
  },
  {
    "objectID": "stats.html",
    "href": "stats.html",
    "title": "8  Essential Statistics",
    "section": "",
    "text": "Not much to see here…"
  },
  {
    "objectID": "survival.html",
    "href": "survival.html",
    "title": "9  Survival Analysis",
    "section": "",
    "text": "Not much to see here…"
  },
  {
    "objectID": "predmodeling.html",
    "href": "predmodeling.html",
    "title": "10  Predictive Modeling",
    "section": "",
    "text": "Not much to see here…"
  },
  {
    "objectID": "forecasting.html",
    "href": "forecasting.html",
    "title": "11  Probabilistic Forecasting",
    "section": "",
    "text": "Not much to see here…"
  },
  {
    "objectID": "textmining.html",
    "href": "textmining.html",
    "title": "12  Text Mining",
    "section": "",
    "text": "Not much to see here…"
  },
  {
    "objectID": "ggtree.html",
    "href": "ggtree.html",
    "title": "13  Phylogenetic Trees",
    "section": "",
    "text": "Not much to see here…"
  },
  {
    "objectID": "rnaseq.html",
    "href": "rnaseq.html",
    "title": "14  RNA-seq",
    "section": "",
    "text": "Not much to see here…"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Bryan, Jennifer. 2019. “STAT 545: Data Wrangling, Exploration, and\nAnalysis with r.” https://stat545.com/.\n\n\nLove, Michael I., Wolfgang Huber, and Simon Anders. 2014.\n“Moderated Estimation of Fold Change and Dispersion for RNA-seq Data with DESeq2.”\nGenome Biology 15 (12): 1–21.\n\n\nRobinson, David. 2015. “Variance Explained.”\nhttp://varianceexplained.org/.\n\n\nSilge, Julia, and David Robinson. 2017. Text Mining\nwith R: A Tidy Approach. 1st edition.\nBeijing ; Boston: O’Reilly Media.\n\n\nTeal, Tracy K., Karen A. Cranston, Hilmar Lapp, Ethan White, Greg\nWilson, Karthik Ram, and Aleksandra Pawlik. 2015. “Data Carpentry:\nWorkshops to Increase Data Literacy for Researchers.”\n\n\nWilson, Greg. 2014. “Software Carpentry: Lessons\nLearned.” F1000Research 3.\n\n\nYu, Guangchuang. 2022. “Ggtree: An r Package for Visualization of\nTree and Annotation Data.” http://bioconductor.org/packages/ggtree/.\n\n\nYu, Guangchuang, David K. Smith, Huachen Zhu, Yi Guan, and Tommy\nTsan-Yuk Lam. 2017. “Ggtree: An R Package for\nVisualization and Annotation of Phylogenetic Trees with Their Covariates\nand Other Associated Data.” Methods in Ecology and\nEvolution 8 (1): 28–36."
  },
  {
    "objectID": "setup.html#software",
    "href": "setup.html#software",
    "title": "Appendix A — Setup",
    "section": "A.1 Software",
    "text": "A.1 Software"
  },
  {
    "objectID": "setup.html#data",
    "href": "setup.html#data",
    "title": "Appendix A — Setup",
    "section": "A.2 Data",
    "text": "A.2 Data\n\nOption 1: Download all the data. Download and extract this zip file (11.36 Mb) with all the data for the entire workshop. This may include additional datasets that we won’t use here.\nOption 2: Download individual datasets as needed.\n\nCreate a new folder somewhere on your computer that’s easy to get to (e.g., your Desktop). Name it bds. Inside that folder, make a folder called data, all lowercase.\nDownload individual data files as needed, saving them to the new bdsr/data folder you just made. Click to download. If data displays in your browser, right-click and select Save link as… (or similar) to save to the desired location.\n\n\n\ndata/airway_metadata.csv\ndata/airway_scaledcounts.csv\ndata/annotables_grch38.csv\ndata/austen.csv\ndata/brauer2007_messy.csv\ndata/brauer2007_sysname2go.csv\ndata/brauer2007_tidy.csv\ndata/dmd.csv\ndata/flu_genotype.csv\ndata/gapminder.csv\ndata/grads_dd.csv\ndata/grads.csv\ndata/h7n9_analysisready.csv\ndata/h7n9.csv\ndata/heartrate2dose.csv\ndata/ilinet.csv\ndata/movies_dd.csv\ndata/movies_imdb.csv\ndata/movies.csv\ndata/nhanes_dd.csv\ndata/nhanes.csv\ndata/SRP026387_metadata.csv\ndata/SRP026387_scaledcounts.csv\ndata/stressEcho.csv"
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Appendix B — Additional Resources",
    "section": "",
    "text": "Not much to see here…"
  }
]