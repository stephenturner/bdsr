[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Biological Data Science with R",
    "section": "",
    "text": "Preface\nThis book was written as a companion to a series of courses introducing the essentials of biological data science with R. While this book was written with the accompanying live instruction in mind, this book can be used as a self-contained self study guide for quickly learning the essentials need to get started with R. The BDSR book and accompanying course introduces methods, tools, and software for reproducibly managing, manipulating, analyzing, and visualizing large-scale biological data using the R statistical computing environment. This book also covers essential statistical analysis, and advanced topics including survival analysis, predictive modeling, forecasting, and text mining.\nThis is not a “Tool X” or “Software Y” book. I want you to take away from this book and accompanying course the ability to use an extremely powerful scientific computing environment (R) to do many of the things that you’ll do across study designs and disciplines – managing, manipulating, visualizing, and analyzing large, sometimes high-dimensional data. Regardless of your specific discipline you’ll need the same computational know-how and data literacy to do the same kinds of basic tasks in each. This book might show you how to use specific tools here and there (e.g., DESeq2 for RNA-seq analysis (Love, Huber, and Anders 2014), ggtree for drawing phylogenetic trees (Yu et al. 2017), etc.), but these are not important – you probably won’t be using the same specific software or methods 10 years from now, but you’ll still use the same underlying data and computational foundation. That is the point of this series – to arm you with a basic foundation, and more importantly, to enable you to figure out how to use this tool or that tool on your own, when you need to.\nThis is not a statistics book. There is a short lesson on essential statistics using R in Chapter 7 but this short chapter offers neither a comprehensive background on underlying theory nor in-depth coverage of implementation strategies using R. Some general knowledge of statistics and study design is helpful, but isn’t required for going through this book or taking the accompanying course.\nThere are no prerequisites to this book or the accompanying course. However, each chapter involves lots of hands-on practice coding, and you’ll need to download and install required softwar and download required data. See the setup instructions in Appendix A.\n\n\nAcknowledgements\nThis book is partially adapted from material we developed for the University of Virginia BIMS8382 graduate course . The material for this course was adapted from and/or inspired by Jenny Bryan’s STAT545 course at UBC (Bryan 2019), Software Carpentry (Wilson 2014) and Data Carpentry (Teal et al. 2015) courses, David Robinson’s Variance Explained blog (Robinson 2015), the ggtree vignettes (Yu 2022) Tidy Text Mining with R (Silge and Robinson 2017), and likely many others.\n\n\n\n\nBryan, Jennifer. 2019. “STAT 545: Data Wrangling, Exploration, and Analysis with r.” https://stat545.com/.\n\n\nLove, Michael I., Wolfgang Huber, and Simon Anders. 2014. “Moderated Estimation of Fold Change and Dispersion for RNA-seq Data with DESeq2.” Genome Biology 15 (12): 1–21.\n\n\nRobinson, David. 2015. “Variance Explained.” http://varianceexplained.org/.\n\n\nSilge, Julia, and David Robinson. 2017. Text Mining with R: A Tidy Approach. 1st edition. Beijing ; Boston: O’Reilly Media.\n\n\nTeal, Tracy K., Karen A. Cranston, Hilmar Lapp, Ethan White, Greg Wilson, Karthik Ram, and Aleksandra Pawlik. 2015. “Data Carpentry: Workshops to Increase Data Literacy for Researchers.”\n\n\nWilson, Greg. 2014. “Software Carpentry: Lessons Learned.” F1000Research 3.\n\n\nYu, Guangchuang. 2022. “Ggtree: An r Package for Visualization of Tree and Annotation Data.” http://bioconductor.org/packages/ggtree/.\n\n\nYu, Guangchuang, David K. Smith, Huachen Zhu, Yi Guan, and Tommy Tsan-Yuk Lam. 2017. “Ggtree: An R Package for Visualization and Annotation of Phylogenetic Trees with Their Covariates and Other Associated Data.” Methods in Ecology and Evolution 8 (1): 28–36."
  },
  {
    "objectID": "basics.html#rstudio",
    "href": "basics.html#rstudio",
    "title": "1  Basics",
    "section": "1.1 RStudio",
    "text": "1.1 RStudio\nLet’s start by learning about RStudio. R is the underlying statistical computing environment. RStudio is a graphical integrated development environment (IDE) that makes using R much easier.\n\nOptions: First, let’s change a few options. We’ll only have to do this once. Under Tools… Global Options…:\n\nUnder General: Uncheck “Restore most recently opened project at startup”\nUnder General: Uncheck “Restore .RData into workspace at startup”\nUnder General: Set “Save workspace to .RData on exit:” to Never.\nUnder General: Set “Save workspace to .RData on exit:” to Never.\nUnder R Markdown: Uncheck “Show output inline for all R Markdown documents”\n\nProjects: first, start a new project in a new folder somewhere easy to remember. When we start reading in data it’ll be important that the code and the data are in the same place. Creating a project creates an Rproj file that opens R running in that folder. This way, when you want to read in dataset whatever.txt, you just tell it the filename rather than a full path. This is critical for reproducibility, and we’ll talk about that more later.\nCode that you type into the console is code that R executes. From here forward we will use the editor window to write a script that we can save to a file and run it again whenever we want to. We usually give it a .R extension, but it’s just a plain text file. If you want to send commands from your editor to the console, use CMD+Enter (Ctrl+Enter on Windows).\nAnything after a # sign is a comment. Use them liberally to comment your code."
  },
  {
    "objectID": "basics.html#basic-operations",
    "href": "basics.html#basic-operations",
    "title": "1  Basics",
    "section": "1.2 Basic operations",
    "text": "1.2 Basic operations\nR can be used as a glorified calculator. Try typing this in directly into the console. Make sure you’re typing into into the editor, not the console, and save your script. Use the run button, or press CMD+Enter (Ctrl+Enter on Windows).\n\n2+2\n5*4\n2^3\n\nR Knows order of operations and scientific notation.\n\n2+3*4/(5+3)*15/2^2+3*4^2\n5e4\n\nHowever, to do useful and interesting things, we need to assign values to objects. To create objects, we need to give it a name followed by the assignment operator &lt;- and the value we want to give it:\n\nweight_kg &lt;- 55\n\n&lt;- is the assignment operator. Assigns values on the right to objects on the left, it is like an arrow that points from the value to the object. Mostly similar to = but not always. Learn to use &lt;- as it is good programming practice. Using = in place of &lt;- can lead to issues down the line. The keyboard shortcut for inserting the &lt;- operator is Alt-dash.\nObjects can be given any name such as x, current_temperature, or subject_id. You want your object names to be explicit and not too long. They cannot start with a number (2x is not valid but x2 is). R is case sensitive (e.g., weight_kg is different from Weight_kg). There are some names that cannot be used because they represent the names of fundamental functions in R (e.g., if, else, for, see here for a complete list). In general, even if it’s allowed, it’s best to not use other function names, which we’ll get into shortly (e.g., c, T, mean, data, df, weights). In doubt check the help to see if the name is already in use. It’s also best to avoid dots (.) within a variable name as in my.dataset. It is also recommended to use nouns for variable names, and verbs for function names.\nWhen assigning a value to an object, R does not print anything. You can force to print the value by typing the name:\n\nweight_kg\n\nNow that R has weight_kg in memory, we can do arithmetic with it. For instance, we may want to convert this weight in pounds (weight in pounds is 2.2 times the weight in kg).\n\n2.2 * weight_kg\n\nWe can also change a variable’s value by assigning it a new one:\n\nweight_kg &lt;- 57.5\n2.2 * weight_kg\n\nThis means that assigning a value to one variable does not change the values of other variables. For example, let’s store the animal’s weight in pounds in a variable.\n\nweight_lb &lt;- 2.2 * weight_kg\n\nand then change weight_kg to 100.\n\nweight_kg &lt;- 100\n\nWhat do you think is the current content of the object weight_lb? 126.5 or 220?\nYou can see what objects (variables) are stored by viewing the Environment tab in Rstudio. You can also use the ls() function. You can remove objects (variables) with the rm() function. You can do this one at a time or remove several objects at once. You can also use the little broom button in your environment pane to remove everything from your environment.\n\nls()\nrm(weight_lb, weight_kg)\nls()\nweight_lb # oops! you should get an error because weight_lb no longer exists!\n\n\n\n\n\n\n\nExercise 1\n\n\n\nWhat are the values after each statement in the following?\n\nmass &lt;- 50              # mass?\nage  &lt;- 30              # age?\nmass &lt;- mass * 2        # mass?\nage  &lt;- age - 10        # age?\nmass_index &lt;- mass/age  # massIndex?"
  },
  {
    "objectID": "basics.html#functions",
    "href": "basics.html#functions",
    "title": "1  Basics",
    "section": "1.3 Functions",
    "text": "1.3 Functions\nR has built-in functions.\n\n# Notice that this is a comment.\n# Anything behind a # is \"commented out\" and is not run.\nsqrt(144)\nlog(1000)\n\nGet help by typing a question mark in front of the function’s name, or help(functionname):\n\nhelp(log)\n?log\n\nNote syntax highlighting when typing this into the editor. Also note how we pass arguments to functions. The base= part inside the parentheses is called an argument, and most functions use arguments. Arguments modify the behavior of the function. Functions some input (e.g., some data, an object) and other options to change what the function will return, or how to treat the data provided. Finally, see how you can next one function inside of another (here taking the square root of the log-base-10 of 1000).\n\nlog(1000)\nlog(1000, base=10)\nlog(1000, 10)\nsqrt(log(1000, base=10))\n\n\n\n\n\n\n\nExercise 2\n\n\n\nSee ?abs and calculate the square root of the log-base-10 of the absolute value of -4*(2550-50). Answer should be 2."
  },
  {
    "objectID": "basics.html#tibbles-data-frames",
    "href": "basics.html#tibbles-data-frames",
    "title": "1  Basics",
    "section": "1.4 Tibbles (data frames)",
    "text": "1.4 Tibbles (data frames)\nThere are lots of different basic data structures in R. If you take any kind of longer introduction to R you’ll probably learn about arrays, lists, matrices, etc. We are going to skip straight to the data structure you’ll probably use most – the tibble (also known as the data frame). We use tibbles to store heterogeneous tabular data in R: tabular, meaning that individuals or observations are typically represented in rows, while variables or features are represented as columns; heterogeneous, meaning that columns/features/variables can be different classes (on variable, e.g. age, can be numeric, while another, e.g., cause of death, can be text).\nWe’ll learn more about tibbles in Chapter 2."
  },
  {
    "objectID": "tibbles.html#our-data",
    "href": "tibbles.html#our-data",
    "title": "2  Tibbles",
    "section": "2.1 Our data",
    "text": "2.1 Our data\n\nThe data we’re going to look at is cleaned up version of a gene expression dataset from Brauer et al. Coordination of Growth Rate, Cell Cycle, Stress Response, and Metabolic Activity in Yeast (2008) Mol Biol Cell 19:352-367. This data is from a gene expression microarray, and in this paper the authors are examining the relationship between growth rate and gene expression in yeast cultures limited by one of six different nutrients (glucose, leucine, ammonium, sulfate, phosphate, uracil). If you give yeast a rich media loaded with nutrients except restrict the supply of a single nutrient, you can control the growth rate to any rate you choose. By starving yeast of specific nutrients you can find genes that:\n\nRaise or lower their expression in response to growth rate. Growth-rate dependent expression patterns can tell us a lot about cell cycle control, and how the cell responds to stress. The authors found that expression of &gt;25% of all yeast genes is linearly correlated with growth rate, independent of the limiting nutrient. They also found that the subset of negatively growth-correlated genes is enriched for peroxisomal functions, and positively correlated genes mainly encode ribosomal functions.\nRespond differently when different nutrients are being limited. If you see particular genes that respond very differently when a nutrient is sharply restricted, these genes might be involved in the transport or metabolism of that specific nutrient.\n\nYou can download the cleaned up version of the data here. The file is called brauer2007_tidy.csv. Later on we’ll actually start with the original raw data (minimally processed) and manipulate it so that we can make it more amenable for analysis."
  },
  {
    "objectID": "tibbles.html#reading-in-data",
    "href": "tibbles.html#reading-in-data",
    "title": "2  Tibbles",
    "section": "2.2 Reading in data",
    "text": "2.2 Reading in data\n\n2.2.1 dplyr and readr\nThere are some built-in functions for reading in data in text files. These functions are read-dot-something – for example, read.csv() reads in comma-delimited text data; read.delim() reads in tab-delimited text, etc. We’re going to read in data a little bit differently here using the readr package. When you load the readr package, you’ll have access to very similar looking functions, named read-underscore-something – e.g., read_csv(). You have to have the readr package installed to access these functions. Compared to the base functions, they’re much faster, they’re good at guessing the types of data in the columns, they don’t do some of the other silly things that the base functions do. We’re going to use another package later on called dplyr, and if you have the dplyr package loaded as well, and you read in the data with readr, the data will display nicely.\nFirst let’s load those packages.\n\nlibrary(readr)\nlibrary(dplyr)\n\nIf you see a warning that looks like this: Error in library(packageName) : there is no package called 'packageName', then you don’t have the package installed correctly. See the setup chapter (Appendix A).\n\n\n2.2.2 read_csv()\nNow, let’s actually load the data. You can get help for the import function with ?read_csv. When we load data we assign it to a variable just like any other, and we can choose a name for that data. Since we’re going to be referring to this data a lot, let’s give it a short easy name to type. I’m going to call it ydat. Once we’ve loaded it we can type the name of the object itself (ydat) to see it printed to the screen.\n\nydat &lt;- read_csv(file=\"data/brauer2007_tidy.csv\")\nydat\n\nTake a look at that output. The nice thing about loading dplyr and reading in data with readr is that data frames are displayed in a much more friendly way. This dataset has nearly 200,000 rows and 7 columns. When you import data this way and try to display the object in the console, instead of trying to display all 200,000 rows, you’ll only see about 10 by default. Also, if you have so many columns that the data would wrap off the edge of your screen, those columns will not be displayed, but you’ll see at the bottom of the output which, if any, columns were hidden from view. If you want to see the whole dataset, there are two ways to do this. First, you can click on the name of the data.frame in the Environment panel in RStudio. Or you could use the View() function (with a capital V).\n\nView(ydat)"
  },
  {
    "objectID": "tibbles.html#inspecting-data.frame-objects",
    "href": "tibbles.html#inspecting-data.frame-objects",
    "title": "2  Tibbles",
    "section": "2.3 Inspecting data.frame objects",
    "text": "2.3 Inspecting data.frame objects\n\n2.3.1 Built-in functions\nThere are several built-in functions that are useful for working with data frames.\n\nContent:\n\nhead(): shows the first few rows\ntail(): shows the last few rows\n\nSize:\n\ndim(): returns a 2-element vector with the number of rows in the first element, and the number of columns as the second element (the dimensions of the object)\nnrow(): returns the number of rows\nncol(): returns the number of columns\n\nSummary:\n\ncolnames() (or just names()): returns the column names\nstr(): structure of the object and information about the class, length and content of each column\nsummary(): works differently depending on what kind of object you pass to it. Passing a data frame to the summary() function prints out useful summary statistics about numeric column (min, max, median, mean, etc.)\n\n\n\nhead(ydat)\ntail(ydat)\ndim(ydat)\nnames(ydat)\nstr(ydat)\nsummary(ydat)\n\n\n\n2.3.2 Other packages\nThe glimpse() function is available once you load the dplyr library, and it’s like str() but its display is a little bit better.\n\nglimpse(ydat)\n\nThe skimr package has a nice function, skim, that provides summary statistics the user can skim quickly to understand your data. You can install it with install.packages(\"skimr\") if you don’t have it already.\n\nlibrary(skimr)\nskim(ydat)"
  },
  {
    "objectID": "tibbles.html#accessing-variables-subsetting-data-frames",
    "href": "tibbles.html#accessing-variables-subsetting-data-frames",
    "title": "2  Tibbles",
    "section": "2.4 Accessing variables & subsetting data frames",
    "text": "2.4 Accessing variables & subsetting data frames\nWe can access individual variables within a data frame using the $ operator, e.g., mydataframe$specificVariable. Let’s print out all the gene names in the data. Then let’s calculate the average expression across all conditions, all genes (using the built-in mean() function).\n\n# display all gene symbols\nydat$symbol\n\n#mean expression\nmean(ydat$expression)\n\nNow that’s not too interesting. This is the average gene expression across all genes, across all conditions. The data is actually scaled/centered around zero:\nWe might be interested in the average expression of genes with a particular biological function, and how that changes over different growth rates restricted by particular nutrients. This is the kind of thing we’re going to do in the next section.\n\n\n\n\n\n\nExercise 1\n\n\n\n\nWhat’s the standard deviation expression (hint: get help on the sd function with ?sd).\nWhat’s the range of rate represented in the data? (hint: range())."
  },
  {
    "objectID": "tibbles.html#bonus-preview-to-advanced-manipulation",
    "href": "tibbles.html#bonus-preview-to-advanced-manipulation",
    "title": "2  Tibbles",
    "section": "2.5 BONUS: Preview to advanced manipulation",
    "text": "2.5 BONUS: Preview to advanced manipulation\nWhat if we wanted show the mean expression, standard deviation, and correlation between growth rate and expression, separately for each limiting nutrient, separately for each gene, for all genes involved in the leucine biosynthesis pathway?\n\nydat |&gt; \n  filter(bp==\"leucine biosynthesis\") |&gt; \n  group_by(nutrient, symbol) |&gt; \n  summarize(mean=mean(expression), sd=sd(expression), r=cor(rate, expression))\n\nNeat eh? We’ll learn how to do that in the advanced manipulation with dplyr lesson."
  },
  {
    "objectID": "dplyr.html#review",
    "href": "dplyr.html#review",
    "title": "3  Data Manipulation",
    "section": "3.1 Review",
    "text": "3.1 Review\n\n3.1.1 Our data\nWe’re going to use the yeast gene expression dataset described on the data frames lesson in Chapter 2. This is a cleaned up version of a gene expression dataset from Brauer et al. Coordination of Growth Rate, Cell Cycle, Stress Response, and Metabolic Activity in Yeast (2008) Mol Biol Cell 19:352-367. This data is from a gene expression microarray, and in this paper the authors are examining the relationship between growth rate and gene expression in yeast cultures limited by one of six different nutrients (glucose, leucine, ammonium, sulfate, phosphate, uracil). If you give yeast a rich media loaded with nutrients except restrict the supply of a single nutrient, you can control the growth rate to any rate you choose. By starving yeast of specific nutrients you can find genes that:\n\nRaise or lower their expression in response to growth rate. Growth-rate dependent expression patterns can tell us a lot about cell cycle control, and how the cell responds to stress. The authors found that expression of &gt;25% of all yeast genes is linearly correlated with growth rate, independent of the limiting nutrient. They also found that the subset of negatively growth-correlated genes is enriched for peroxisomal functions, and positively correlated genes mainly encode ribosomal functions.\nRespond differently when different nutrients are being limited. If you see particular genes that respond very differently when a nutrient is sharply restricted, these genes might be involved in the transport or metabolism of that specific nutrient.\n\nYou can download the cleaned up version of the data here. The file is called brauer2007_tidy.csv. Later on we’ll actually start with the original raw data (minimally processed) and manipulate it so that we can make it more amenable for analysis.\n\n\n3.1.2 Reading in data\nWe need to load both the dplyr and readr packages for efficiently reading in and displaying this data. We’re also going to use many other functions from the dplyr package. Make sure you have these packages installed as described on the setup chapter (Appendix A).\n\n# Load packages\nlibrary(readr)\nlibrary(dplyr)\n\n# Read in data\nydat &lt;- read_csv(file=\"data/brauer2007_tidy.csv\")\n\n# Display the data\nydat\n\n# Optionally, bring up the data in a viewer window\n# View(ydat)\n\n# A tibble: 198,430 × 7\n   symbol systematic_name nutrient  rate expression bp                     mf   \n   &lt;chr&gt;  &lt;chr&gt;           &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;                  &lt;chr&gt;\n 1 SFB2   YNL049C         Glucose   0.05      -0.24 ER to Golgi transport  mole…\n 2 &lt;NA&gt;   YNL095C         Glucose   0.05       0.28 biological process un… mole…\n 3 QRI7   YDL104C         Glucose   0.05      -0.02 proteolysis and pepti… meta…\n 4 CFT2   YLR115W         Glucose   0.05      -0.33 mRNA polyadenylylatio… RNA …\n 5 SSO2   YMR183C         Glucose   0.05       0.05 vesicle fusion*        t-SN…\n 6 PSP2   YML017W         Glucose   0.05      -0.69 biological process un… mole…\n 7 RIB2   YOL066C         Glucose   0.05      -0.55 riboflavin biosynthes… pseu…\n 8 VMA13  YPR036W         Glucose   0.05      -0.75 vacuolar acidification hydr…\n 9 EDC3   YEL015W         Glucose   0.05      -0.24 deadenylylation-indep… mole…\n10 VPS5   YOR069W         Glucose   0.05      -0.16 protein retention in … prot…\n# ℹ 198,420 more rows"
  },
  {
    "objectID": "dplyr.html#the-dplyr-package",
    "href": "dplyr.html#the-dplyr-package",
    "title": "3  Data Manipulation",
    "section": "3.2 The dplyr package",
    "text": "3.2 The dplyr package\nThe dplyr package is a relatively new R package that makes data manipulation fast and easy. It imports functionality from another package called magrittr that allows you to chain commands together into a pipeline that will completely change the way you write R code such that you’re writing code the way you’re thinking about the problem.\nWhen you read in data with the readr package (read_csv()) and you had the dplyr package loaded already, the data frame takes on this “special” class of data frames called a tbl (pronounced “tibble”), which you can see with class(ydat). If you have other “regular” data frames in your workspace, the as_tibble() function will convert it into the special dplyr tbl that displays nicely (e.g.: iris &lt;- as_tibble(iris)). You don’t have to turn all your data frame objects into tibbles, but it does make working with large datasets a bit easier.\nYou can read more about tibbles in Tibbles chapter in R for Data Science or in the tibbles vignette. They keep most of the features of data frames, and drop the features that used to be convenient but are now frustrating (i.e. converting character vectors to factors). You can read more about the differences between data frames and tibbles in this section of the tibbles vignette, but the major convenience for us concerns printing (aka displaying) a tibble to the screen. When you print (i.e., display) a tibble, it only shows the first 10 rows and all the columns that fit on one screen. It also prints an abbreviated description of the column type. You can control the default appearance with options:\n\noptions(tibble.print_max = n, tibble.print_min = m): if there are more than n rows, print only the first m rows. Use options(tibble.print_max = Inf) to always show all rows.\noptions(tibble.width = Inf) will always print all columns, regardless of the width of the screen."
  },
  {
    "objectID": "dplyr.html#dplyr-verbs",
    "href": "dplyr.html#dplyr-verbs",
    "title": "3  Data Manipulation",
    "section": "3.3 dplyr verbs",
    "text": "3.3 dplyr verbs\nThe dplyr package gives you a handful of useful verbs for managing data. On their own they don’t do anything that base R can’t do. Here are some of the single-table verbs we’ll be working with in this lesson (single-table meaning that they only work on a single table – contrast that to two-table verbs used for joining data together, which we’ll cover in a later lesson).\n\nfilter()\nselect()\nmutate()\narrange()\nsummarize()\ngroup_by()\n\nThey all take a data frame or tibble as their input for the first argument, and they all return a data frame or tibble as output.\n\n3.3.1 filter()\nIf you want to filter rows of the data where some condition is true, use the filter() function.\n\nThe first argument is the data frame you want to filter, e.g. filter(mydata, ....\nThe second argument is a condition you must satisfy, e.g. filter(ydat, symbol == \"LEU1\"). If you want to satisfy all of multiple conditions, you can use the “and” operator, &. The “or” operator | (the pipe character, usually shift-backslash) will return a subset that meet any of the conditions.\n\n\n==: Equal to\n!=: Not equal to\n&gt;, &gt;=: Greater than, greater than or equal to\n&lt;, &lt;=: Less than, less than or equal to\n\nLet’s try it out. For this to work you have to have already loaded the dplyr package. Let’s take a look at LEU1, a gene involved in leucine synthesis.\n\n# First, make sure you've loaded the dplyr package\nlibrary(dplyr)\n\n# Look at a single gene involved in leucine synthesis pathway\nfilter(ydat, symbol == \"LEU1\")\n\n# Optionally, bring that result up in a View window\n# View(filter(ydat, symbol == \"LEU1\"))\n\n# Look at multiple genes\nfilter(ydat, symbol==\"LEU1\" | symbol==\"ADH2\")\n\n# Look at LEU1 expression at a low growth rate due to nutrient depletion\n# Notice how LEU1 is highly upregulated when leucine is depleted!\nfilter(ydat, symbol==\"LEU1\" & rate==.05)\n\n# But expression goes back down when the growth/nutrient restriction is relaxed\nfilter(ydat, symbol==\"LEU1\" & rate==.3)\n\n# Show only stats for LEU1 and Leucine depletion. \n# LEU1 expression starts off high and drops\nfilter(ydat, symbol==\"LEU1\" & nutrient==\"Leucine\")\n\n# What about LEU1 expression with other nutrients being depleted?\nfilter(ydat, symbol==\"LEU1\" & nutrient==\"Glucose\")\n\nLet’s look at this graphically. Don’t worry about what these commands are doing just yet - we’ll cover that later on when we talk about ggplot2. Here’s I’m taking the filtered dataset containing just expression estimates for LEU1 where I have 36 rows (one for each of 6 nutrients \\(\\times\\) 6 growth rates), and I’m piping that dataset to the plotting function, where I’m plotting rate on the x-axis, expression on the y-axis, mapping the value of nutrient to the color, and using a line plot to display the data.\n\nlibrary(ggplot2)\nfilter(ydat, symbol==\"LEU1\") |&gt; \n  ggplot(aes(rate, expression, colour=nutrient)) + geom_line(lwd=1.5)\n\nLook closely at that! LEU1 is highly expressed when starved of leucine because the cell has to synthesize its own! And as the amount of leucine in the environment (the growth rate) increases, the cell can worry less about synthesizing leucine, so LEU1 expression goes back down. Consequently the cell can devote more energy into other functions, and we see other genes’ expression very slightly raising.\n\n\n\n\n\n\nExercise 1\n\n\n\n\nDisplay the data where the gene ontology biological process (the bp variable) is “leucine biosynthesis” (case-sensitive) and the limiting nutrient was Leucine. (Answer should return a 24-by-7 data frame – 4 genes \\(\\times\\) 6 growth rates).\nGene/rate combinations had high expression (in the top 1% of expressed genes)? Hint: see ?quantile and try quantile(ydat$expression, probs=.99) to see the expression value which is higher than 99% of all the data, then filter() based on that. Try wrapping your answer with a View() function so you can see the whole thing. What does it look like those genes are doing? Answer should return a 1971-by-7 data frame.\n\n\n\n\n3.3.1.1 Aside: Writing Data to File\nWhat we’ve done up to this point is read in data from a file (read_csv(...)), and assigning that to an object in our workspace (ydat &lt;- ...). When we run operations like filter() on our data, consider two things:\n\nThe ydat object in our workspace is not being modified directly. That is, we can filter(ydat, ...), and a result is returned to the screen, but ydat remains the same. This effect is similar to what we demonstrated in our first session.\n\n\n# Assign the value '50' to the weight object.\nweight &lt;- 50\n\n# Print out weight to the screen (50)\nweight\n\n# What's the value of weight plus 10?\nweight + 10\n\n# Weight is still 50\nweight\n\n# Weight is only modified if we *reassign* weight to the modified value\nweight &lt;- weight+10\n# Weight is now 60\nweight\n\n\nMore importantly, the data file on disk (data/brauer2007_tidy.csv) is never modified. No matter what we do to ydat, the file is never modified. If we want to save the result of an operation to a file on disk, we can assign the result of an operation to an object, and write_csv that object to disk. See the help for ?write_csv (note, write_csv() with an underscore is part of the readr package – not to be confused with the built-in write.csv() function).\n\n\n# What's the result of this filter operation?\nfilter(ydat, nutrient==\"Leucine\" & bp==\"leucine biosynthesis\")\n\n# Assign the result to a new object\nleudat &lt;- filter(ydat, nutrient==\"Leucine\" & bp==\"leucine biosynthesis\")\n\n# Write that out to disk\nwrite_csv(leudat, \"leucinedata.csv\")\n\nNote that this is different than saving your entire workspace to an Rdata file, which would contain all the objects we’ve created (weight, ydat, leudat, etc).\n\n\n\n3.3.2 select()\nThe filter() function allows you to return only certain rows matching a condition. The select() function returns only certain columns. The first argument is the data, and subsequent arguments are the columns you want.\n\n# Select just the symbol and systematic_name\nselect(ydat, symbol, systematic_name)\n\n# Alternatively, just remove columns. Remove the bp and mf columns.\nselect(ydat, -bp, -mf)\n\n# Notice that the original data doesn't change!\nydat\n\nNotice above how the original data doesn’t change. We’re selecting out only certain columns of interest and throwing away columns we don’t care about. If we wanted to keep this data, we would need to reassign the result of the select() operation to a new object. Let’s make a new object called nogo that does not contain the GO annotations. Notice again how the original data is unchanged.\n\n# create a new dataset without the go annotations.\nnogo &lt;- select(ydat, -bp, -mf)\nnogo\n\n# we could filter this new dataset\nfilter(nogo, symbol==\"LEU1\" & rate==.05)\n\n# Notice how the original data is unchanged - still have all 7 columns\nydat\n\n\n\n3.3.3 mutate()\nThe mutate() function adds new columns to the data. Remember, it doesn’t actually modify the data frame you’re operating on, and the result is transient unless you assign it to a new object or reassign it back to itself (generally, not always a good practice).\nThe expression level reported here is the \\(log_2\\) of the sample signal divided by the signal in the reference channel, where the reference RNA for all samples was taken from the glucose-limited chemostat grown at a dilution rate of 0.25 \\(h^{-1}\\). Let’s mutate this data to add a new variable called “signal” that’s the actual raw signal ratio instead of the log-transformed signal.\n\nmutate(nogo, signal=2^expression)\n\nMutate has a nice little feature too in that it’s “lazy.” You can mutate and add one variable, then continue mutating to add more variables based on that variable. Let’s make another column that’s the square root of the signal ratio.\n\nmutate(nogo, signal=2^expression, sigsr=sqrt(signal))\n\nAgain, don’t worry about the code here to make the plot – we’ll learn about this later. Why do you think we log-transform the data prior to analysis?\n\nlibrary(tidyr)\nmutate(nogo, signal=2^expression, sigsr=sqrt(signal)) |&gt; \n  gather(unit, value, expression:sigsr) |&gt; \n  ggplot(aes(value)) + geom_histogram(bins=100) + facet_wrap(~unit, scales=\"free\")\n\n\n\n3.3.4 arrange()\nThe arrange() function does what it sounds like. It takes a data frame or tbl and arranges (or sorts) by column(s) of interest. The first argument is the data, and subsequent arguments are columns to sort on. Use the desc() function to arrange by descending.\n\n# arrange by gene symbol\narrange(ydat, symbol)\n\n# arrange by expression (default: increasing)\narrange(ydat, expression)\n\n# arrange by decreasing expression\narrange(ydat, desc(expression))\n\n\n\n\n\n\n\nExercise 2\n\n\n\n\nFirst, re-run the command you used above to filter the data for genes involved in the “leucine biosynthesis” biological process and where the limiting nutrient is Leucine.\nWrap this entire filtered result with a call to arrange() where you’ll arrange the result of #1 by the gene symbol.\nWrap this entire result in a View() statement so you can see the entire result.\n\n\n\n\n\n3.3.5 summarize()\nThe summarize() function summarizes multiple values to a single value. On its own the summarize() function doesn’t seem to be all that useful. The dplyr package provides a few convenience functions called n() and n_distinct() that tell you the number of observations or the number of distinct values of a particular variable.\nNotice that summarize takes a data frame and returns a data frame. In this case it’s a 1x1 data frame with a single row and a single column. The name of the column, by default is whatever the expression was used to summarize the data. This usually isn’t pretty, and if we wanted to work with this resulting data frame later on, we’d want to name that returned value something easier to deal with.\n\n# Get the mean expression for all genes\nsummarize(ydat, mean(expression))\n\n# Use a more friendly name, e.g., meanexp, or whatever you want to call it.\nsummarize(ydat, meanexp=mean(expression))\n\n# Measure the correlation between rate and expression \nsummarize(ydat, r=cor(rate, expression))\n\n# Get the number of observations\nsummarize(ydat, n())\n\n# The number of distinct gene symbols in the data \nsummarize(ydat, n_distinct(symbol))\n\n\n\n3.3.6 group_by()\nWe saw that summarize() isn’t that useful on its own. Neither is group_by() All this does is takes an existing data frame and coverts it into a grouped data frame where operations are performed by group.\n\nydat\ngroup_by(ydat, nutrient)\ngroup_by(ydat, nutrient, rate)\n\nThe real power comes in where group_by() and summarize() are used together. First, write the group_by() statement. Then wrap the result of that with a call to summarize().\n\n# Get the mean expression for each gene\n# group_by(ydat, symbol)\nsummarize(group_by(ydat, symbol), meanexp=mean(expression))\n\n# Get the correlation between rate and expression for each nutrient\n# group_by(ydat, nutrient)\nsummarize(group_by(ydat, nutrient), r=cor(rate, expression))"
  },
  {
    "objectID": "dplyr.html#the-pipe",
    "href": "dplyr.html#the-pipe",
    "title": "3  Data Manipulation",
    "section": "3.4 The pipe: |>",
    "text": "3.4 The pipe: |&gt;\n\n3.4.1 How |&gt; works\nThis is where things get awesome. The dplyr package imports functionality from the magrittr package that lets you pipe the output of one function to the input of another, so you can avoid nesting functions. It looks like this: |&gt;. You don’t have to load the magrittr package to use it since dplyr imports its functionality when you load the dplyr package.\nHere’s the simplest way to use it. Remember the tail() function. It expects a data frame as input, and the next argument is the number of lines to print. These two commands are identical:\n\ntail(ydat, 5)\nydat |&gt; tail(5)\n\nLet’s use one of the dplyr verbs.\n\nfilter(ydat, nutrient==\"Leucine\")\nydat |&gt; filter(nutrient==\"Leucine\")\n\n\n\n3.4.2 Nesting versus |&gt;\nSo what?\nNow, think about this for a minute. What if we wanted to get the correlation between the growth rate and expression separately for each limiting nutrient only for genes in the leucine biosynthesis pathway, and return a sorted list of those correlation coeffients rounded to two digits? Mentally we would do something like this:\n\nTake the ydat dataset\nthen filter() it for genes in the leucine biosynthesis pathway\nthen group_by() the limiting nutrient\nthen summarize() to get the correlation (cor()) between rate and expression\nthen mutate() to round the result of the above calculation to two significant digits\nthen arrange() by the rounded correlation coefficient above\n\nBut in code, it gets ugly. First, take the ydat dataset\n\nydat\n\nthen filter() it for genes in the leucine biosynthesis pathway\n\nfilter(ydat, bp==\"leucine biosynthesis\")\n\nthen group_by() the limiting nutrient\n\ngroup_by(filter(ydat, bp==\"leucine biosynthesis\"), nutrient)\n\nthen summarize() to get the correlation (cor()) between rate and expression\n\nsummarize(group_by(filter(ydat, bp == \"leucine biosynthesis\"), nutrient), r = cor(rate,\n    expression))\n\nthen mutate() to round the result of the above calculation to two significant digits\n\nmutate(summarize(group_by(filter(ydat, bp == \"leucine biosynthesis\"), nutrient),\n    r = cor(rate, expression)), r = round(r, 2))\n\nthen arrange() by the rounded correlation coefficient above\n\narrange(\n  mutate(\n    summarize(\n      group_by(\n        filter(ydat, bp==\"leucine biosynthesis\"), \n      nutrient), \n    r=cor(rate, expression)), \n  r=round(r, 2)), \nr)\n\nNow compare that with the mental process of what you’re actually trying to accomplish. The way you would do this without pipes is completely inside-out and backwards from the way you express in words and in thought what you want to do. The pipe operator |&gt; allows you to pass the output data frame from one function to the input data frame to another function.\n\n\n\nNesting functions versus piping\n\n\nThis is how we would do that in code. It’s as simple as replacing the word “then” in words to the symbol |&gt; in code. (There’s a keyboard shortcut that I’ll use frequently to insert the |&gt; sequence – you can see what it is by clicking the Tools menu in RStudio, then selecting Keyboard Shortcut Help. On Mac, it’s CMD-SHIFT-M.)\n\nydat |&gt; \n  filter(bp==\"leucine biosynthesis\") |&gt;\n  group_by(nutrient) |&gt; \n  summarize(r=cor(rate, expression)) |&gt; \n  mutate(r=round(r,2)) |&gt; \n  arrange(r)"
  },
  {
    "objectID": "dplyr.html#exercises",
    "href": "dplyr.html#exercises",
    "title": "3  Data Manipulation",
    "section": "3.5 Exercises",
    "text": "3.5 Exercises\nHere’s a warm-up round. Try the following.\n\n\n\n\n\n\nExercise 3\n\n\n\nShow the limiting nutrient and expression values for the gene ADH2 when the growth rate is restricted to 0.05. Hint: 2 pipes: filter and select.\n\n\n\n\n\n\n\n\nExercise 4\n\n\n\nWhat are the four most highly expressed genes when the growth rate is restricted to 0.05 by restricting glucose? Show only the symbol, expression value, and GO terms. Hint: 4 pipes: filter, arrange, head, and select.\n\n\n\n\n\n\n\n\nExercise 5\n\n\n\nWhen the growth rate is restricted to 0.05, what is the average expression level across all genes in the “response to stress” biological process, separately for each limiting nutrient? What about genes in the “protein biosynthesis” biological process? Hint: 3 pipes: filter, group_by, summarize.\n\n\nThat was easy, right? How about some tougher ones.\n\n\n\n\n\n\nExercise 6\n\n\n\nFirst, some review. How do we see the number of distinct values of a variable? Use n_distinct() within a summarize() call.\n\nydat |&gt; summarize(n_distinct(mf))\n\n\n\n\n\n\n\n\n\nExercise 7\n\n\n\nWhich 10 biological process annotations have the most genes associated with them? What about molecular functions? Hint: 4 pipes: group_by, summarize with n_distinct, arrange, head.\n\n\n\n\n\n\n\n\nExercise 8\n\n\n\nHow many distinct genes are there where we know what process the gene is involved in but we don’t know what it does? Hint: 3 pipes; filter where bp!=\"biological process unknown\" & mf==\"molecular function unknown\", and after selecting columns of interest, pipe the output to distinct(). The answer should be 737, and here are a few:\n\n\n\n\n\n\n\n\nExercise 9\n\n\n\nWhen the growth rate is restricted to 0.05 by limiting Glucose, which biological processes are the most upregulated? Show a sorted list with the most upregulated BPs on top, displaying the biological process and the average expression of all genes in that process rounded to two digits. Hint: 5 pipes: filter, group_by, summarize, mutate, arrange.\n\n\n\n\n\n\n\n\nExercise 10\n\n\n\nGroup the data by limiting nutrient (primarily) then by biological process. Get the average expression for all genes annotated with each process, separately for each limiting nutrient, where the growth rate is restricted to 0.05. Arrange the result to show the most upregulated processes on top. The initial result will look like the result below. Pipe this output to a View() statement. What’s going on? Why didn’t the arrange() work? Hint: 5 pipes: filter, group_by, summarize, arrange, View.\n\n\n\n\n\n\n\n\nExercise 11\n\n\n\nLet’s try to further process that result to get only the top three most upregulated biolgocal processes for each limiting nutrient. Google search “dplyr first result within group.” You’ll need a filter(row_number()......) in there somewhere. Hint: 5 pipes: filter, group_by, summarize, arrange, filter(row_number().... Note: dplyr’s pipe syntax used to be %.% before it changed to |&gt;. So when looking around, you might still see some people use the old syntax. Now if you try to use the old syntax, you’ll get a deprecation warning.\n\n\n\n\n\n\n\n\nExercise 12\n\n\n\nThere’s a slight problem with the examples above. We’re getting the average expression of all the biological processes separately by each nutrient. But some of these biological processes only have a single gene in them! If we tried to do the same thing to get the correlation between rate and expression, the calculation would work, but we’d get a warning about a standard deviation being zero. The correlation coefficient value that results is NA, i.e., missing. While we’re summarizing the correlation between rate and expression, let’s also show the number of distinct genes within each grouping.\n\nydat |&gt; \n  group_by(nutrient, bp) |&gt; \n  summarize(r=cor(rate, expression), ngenes=n_distinct(symbol))\n\nWarning: There was 1 warning in `summarize()`.\nℹ In argument: `r = cor(rate, expression)`.\nℹ In group 110: `nutrient = \"Ammonia\"` and `bp = \"allantoate transport\"`.\nCaused by warning in `cor()`:\n! the standard deviation is zero\n\n\nTake the above code and continue to process the result to show only results where the process has at least 5 genes. Add a column corresponding to the absolute value of the correlation coefficient, and show for each nutrient the singular process with the highest correlation between rate and expression, regardless of direction. Hint: 4 more pipes: filter, mutate, arrange, and filter again with row_number()==1. Ignore the warning."
  },
  {
    "objectID": "ggplot2.html",
    "href": "ggplot2.html",
    "title": "4  Data Visualization",
    "section": "",
    "text": "Not much to see here…"
  },
  {
    "objectID": "tidyeda.html",
    "href": "tidyeda.html",
    "title": "5  Tidy EDA",
    "section": "",
    "text": "Not much to see here…"
  },
  {
    "objectID": "rmarkdown.html",
    "href": "rmarkdown.html",
    "title": "6  R Markdown",
    "section": "",
    "text": "Not much to see here…"
  },
  {
    "objectID": "stats.html",
    "href": "stats.html",
    "title": "7  Essential Statistics",
    "section": "",
    "text": "Not much to see here…"
  },
  {
    "objectID": "survival.html",
    "href": "survival.html",
    "title": "8  Survival Analysis",
    "section": "",
    "text": "Not much to see here…"
  },
  {
    "objectID": "predmodeling.html",
    "href": "predmodeling.html",
    "title": "9  Predictive Modeling",
    "section": "",
    "text": "Not much to see here…"
  },
  {
    "objectID": "forecasting.html",
    "href": "forecasting.html",
    "title": "10  Probabilistic Forecasting",
    "section": "",
    "text": "Not much to see here…"
  },
  {
    "objectID": "textmining.html",
    "href": "textmining.html",
    "title": "11  Text Mining",
    "section": "",
    "text": "Not much to see here…"
  },
  {
    "objectID": "ggtree.html",
    "href": "ggtree.html",
    "title": "12  Phylogenetic Trees",
    "section": "",
    "text": "Not much to see here…"
  },
  {
    "objectID": "rnaseq.html",
    "href": "rnaseq.html",
    "title": "13  RNA-seq",
    "section": "",
    "text": "Not much to see here…"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Bryan, Jennifer. 2019. “STAT 545: Data Wrangling, Exploration, and\nAnalysis with r.” https://stat545.com/.\n\n\nLove, Michael I., Wolfgang Huber, and Simon Anders. 2014.\n“Moderated Estimation of Fold Change and Dispersion for RNA-seq Data with DESeq2.”\nGenome Biology 15 (12): 1–21.\n\n\nRobinson, David. 2015. “Variance Explained.”\nhttp://varianceexplained.org/.\n\n\nSilge, Julia, and David Robinson. 2017. Text Mining\nwith R: A Tidy Approach. 1st edition.\nBeijing ; Boston: O’Reilly Media.\n\n\nTeal, Tracy K., Karen A. Cranston, Hilmar Lapp, Ethan White, Greg\nWilson, Karthik Ram, and Aleksandra Pawlik. 2015. “Data Carpentry:\nWorkshops to Increase Data Literacy for Researchers.”\n\n\nWilson, Greg. 2014. “Software Carpentry: Lessons\nLearned.” F1000Research 3.\n\n\nYu, Guangchuang. 2022. “Ggtree: An r Package for Visualization of\nTree and Annotation Data.” http://bioconductor.org/packages/ggtree/.\n\n\nYu, Guangchuang, David K. Smith, Huachen Zhu, Yi Guan, and Tommy\nTsan-Yuk Lam. 2017. “Ggtree: An R Package for\nVisualization and Annotation of Phylogenetic Trees with Their Covariates\nand Other Associated Data.” Methods in Ecology and\nEvolution 8 (1): 28–36."
  },
  {
    "objectID": "setup.html#software",
    "href": "setup.html#software",
    "title": "Appendix A — Setup",
    "section": "A.1 Software",
    "text": "A.1 Software"
  },
  {
    "objectID": "setup.html#data",
    "href": "setup.html#data",
    "title": "Appendix A — Setup",
    "section": "A.2 Data",
    "text": "A.2 Data\n\nOption 1: Download all the data. Download and extract this zip file (11.36 Mb) with all the data for the entire workshop. This may include additional datasets that we won’t use here.\nOption 2: Download individual datasets as needed.\n\nCreate a new folder somewhere on your computer that’s easy to get to (e.g., your Desktop). Name it bds. Inside that folder, make a folder called data, all lowercase.\nDownload individual data files as needed, saving them to the new bdsr/data folder you just made. Click to download. If data displays in your browser, right-click and select Save link as… (or similar) to save to the desired location.\n\n\n\ndata/airway_metadata.csv\ndata/airway_scaledcounts.csv\ndata/annotables_grch38.csv\ndata/austen.csv\ndata/brauer2007_messy.csv\ndata/brauer2007_sysname2go.csv\ndata/brauer2007_tidy.csv\ndata/dmd.csv\ndata/flu_genotype.csv\ndata/gapminder.csv\ndata/grads_dd.csv\ndata/grads.csv\ndata/h7n9_analysisready.csv\ndata/h7n9.csv\ndata/heartrate2dose.csv\ndata/ilinet.csv\ndata/movies_dd.csv\ndata/movies_imdb.csv\ndata/movies.csv\ndata/nhanes_dd.csv\ndata/nhanes.csv\ndata/SRP026387_metadata.csv\ndata/SRP026387_scaledcounts.csv\ndata/stressEcho.csv"
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Appendix B — Additional Resources",
    "section": "",
    "text": "Not much to see here…"
  }
]